#!/usr/bin/env python3
"""
å› å­åº“ç®¡ç†å™¨

ç”¨äºåœ¨å®éªŒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä¿å­˜å› å­åˆ°ç»Ÿä¸€çš„å› å­åº“JSONæ–‡ä»¶ã€‚
æ¯å®Œæˆä¸€è½®å›æµ‹åï¼Œä¼šè‡ªåŠ¨å°†æŒ–æ˜å‡ºçš„å› å­è¿½åŠ åˆ°å› å­åº“ä¸­ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
    from factor_library_manager import FactorLibraryManager
    
    manager = FactorLibraryManager("all_factors_library.json")
    manager.add_factors_from_experiment(
        experiment=exp,
        experiment_id="2026-01-18_12-00-00",
        round_number=0,
        hypothesis="...",
        feedback=feedback_obj,
        evolution_phase="original",
        ...
    )
"""

import json
import hashlib
import os
from datetime import datetime
from pathlib import Path
from collections import OrderedDict
from typing import Any, Optional, List
import threading


class FactorLibraryManager:
    """å› å­åº“ç®¡ç†å™¨ï¼Œç”¨äºä¿å­˜å’Œç®¡ç†æŒ–æ˜å‡ºçš„å› å­"""
    
    _lock = threading.Lock()  # æ–‡ä»¶å†™å…¥é”ï¼Œç¡®ä¿å¹¶å‘å®‰å…¨
    
    def __init__(self, library_path: str):
        """
        åˆå§‹åŒ–å› å­åº“ç®¡ç†å™¨
        
        Args:
            library_path: å› å­åº“JSONæ–‡ä»¶è·¯å¾„
        """
        self.library_path = Path(library_path)
        
    def _generate_factor_id(self, factor_name: str, factor_expression: str, timestamp: str) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„å› å­ID
        
        Args:
            factor_name: å› å­åç§°
            factor_expression: å› å­è¡¨è¾¾å¼
            timestamp: æ—¶é—´æˆ³
            
        Returns:
            16ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ä½œä¸ºå› å­ID
        """
        content = f"{factor_name}_{factor_expression}_{timestamp}"
        return hashlib.md5(content.encode()).hexdigest()[:16]
    
    def _load_library(self) -> dict:
        """
        åŠ è½½å› å­åº“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°çš„
        
        Returns:
            å› å­åº“å­—å…¸ï¼ŒåŒ…å« metadata å’Œ factors
        """
        if self.library_path.exists():
            try:
                with open(self.library_path, 'r', encoding='utf-8') as f:
                    return json.load(f, object_pairs_hook=OrderedDict)
            except (json.JSONDecodeError, IOError):
                pass
        
        # åˆ›å»ºæ–°çš„å› å­åº“
        return {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "total_factors": 0,
                "version": "1.0"
            },
            "factors": OrderedDict()
        }
    
    def _save_library(self, data: dict) -> None:
        """
        ä¿å­˜å› å­åº“åˆ°æ–‡ä»¶
        
        Args:
            data: å› å­åº“å­—å…¸
        """
        # æ›´æ–°å…ƒæ•°æ®
        data["metadata"]["last_updated"] = datetime.now().isoformat()
        data["metadata"]["total_factors"] = len(data.get("factors", {}))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.library_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(self.library_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def add_factors_from_experiment(
        self,
        experiment: Any,
        experiment_id: str,
        round_number: int,
        hypothesis: Optional[str] = None,
        feedback: Optional[Any] = None,
        initial_direction: Optional[str] = None,
        user_initial_direction: Optional[str] = None,
        planning_direction: Optional[str] = None,
        evolution_phase: str = "original",
        trajectory_id: str = "",
        parent_trajectory_ids: Optional[List[str]] = None,
    ) -> int:
        """
        ä»å®éªŒå¯¹è±¡ä¸­æå–å› å­å¹¶ä¿å­˜åˆ°åº“ä¸­
        
        Args:
            experiment: å®éªŒå¯¹è±¡ï¼ŒåŒ…å« sub_tasks å’Œ result
            experiment_id: å®éªŒID
            round_number: è½®æ¬¡ç¼–å·
            hypothesis: å‡è®¾æ–‡æœ¬
            feedback: åé¦ˆå¯¹è±¡
            initial_direction: åˆå§‹æ–¹å‘
            user_initial_direction: ç”¨æˆ·åˆå§‹æ–¹å‘
            planning_direction: è§„åˆ’æ–¹å‘
            evolution_phase: è¿›åŒ–é˜¶æ®µ (original/mutation/crossover)
            trajectory_id: è½¨è¿¹ID
            parent_trajectory_ids: çˆ¶è½¨è¿¹IDåˆ—è¡¨
            
        Returns:
            æ·»åŠ çš„å› å­æ•°é‡
        """
        if experiment is None:
            return 0
        
        # è·å–æ—¶é—´æˆ³
        timestamp = datetime.now().isoformat()
        
        # æå–å®éªŒç»“æœæŒ‡æ ‡
        result_metrics = {}
        if hasattr(experiment, 'result') and experiment.result is not None:
            result = experiment.result
            if hasattr(result, 'to_dict'):
                result_metrics = result.to_dict()
            elif isinstance(result, dict):
                result_metrics = result
            else:
                try:
                    # pandas Series
                    result_metrics = result.to_dict() if hasattr(result, 'to_dict') else {}
                except:
                    result_metrics = {}
        
        # æå–åé¦ˆä¿¡æ¯
        feedback_info = {}
        if feedback is not None:
            if hasattr(feedback, 'observations'):
                feedback_info['observations'] = str(feedback.observations)
            if hasattr(feedback, 'hypothesis_evaluation'):
                feedback_info['hypothesis_evaluation'] = str(feedback.hypothesis_evaluation)
            if hasattr(feedback, 'decision'):
                feedback_info['decision'] = feedback.decision
            if hasattr(feedback, 'reason'):
                feedback_info['reason'] = str(feedback.reason)
        
        # ä»å®éªŒä¸­æå–å› å­
        factors_to_add = []
        
        if hasattr(experiment, 'sub_tasks'):
            for idx, task in enumerate(experiment.sub_tasks):
                try:
                    # è·å–ä»»åŠ¡ä¿¡æ¯
                    task_info = {}
                    if hasattr(task, 'get_task_information_and_implementation_result'):
                        task_info = task.get_task_information_and_implementation_result()
                    
                    factor_name = task_info.get('factor_name') or getattr(task, 'factor_name', f'factor_{idx}')
                    factor_expression = task_info.get('factor_expression') or getattr(task, 'factor_expression', '')
                    factor_description = task_info.get('factor_description') or getattr(task, 'factor_description', '')
                    factor_formulation = task_info.get('factor_formulation') or getattr(task, 'factor_formulation', '')
                    
                    # è·å–å®ç°ä»£ç å’Œå› å­ç›®å½•è·¯å¾„ï¼ˆç¨³å¥å¤„ç†ï¼‰
                    implementation_code = ""
                    factor_dir = ""
                    result_h5_path = ""
                    cache_location = None
                    
                    try:
                        if hasattr(experiment, 'sub_workspace_list') and idx < len(experiment.sub_workspace_list):
                            workspace = experiment.sub_workspace_list[idx]
                            # è·å–å®ç°ä»£ç 
                            if hasattr(workspace, 'code'):
                                implementation_code = workspace.code or ""
                            # è·å–å› å­ç›®å½•è·¯å¾„ï¼ˆworkspace_path å±æ€§ï¼‰
                            if hasattr(workspace, 'workspace_path') and workspace.workspace_path:
                                try:
                                    ws_path = Path(workspace.workspace_path) if not isinstance(workspace.workspace_path, Path) else workspace.workspace_path
                                    factor_dir = ws_path.name
                                    result_h5_path = str(ws_path / 'result.h5')
                                except Exception as path_err:
                                    print(f"Warning: Failed to parse workspace path: {path_err}")
                        
                        # è·å–å·¥ä½œç©ºé—´åç¼€ï¼ˆç”¨äºå®šä½ç¼“å­˜ï¼‰
                        workspace_suffix = os.environ.get('EXPERIMENT_ID', '')
                        pickle_cache_path = os.environ.get('PICKLE_CACHE_FOLDER_PATH_STR', '')
                        env_workspace_path = os.environ.get('WORKSPACE_PATH', '')
                        
                        # æ„å»ºç¼“å­˜ä½ç½®ä¿¡æ¯ï¼ˆä»…å½“æœ‰è¶³å¤Ÿä¿¡æ¯æ—¶ï¼‰
                        if workspace_suffix and factor_dir:
                            cache_location = {
                                "workspace_suffix": workspace_suffix,
                                "workspace_path": env_workspace_path,
                                "factor_dir": factor_dir,
                                "result_h5_path": result_h5_path,
                            }
                    except Exception as cache_err:
                        # ç¼“å­˜ä½ç½®è·å–å¤±è´¥ä¸å½±å“å› å­ä¿å­˜
                        print(f"Warning: Failed to get cache location for factor {idx}: {cache_err}")
                        cache_location = None
                    
                    # ç”Ÿæˆå› å­ID
                    factor_id = self._generate_factor_id(factor_name, factor_expression, timestamp)
                    
                    # æ„å»ºå› å­è®°å½•
                    factor_record = {
                        "factor_id": factor_id,
                        "factor_name": factor_name,
                        "factor_expression": factor_expression,
                        "factor_implementation_code": implementation_code,
                        "factor_description": factor_description,
                        "factor_formulation": factor_formulation,
                        "cache_location": cache_location,  # æ–°å¢ï¼šå®Œæ•´çš„ç¼“å­˜ä½ç½®ä¿¡æ¯
                        "metadata": {
                            "experiment_id": experiment_id,
                            "round_number": round_number,
                            "evolution_phase": evolution_phase,
                            "trajectory_id": trajectory_id,
                            "parent_trajectory_ids": parent_trajectory_ids or [],
                            "hypothesis": hypothesis,
                            "initial_direction": initial_direction,
                            "planning_direction": planning_direction,
                            "created_at": timestamp,
                        },
                        "backtest_results": result_metrics,
                        "feedback": feedback_info,
                    }
                    
                    factors_to_add.append((factor_id, factor_record))
                    
                except Exception as e:
                    print(f"Warning: Failed to extract factor {idx}: {e}")
                    continue
        
        # å†™å…¥å› å­åº“ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        if factors_to_add:
            with self._lock:
                data = self._load_library()
                for factor_id, factor_record in factors_to_add:
                    data["factors"][factor_id] = factor_record
                self._save_library(data)
        
        return len(factors_to_add)

# ============================================================
# ä»¥ä¸‹æ˜¯åŸæœ‰çš„å› å­åº“æŠ½æ ·å·¥å…·å‡½æ•°
# ============================================================

def load_factor_library(filepath: Path):
    """
    åŠ è½½å› å­åº“ï¼Œè¿”å› metadata å’Œ factorsï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
    """
    print(f"ğŸ“– åŠ è½½å› å­åº“: {filepath}")
    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f, object_pairs_hook=OrderedDict)
    
    metadata = data.get('metadata', {})
    factors = data.get('factors', OrderedDict())
    
    print(f"   æ€»å› å­æ•°: {len(factors)}")
    return metadata, factors


def save_factor_library(factors: OrderedDict, output_path: Path, note: str):
    """
    ä¿å­˜å› å­åº“åˆ° JSON æ–‡ä»¶
    """
    output_data = OrderedDict([
        ('metadata', OrderedDict([
            ('created_at', datetime.now().isoformat()),
            ('total_factors', len(factors)),
            ('sampling_note', note),
            ('version', '1.0')
        ])),
        ('factors', factors)
    ])
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å·²ä¿å­˜: {output_path} ({len(factors)} ä¸ªå› å­)")

