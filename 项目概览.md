# AlphaAgent 项目细节文档

## 📖 项目简介

**AlphaAgent** 是一个基于大语言模型（LLM）驱动的自主Alpha因子挖掘框架，旨在通过三个专门的智能体来挖掘可解释且抗衰减的Alpha因子。该项目是KDD 2025论文 [AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay](https://arxiv.org/abs/2502.16789) 的官方实现。

### 核心价值

AlphaAgent通过整合LLM智能体，实现了从市场假设提出、因子构建到因子评估的完整自动化流程，有效解决了传统量化因子挖掘中的以下问题：
- **因子衰减问题**：通过正则化探索机制避免重复和过拟合
- **因子可解释性**：基于金融理论或新兴趋势提出可解释的市场假设
- **迭代优化**：通过反馈循环持续优化因子性能

## 🏗️ 项目架构

### 三大核心智能体

1. **Idea Agent（假设生成智能体）**
   - 基于金融理论或市场趋势提出市场假设
   - 指导因子创建的方向
   - 位置：`alphaagent/components/proposal/`

2. **Factor Agent（因子构建智能体）**
   - 根据假设构建具体的因子表达式
   - 集成正则化机制避免重复和过拟合
   - 位置：`alphaagent/components/coder/factor_coder/`

3. **Eval Agent（评估智能体）**
   - 验证因子的实用性
   - 执行回测
   - 通过反馈循环迭代优化因子
   - 位置：`alphaagent/core/evaluation.py`、`alphaagent/scenarios/qlib/experiment/`

### 正则化创新点

新颖性强制（Originality Enforcement）：为了避免“因子拥挤”，框架引入了基于**抽象语法树（AST）**的相似度度量。它会将新生成的因子与现有的 Alpha 库（如 Alpha101）进行 AST 子树同构检测，计算相似度分数 $S(f)$，从而确保因子具有独特性。

假设-因子对齐（Hypothesis-Factor Alignment）：利用 LLM 评估语义一致性 $C(h, d, f)$ 。这包括验证“因子描述是否符合市场假设”以及“数学表达式是否准确反映了描述逻辑”，从而过滤掉缺乏金融逻辑的随机拟合因子 。

复杂度控制（Complexity Control）：通过 AST 结构约束和参数计数来惩罚过于复杂的表达式 15151515。这有助于产生简练（Parsimonious）的因子，降低过拟合风险 16161616。
### 技术实现细节


算子库 (Operator Library)：框架预定义了一套标准化的数学和金融运算（如滚动平均、逻辑判断、截面处理等），作为 LLM 生成代码的中介层，解决了代码生成中的兼容性与鲁棒性问题。

AST 解析与匹配：每个因子表达式都会被解析为 AST，叶子节点为原始行情数据（如 $high, $low），内部节点为算子 18181818。相似度通过寻找两个 AST 之间的最大公共子树来确定 。

优化目标函数：AlphaAgent 的优化目标可表述为：$$f^* = \arg \max_{f \in \mathcal{F}} \mathcal{L}(f(X), y) - \lambda \mathcal{R}_g(f, h)$$其中 $\mathcal{L}$ 是预测效能指标，$\mathcal{R}_g$ 是包含复杂度、新颖性和对齐度的正则化项 202020202020202020。

底层模型：框架默认使用 GPT-3.5-turbo 作为基础智能体 21。

## 🔬 核心算法细节

### 1. AST相似度匹配算法（最大公共子树检测）

**位置**：`alphaagent/components/coder/factor_coder/factor_ast.py`

**核心函数**：`find_largest_common_subtree(root1, root2)`

**算法流程**：

1. **AST节点类型定义**：
   - `VarNode`: 变量节点（如 `$close`, `$high`）
   - `NumberNode`: 数字常量节点（如 `14`, `1e-8`）
   - `FunctionNode`: 函数调用节点（如 `TS_MAX($high, 14)`）
   - `BinaryOpNode`: 二元操作节点（如 `+`, `-`, `*`, `/`）
   - `ConditionalNode`: 条件表达式节点（如 `? :`）

2. **子树提取**：
   ```python
   def get_all_subtrees(root: Node) -> List[Node]:
       """递归提取所有可能的子树根节点"""
       result = [root]
       if isinstance(root, FunctionNode):
           for arg in root.args:
               result.extend(get_all_subtrees(arg))
       elif isinstance(root, BinaryOpNode):
           result.extend(get_all_subtrees(root.left))
           result.extend(get_all_subtrees(root.right))
       # ... 其他节点类型
   ```

3. **子树匹配**：
   - 对两个AST的所有子树进行两两比较
   - 使用 `are_subtrees_equal()` 递归比较子树结构
   - **可交换操作符处理**：对于 `+`, `*`, `==`, `!=` 等可交换操作，同时检查 `(A op B)` 和 `(B op A)` 两种顺序
   - 返回最大公共子树的根节点和大小

4. **相似度计算**：
   ```python
   duplicated_subtree_size, duplicated_subtree, matched_alpha = match_alphazoo(
       new_expression, factor_zoo_dataframe
   )
   ```
   - 遍历因子库（如Alpha101）中的所有因子
   - 计算新因子与每个已有因子的最大公共子树大小
   - 返回最大匹配大小和对应的匹配子树

**时间复杂度**：O(n² × m)，其中 n 是AST节点数，m 是因子库大小

### 2. 因子正则化算法（FactorRegulator）

**位置**：`alphaagent/scenarios/qlib/regulator/factor_regulator.py`

**核心类**：`FactorRegulator`

**正则化条件**：

1. **新颖性检查**（条件1）：
   ```python
   cond1 = eval_dict['duplicated_subtree_size'] <= duplication_threshold
   ```
   - 默认阈值：`duplication_threshold = 8`
   - 如果最大公共子树大小超过阈值，因子被认为与已有因子过于相似

2. **自由参数比例控制**（条件2）：
   ```python
   free_args_ratio = num_free_args / num_all_nodes
   cond2 = -np.log(1 - free_args_ratio) < 0.693  # 等价于 free_args_ratio < 0.5
   ```
   - `num_free_args`: AST中数字常量节点（NumberNode）的数量
   - `num_all_nodes`: AST中所有节点的总数
   - 使用 `-log(1-x)` 函数确保自由参数比例不超过50%，避免过度参数化

3. **唯一变量比例控制**（条件3）：
   ```python
   unique_vars_ratio = num_unique_vars / num_all_nodes
   cond3 = -np.log(1 - unique_vars_ratio) < 0.693  # 等价于 unique_vars_ratio < 0.5
   ```
   - `num_unique_vars`: AST中唯一变量名（以`$`开头的变量）的数量
   - 确保因子不过度依赖单一变量，保持多样性

**因子接受判断**：
```python
def is_expression_acceptable(self, eval_dict) -> bool:
    return cond1 and cond2 and cond3
```

**迭代优化机制**：
- 如果因子不满足正则化条件，将重复信息反馈给LLM
- LLM根据反馈重新生成因子表达式
- 重复此过程直到生成满足条件的因子或达到最大重试次数

### 3. 因子表达式解析算法（ExprParser）

**位置**：`alphaagent/components/coder/factor_coder/expr_parser.py`

**核心函数**：`parse_expression(factor_expression)`

**解析流程**：

1. **词法分析**：
   - 变量：`$变量名` 或 `变量名`（如 `$close`, `TS_MAX`）
   - 数字：支持整数、小数、科学计数法（如 `14`, `1e-8`）
   - 操作符：`+`, `-`, `*`, `/`, `>`, `<`, `>=`, `<=`, `==`, `!=`, `&&`, `||`, `?`, `:`

2. **语法分析**（使用 `pyparsing` 库）：
   - 操作符优先级（从高到低）：
     1. 乘除：`*`, `/`
     2. 加减：`+`, `-`
     3. 比较：`>`, `<`, `>=`, `<=`, `==`, `!=`
     4. 逻辑与：`&&`, `&`
     5. 逻辑或：`||`, `|`
     6. 条件表达式：`? :`（右结合）

3. **表达式转换**：
   - 二元运算转换为函数调用：
     ```python
     # "$close + $open" -> "ADD($close, $open)"
     # "$high - $low" -> "SUBTRACT($high, $low)"
     # "$volume * $close" -> "MULTIPLY($volume, $close)"
     # "$close / $open" -> "DIVIDE($close, $open)"
     ```
   - 逻辑运算转换为函数调用：
     ```python
     # "A && B" -> "AND(A, B)"
     # "A || B" -> "OR(A, B)"
     ```
   - 条件表达式转换：
     ```python
     # "A ? B : C" -> "pd.Series(np.where(A, B, C), index=A.index)"
     ```

4. **验证机制**：
   - 括号平衡检查：`check_parentheses_balance()`
   - 无效操作符检查：`check_for_invalid_operators()`

### 4. 假设生成算法（Hypothesis Generation）

**位置**：`alphaagent/scenarios/qlib/proposal/factor_proposal.py`

**核心类**：`AlphaAgentHypothesisGen`

**生成流程**：

1. **上下文准备**：
   ```python
   def prepare_context(self, trace: Trace) -> Tuple[dict, bool]:
       if len(trace.hist) > 0:
           # 使用历史假设和反馈
           hypothesis_and_feedback = render_from_template(trace)
       elif self.potential_direction is not None:
           # 使用初始方向提示
           hypothesis_and_feedback = render_potential_direction(self.potential_direction)
       else:
           # 首次生成，鼓励创新
           hypothesis_and_feedback = "鼓励提出与现有视角显著不同的创新假设"
   ```

2. **Prompt构建**：
   - **System Prompt**：包含场景描述、假设规范、输出格式
   - **User Prompt**：包含历史假设和反馈、当前轮次、RAG检索结果（如有）

3. **LLM调用**：
   ```python
   response = APIBackend().build_messages_and_create_chat_completion(
       user_prompt, system_prompt, json_mode=True
   )
   ```

4. **响应解析**：
   ```python
   hypothesis = AlphaAgentHypothesis(
       hypothesis=response_dict["hypothesis"],
       concise_observation=response_dict["concise_observation"],
       concise_justification=response_dict["concise_justification"],
       concise_knowledge=response_dict["concise_knowledge"],
       concise_specification=response_dict["concise_specification"],
   )
   ```

**假设结构**：
- `hypothesis`: 完整的市场假设描述
- `concise_observation`: 简洁的观察
- `concise_justification`: 简洁的合理性说明
- `concise_knowledge`: 相关的金融知识
- `concise_specification`: 简洁的规范说明

### 5. 因子构建算法（Hypothesis to Factor Expression）

**位置**：`alphaagent/scenarios/qlib/proposal/factor_proposal.py`

**核心类**：`AlphaAgentHypothesis2FactorExpression`

**构建流程**：

1. **上下文准备**：
   ```python
   context = {
       "target_hypothesis": str(hypothesis),
       "scenario": scenario_description,
       "hypothesis_and_feedback": historical_feedback,
       "function_lib_description": available_functions,
       "experiment_output_format": output_format,
       "target_list": existing_factors,
   }
   ```

2. **迭代生成与验证循环**：
   ```python
   while True:
       # 1. LLM生成因子表达式
       response = APIBackend().build_messages_and_create_chat_completion(...)
       response_dict = json.loads(response)
       
       # 2. 对每个因子进行验证
       for factor_name, factor_data in response_dict.items():
           expr = factor_data["expression"]
           
           # 2.1 语法解析检查
           if not self.factor_regulator.is_parsable(expr):
               break  # 重新生成
           
           # 2.2 正则化检查
           success, eval_dict = self.factor_regulator.evaluate(expr)
           if not self.factor_regulator.is_expression_acceptable(eval_dict):
               # 2.3 生成反馈并重新生成
               expression_duplication_prompt = render_duplication_feedback(
                   expr, eval_dict
               )
               user_prompt = update_prompt_with_feedback(...)
               break  # 重新生成
       
       # 3. 所有因子都通过验证
       if all_factors_valid:
           break
   ```

3. **因子任务创建**：
   ```python
   tasks.append(FactorTask(
       factor_name=factor_name,
       factor_description=description,
       factor_formulation=formulation,
       factor_expression=expression,
       variables=variables,
   ))
   ```

4. **去重处理**：
   - 检查新生成的因子是否与历史因子重复（按 `factor_name`）
   - 只保留唯一的因子任务

### 6. 反馈生成算法（Feedback Generation）

**位置**：`alphaagent/scenarios/qlib/developer/feedback.py`

**核心类**：`AlphaAgentQlibFactorHypothesisExperiment2Feedback`

**反馈生成流程**：

1. **结果处理**：
   ```python
   def process_results(current_result, sota_result):
       # 转换为DataFrame
       current_df = pd.DataFrame(current_result)
       sota_df = pd.DataFrame(sota_result)
       
       # 选择重要指标
       important_metrics = [
           "1day.excess_return_without_cost.max_drawdown",
           "1day.excess_return_without_cost.information_ratio",
           "1day.excess_return_without_cost.annualized_return",
           "IC",
       ]
       
       # 比较当前结果与SOTA结果
       combined_df = pd.concat([current_df, sota_df], axis=1)
       filtered_df = combined_df.loc[important_metrics]
       
       # 标记哪个结果更好
       filtered_df["Bigger columns name"] = filtered_df.apply(
           lambda row: "Current Result" if row["Current Result"] > row["SOTA Result"] 
                       else "SOTA Result", axis=1
       )
   ```

2. **Prompt构建**：
   ```python
   sys_prompt = render_template(
       "factor_feedback_generation/system",
       scenario=scenario_description
   )
   
   usr_prompt = render_template(
       "factor_feedback_generation/user",
       hypothesis_text=hypothesis_text,
       task_details=factor_tasks_details,
       combined_result=processed_results,
   )
   ```

3. **LLM生成反馈**：
   ```python
   response = APIBackend().build_messages_and_create_chat_completion(
       user_prompt=usr_prompt,
       system_prompt=sys_prompt,
       json_mode=True,
   )
   ```

4. **反馈解析**：
   ```python
   feedback = HypothesisFeedback(
       observations=response_json.get("Observations"),
       hypothesis_evaluation=response_json.get("Feedback for Hypothesis"),
       new_hypothesis=response_json.get("New Hypothesis"),
       reason=response_json.get("Reasoning"),
       decision=convert2bool(response_json.get("Replace Best Result")),
   )
   ```

**反馈结构**：
- `observations`: 对实验结果的观察
- `hypothesis_evaluation`: 对假设的评价
- `new_hypothesis`: 基于反馈的新假设建议
- `reason`: 决策理由
- `decision`: 是否替换最佳结果（布尔值）

### 7. 因子函数库（Function Library）

**位置**：`alphaagent/components/coder/factor_coder/function_lib.py`

**函数分类**：

1. **时间序列函数**（TS_*）：
   - `TS_RANK(df, p)`: 时间序列百分比排名
   - `TS_MAX(df, p)`: 时间序列滚动最大值
   - `TS_MIN(df, p)`: 时间序列滚动最小值
   - `TS_MEAN(df, p)`: 时间序列滚动平均值
   - `TS_STD(df, p)`: 时间序列滚动标准差
   - `TS_DELTA(df, p)`: 时间序列差分

2. **横截面函数**（截面排名、统计）：
   - `RANK(df)`: 横截面百分比排名
   - `MEAN(df)`: 横截面平均值
   - `STD(df)`: 横截面标准差
   - `MAX(df)`: 横截面最大值
   - `MIN(df)`: 横截面最小值
   - `MEDIAN(df)`: 横截面中位数
   - `SKEW(df)`: 横截面偏度
   - `KURT(df)`: 横截面峰度

3. **基础运算函数**：
   - `ADD(A, B)`: 加法
   - `SUBTRACT(A, B)`: 减法
   - `MULTIPLY(A, B)`: 乘法
   - `DIVIDE(A, B)`: 除法
   - `AND(A, B)`: 逻辑与
   - `OR(A, B)`: 逻辑或

**数据类型适配**：
- 使用 `@datatype_adapter` 装饰器自动处理 NumPy 数组、DataFrame、标量等不同输入类型
- 确保函数在不同数据类型下都能正确执行

### 8. 因子执行与回测算法

**位置**：`alphaagent/scenarios/qlib/developer/factor_runner.py`

**执行流程**：

1. **因子代码生成**：
   - 将因子表达式转换为可执行的Python代码
   - 使用Qlib的数据接口加载历史数据
   - 应用因子函数库中的函数进行计算

2. **因子值计算**：
   ```python
   # 示例：计算因子值
   factor_value = TS_RANK(DELTA($close, 1), 20)
   ```

3. **回测执行**：
   - 使用Qlib的回测框架
   - 计算IC（Information Coefficient）
   - 计算ICIR（IC Information Ratio）
   - 计算Rank IC和Rank ICIR
   - 计算回测收益、夏普比率、最大回撤等指标

4. **结果存储**：
   - 使用MLflow记录实验结果
   - 保存因子值到HDF5文件
   - 生成回测报告

### 9. 主循环控制算法（AlphaAgentLoop）

**位置**：`alphaagent/components/workflow/alphaagent_loop.py`

**循环步骤**：

1. **factor_propose**：生成市场假设
   ```python
   idea = self.hypothesis_generator.gen(self.trace)
   ```

2. **factor_construct**：构建因子表达式
   ```python
   factor = self.factor_constructor.convert(idea, self.trace)
   ```

3. **factor_calculate**：编码并计算因子值
   ```python
   factor = self.coder.develop(factor)
   ```

4. **factor_backtest**：执行回测
   ```python
   exp = self.runner.develop(factor, use_local=self.use_local)
   ```

5. **feedback**：生成反馈并更新历史
   ```python
   feedback = self.summarizer.generate_feedback(exp, idea, self.trace)
   self.trace.hist.append((idea, exp, feedback))
   ```

**停止条件**：
- 达到最大迭代次数
- 收到停止信号（`stop_event.is_set()`）
- 因子为空错误（`FactorEmptyError`）

**错误处理**：
- 使用 `@stop_event_check` 装饰器检查停止信号
- 使用 `skip_loop_error` 定义可跳过的错误类型
- 使用 `@measure_time` 装饰器记录每个步骤的执行时间


### 主要代码结构

```
AlphaAgent/
├── alphaagent/                    # 主代码包
│   ├── core/                      # 核心框架
│   │   ├── evolving_agent.py      # 进化智能体基类
│   │   ├── evolving_framework.py  # 进化框架（EvolvableSubjects、EvolvingStrategy等）
│   │   ├── evaluation.py          # 评估器
│   │   ├── developer.py           # 开发者（编码器、运行器）
│   │   ├── experiment.py          # 实验管理
│   │   ├── proposal.py            # 假设生成
│   │   ├── scenario.py            # 场景抽象
│   │   └── knowledge_base.py      # 知识库
│   │
│   ├── components/                # 功能组件
│   │   ├── coder/                 # 编码器组件
│   │   │   ├── factor_coder/      # 因子编码器（构建因子表达式）
│   │   │   ├── model_coder/       # 模型编码器
│   │   │   └── CoSTEER/           # CoSTEER策略
│   │   ├── workflow/              # 工作流
│   │   │   └── alphaagent_loop.py # AlphaAgent主循环
│   │   ├── proposal/              # 假设生成组件
│   │   ├── knowledge_management/  # 知识管理（RAG、向量库）
│   │   ├── document_reader/       # 文档读取（PDF等）
│   │   ├── loader/                # 加载器（任务、实验）
│   │   └── runner/                # 运行器
│   │
│   ├── scenarios/                 # 场景实现
│   │   └── qlib/                  # Qlib场景
│   │       ├── proposal/          # Qlib假设生成
│   │       ├── developer/         # Qlib开发者（因子/模型编码器、运行器）
│   │       ├── experiment/        # Qlib实验（因子实验、模型实验）
│   │       ├── regulator/         # 因子正则化器
│   │       └── factor_experiment_loader/  # 因子实验加载器
│   │
│   ├── app/                       # 应用入口
│   │   ├── cli.py                 # 命令行接口
│   │   └── qlib_rd_loop/          # Qlib研发循环
│   │       ├── factor_mining.py   # 因子挖掘主流程
│   │       ├── factor_backtest.py # 因子回测
│   │       └── factor_from_report.py  # 从报告提取因子
│   │
│   ├── utils/                     # 工具函数
│   │   ├── agent/                 # 智能体工具
│   │   ├── repo/                  # 仓库工具
│   │   └── workflow.py            # 工作流工具
│   │
│   └── oai/                       # OpenAI相关
│       ├── llm_utils.py           # LLM工具函数
│       └── llm_conf.py            # LLM配置
│
├── requirements.txt               # 依赖列表
├── pyproject.toml                 # 项目配置
├── prepare_cn_data.py             # 中国股票数据准备脚本
└── README.md                      # 项目说明
```

## 🔄 核心工作流程

### AlphaAgent主循环（AlphaAgentLoop）

位于 `alphaagent/components/workflow/alphaagent_loop.py`，实现了完整的因子挖掘循环：

1. **初始化阶段**
   - 加载场景（Scenario）
   - 初始化假设生成器（HypothesisGen）
   - 初始化因子构建器（Hypothesis2Experiment）
   - 初始化编码器（Developer）
   - 初始化运行器（Runner）
   - 初始化反馈生成器（HypothesisExperiment2Feedback）

2. **迭代循环**
   ```
   for each iteration:
      1. 生成假设（Hypothesis）
         └─> Idea Agent提出市场假设
      
      2. 构建因子（Factor Experiments）
         └─> Factor Agent根据假设构建因子表达式
      
      3. 编码因子（Code Factors）
         └─> 将因子表达式转换为可执行代码
      
      4. 运行实验（Run Experiments）
         └─> 在Qlib框架中执行回测
      
      5. 生成反馈（Generate Feedback）
         └─> Eval Agent分析结果并生成反馈
      
      6. 更新知识库（Update Knowledge Base）
         └─> 将成功因子和反馈存入知识库
   ```

### 因子挖掘流程（factor_mining.py）

主要入口函数 `main()` 实现：
- 接收市场假设方向（`potential_direction`）
- 创建AlphaAgentLoop实例
- 执行因子挖掘循环
- 输出挖掘到的因子和回测结果

### 因子回测流程（factor_backtest.py）

支持多因子批量回测：
- 从CSV文件读取因子定义
- 批量执行回测
- 生成回测报告

## 🛠️ 关键技术组件

### 1. 进化框架（Evolving Framework）

**核心类：**
- `EvolvableSubjects`: 可进化主体（因子、模型等）
- `EvolvingStrategy`: 进化策略（定义如何进化）
- `EvoStep`: 进化步骤（记录每次进化的状态）
- `RAGEvoAgent`: 基于RAG的进化智能体

**特点：**
- 支持多步迭代进化
- 集成RAG（检索增强生成）机制
- 支持知识自生成
- 基于反馈的迭代优化

### 2. 因子编码器（Factor Coder）

**位置：** `alphaagent/components/coder/factor_coder/`

**核心功能：**
- 将因子描述转换为Qlib表达式
- 因子AST解析和验证
- 因子函数库管理
- 因子测试和评估

**关键文件：**
- `factor.py`: FactorTask类，定义因子任务
- `factor_ast.py`: 因子AST解析
- `expr_parser.py`: 表达式解析器
- `function_lib.py`: 因子函数库

### 3. 实验管理（Experiment）

**位置：** `alphaagent/scenarios/qlib/experiment/`

**核心功能：**
- 因子实验执行（`factor_experiment.py`）
- 模型实验执行（`model_experiment.py`）
- 从报告提取因子实验（`factor_from_report_experiment.py`）
- 工作空间管理（`workspace.py`）

### 4. 知识管理（Knowledge Management）

**位置：** `alphaagent/components/knowledge_management/`

**功能：**
- 向量数据库（`vector_base.py`）
- 知识图谱（`graph.py`）
- RAG查询和生成

### 5. 文档处理（Document Reader）

**位置：** `alphaagent/components/document_reader/`

**功能：**
- PDF文档读取和解析
- 从研究报告提取因子信息
- 支持LangChain集成

## 📊 数据流程

### 数据准备

1. **股票数据准备**（`prepare_cn_data.py`）
   - 从baostock下载中国股票数据
   - 转换为Qlib格式
   - 收集交易日历和指数成分股

2. **数据路径**
   - 默认位置：`~/.qlib/qlib_data/cn_data`
   - 支持自定义数据路径

### 因子数据流程

```
市场假设 → 因子描述 → 因子表达式 → Qlib代码 → 回测执行 → 评估结果 → 反馈 → 优化
```

## ⚙️ 配置系统

### 环境变量（.env文件）

- `OPENAI_BASE_URL`: OpenAI兼容API的基础URL
- `OPENAI_API_KEY`: API密钥
- `REASONING_MODEL`: 推理模型（用于Idea Agent和Factor Agent）
- `CHAT_MODEL`: 聊天模型（用于调试和反馈生成）
- `USE_LOCAL`: 是否使用本地环境（而非Docker）

### 配置文件

- **因子实验配置：** `alphaagent/scenarios/qlib/experiment/factor_template/conf.yaml`
- **模型实验配置：** `alphaagent/scenarios/qlib/experiment/model_template/conf.yaml`
- **提示词配置：** 各组件下的 `prompts.yaml` 文件

## 🚀 主要功能

### 1. 因子挖掘（Factor Mining）

```bash
alphaagent mine --potential_direction "<市场假设>"
```

**功能：**
- 基于市场假设自动生成因子
- 执行回测验证因子有效性
- 迭代优化因子性能

### 2. 因子回测（Factor Backtest）

```bash
alphaagent backtest --factor_path "<因子CSV文件路径>"
```

**功能：**
- 批量回测多个因子
- 生成回测报告和性能指标

### 3. 从报告提取因子（Factor from Report）

```bash
alphaagent factor_from_report --pdf_path "<PDF文件路径>"
```

**功能：**
- 从研究报告PDF中提取因子
- 自动生成因子表达式
- 执行回测验证

### 4. 健康检查（Health Check）

```bash
alphaagent health_check
```

**功能：**
- 检查环境配置
- 验证依赖安装
- 测试API连接

## 📦 依赖关系

### 核心依赖

- **Qlib**: 量化投资平台（回测框架）
- **OpenAI/LLM**: 大语言模型API
- **LangChain**: LLM应用框架
- **Pandas/NumPy**: 数据处理
- **XGBoost/CatBoost**: 机器学习模型

### 完整依赖列表

见 `requirements.txt` 文件，主要包括：
- 数据处理：pandas, numpy, scikit-learn
- 机器学习：xgboost, catboost
- LLM相关：openai, langchain, tiktoken
- 文档处理：pypdf, pymupdf, azure-ai-formrecognizer
- 其他：loguru, fire, python-dotenv等

## 🔬 实验和评估

### 实验类型

1. **因子实验**（Factor Experiment）
   - 单因子回测
   - 因子性能评估
   - IC、ICIR、Rank IC等指标

2. **模型实验**（Model Experiment）
   - 模型训练和评估
   - 支持多种模型（LSTM、GRU、Transformer等）

### 评估指标

- **IC (Information Coefficient)**: 信息系数
- **ICIR**: IC信息比率
- **Rank IC**: 排序IC
- **Rank ICIR**: 排序IC信息比率
- **回测收益**: 策略回测收益率
- **夏普比率**: 风险调整后收益

## 📝 使用示例

### 基本使用流程

1. **准备数据**
   ```bash
   python prepare_cn_data.py
   ```

2. **配置环境**
   ```bash
   # 创建.env文件
   echo "OPENAI_API_KEY=your_key" > .env
   echo "OPENAI_BASE_URL=your_url" >> .env
   ```

3. **运行因子挖掘**
   ```bash
   alphaagent mine --potential_direction "基于技术指标的动量因子"
   ```

4. **查看结果**
   - 日志文件：`./log/`
   - 回测结果：MLflow tracking UI
   - Web UI：`alphaagent ui --port 19899`

### 完整因子生成示例：从假设到回测的全流程

以下通过一个完整的示例，详细展示 AlphaAgent 如何从头到尾生成一个因子，包括各种情况下的处理机制。

#### 场景设定

**初始输入**：用户提供潜在方向 `"基于波动率调整的动量因子"`

**目标**：生成一个能够捕捉高波动后反转或动量延续的因子

---

#### 阶段1：假设生成（Hypothesis Generation）

**1.1 上下文准备**

系统首先检查历史记录：
- 如果是首次迭代：使用 `potential_direction` 作为初始提示
- 如果有历史记录：加载之前的假设和反馈

**示例 Prompt 构建**：

```
System Prompt:
你是一位经验丰富的量化研究员，需要基于市场观察提出可验证的金融假设。
场景：中国A股市场，数据包含价格、成交量、技术指标等。

User Prompt:
基于以下方向提出市场假设："基于波动率调整的动量因子"
请考虑：
- 市场波动率与价格动量的关系
- 如何通过波动率过滤噪音
- 高波动后的市场行为特征
```

**1.2 LLM 响应**

LLM 生成的假设（JSON格式）：

```json
{
  "hypothesis": "高波动率往往意味着市场过度反应。在剔除市场噪音（高波动）后，纯粹的动量信号可能更有效。我们可以构建一个波动率调整的动量因子，捕捉高波动后的反转或动量延续。",
  "concise_observation": "市场波动率放大时，价格动量信号可能被噪音掩盖",
  "concise_justification": "波动率可以作为噪音的代理变量，通过标准化动量可以提取更纯净的信号",
  "concise_knowledge": "金融理论：波动率聚类现象，高波动后往往伴随价格反转或趋势延续",
  "concise_specification": "构建 (价格动量 / 波动率) 形式的因子，捕捉波动率调整后的动量"
}
```

**1.3 假设对象创建**

系统创建 `AlphaAgentHypothesis` 对象：

```python
hypothesis = AlphaAgentHypothesis(
    hypothesis="高波动率往往意味着市场过度反应...",
    concise_observation="市场波动率放大时，价格动量信号可能被噪音掩盖",
    concise_justification="波动率可以作为噪音的代理变量...",
    concise_knowledge="金融理论：波动率聚类现象...",
    concise_specification="构建 (价格动量 / 波动率) 形式的因子..."
)
```

**结果**：✅ 假设生成成功，进入下一阶段

---

#### 阶段2：因子构建（Factor Construction）

**2.1 上下文准备**

系统准备因子构建的上下文：

```python
context = {
    "target_hypothesis": str(hypothesis),  # 完整的假设描述
    "scenario": qlib_scenario_description,  # Qlib场景描述
    "hypothesis_and_feedback": "",  # 首次迭代为空
    "function_lib_description": available_functions,  # 可用函数列表
    "experiment_output_format": factor_output_format,  # 输出格式要求
    "target_list": [],  # 已有因子列表（首次为空）
}
```

**2.2 LLM 生成因子表达式（第1次尝试）**

**Prompt 示例**：

```
基于以下假设生成因子表达式：
假设：高波动率往往意味着市场过度反应。在剔除市场噪音（高波动）后，纯粹的动量信号可能更有效。

可用函数：
- TS_MEAN(df, p): 时间序列滚动平均值
- TS_STD(df, p): 时间序列滚动标准差
- DELTA(df, p): 时间序列差分
- RANK(df): 横截面排名
...

请生成1-3个因子表达式，每个因子包含：
- factor_name: 因子名称
- description: 因子描述
- formulation: 数学公式
- expression: Qlib表达式
- variables: 使用的变量列表
```

**LLM 第1次响应**：

```json
{
  "volatility_adjusted_momentum": {
    "description": "波动率调整的20日动量因子",
    "formulation": "Return(close, 20) / Std(close, 20)",
    "expression": "DELTA($close, 20) / TS_STD($close, 20)",
    "variables": ["$close"]
  }
}
```

**2.3 语法解析检查**

系统调用 `factor_regulator.is_parsable()`：

```python
expr = "DELTA($close, 20) / TS_STD($close, 20)"
try:
    ast = parse_expression(expr)
    # 解析成功
    is_parsable = True
except ValueError as e:
    # 解析失败，记录错误
    is_parsable = False
```

**结果**：✅ 表达式语法正确，通过解析检查

**2.4 正则化检查（第1次）**

系统调用 `factor_regulator.evaluate()` 进行正则化检查：

```python
# AST相似度匹配
duplicated_subtree_size, matched_subtree, matched_alpha = match_alphazoo(
    "DELTA($close, 20) / TS_STD($close, 20)", 
    alpha101_dataframe
)
# 结果：duplicated_subtree_size = 5
# 匹配到的子树：TS_STD($close, 20)

# 复杂度统计
num_free_args = count_free_args(expr)  # 结果：1 (只有20)
num_unique_vars = count_unique_vars(expr)  # 结果：1 ($close)
num_all_nodes = count_all_nodes(expr)  # 结果：7

# 正则化判断
cond1 = duplicated_subtree_size <= 8  # 5 <= 8 ✅
free_args_ratio = 1 / 7 = 0.143
cond2 = -log(1 - 0.143) = 0.154 < 0.693 ✅
unique_vars_ratio = 1 / 7 = 0.143
cond3 = -log(1 - 0.143) = 0.154 < 0.693 ✅
```

**结果**：✅ 所有正则化条件通过，因子被接受

**2.5 因子任务创建**

系统创建 `FactorTask` 对象：

```python
task = FactorTask(
    factor_name="volatility_adjusted_momentum",
    factor_description="波动率调整的20日动量因子",
    factor_formulation="Return(close, 20) / Std(close, 20)",
    factor_expression="DELTA($close, 20) / TS_STD($close, 20)",
    variables={"$close": "收盘价"}
)
```

**结果**：✅ 因子构建成功，进入编码阶段

---

#### 阶段3：因子编码（Factor Coding）

**3.1 代码生成**

系统将因子表达式转换为可执行的Python代码：

```python
# 生成的 factor.py 代码
import pandas as pd
import numpy as np
from qlib.data import D
from alphaagent.components.coder.factor_coder.function_lib import (
    DELTA, TS_STD
)

# 加载数据
data = D.features(
    instruments="all",
    fields=["$close"],
    start_time="2015-01-01",
    end_time="2019-12-31"
)

# 计算因子
close = data["$close"]
factor_value = DELTA(close, 20) / TS_STD(close, 20)

# 保存结果
factor_value.to_hdf("result.h5", key="factor")
```

**3.2 代码执行**

系统在隔离的工作空间中执行代码：

```python
workspace_path = "/workspace/factor_volatility_adjusted_momentum_001"
subprocess.run(
    f"python {workspace_path}/factor.py",
    cwd=workspace_path,
    timeout=300
)
```

**执行结果检查**：

```python
# 检查输出文件
if workspace_path / "result.h5" exists:
    factor_df = pd.read_hdf("result.h5")
    
    # 检查数据有效性
    if factor_df.isna().all().all():
        # 全NaN，因子无效
        execution_feedback = "因子计算结果全为NaN"
        return False
    else:
        # 因子有效
        execution_feedback = "Execution succeeded"
        return True
```

**结果**：✅ 代码执行成功，因子值计算完成

---

#### 阶段4：因子回测（Factor Backtest）

**4.1 回测配置**

系统配置回测参数：

```python
backtest_config = {
    "train_start": "2015-01-01",
    "train_end": "2019-12-31",
    "test_start": "2020-01-01",
    "test_end": "2023-12-31",
    "topk": 50,  # 选择前50只股票
    "n_drop": 5,  # 每5天调仓
}
```

**4.2 回测执行**

系统使用Qlib执行回测：

```python
# 使用Qlib的因子回测框架
from qlib.contrib.evaluate import backtest

result = backtest(
    factor_data=factor_df,
    **backtest_config
)
```

**4.3 回测结果**

系统计算关键指标：

```python
result = {
    "IC": 0.023,  # 信息系数
    "ICIR": 0.45,  # IC信息比率
    "RankIC": 0.031,  # 排序IC
    "RankICIR": 0.52,  # 排序ICIR
    "1day.excess_return_without_cost.annualized_return": 0.15,  # 年化收益
    "1day.excess_return_without_cost.information_ratio": 1.2,  # 信息比率
    "1day.excess_return_without_cost.max_drawdown": -0.08,  # 最大回撤
}
```

**结果判断**：

```python
# 判断因子质量
if result["RankIC"] > 0.02 and result["ICIR"] > 0.3:
    factor_quality = "High-Quality"  # 优质因子
elif result["RankIC"] > 0:
    factor_quality = "Valid"  # 有效因子
else:
    factor_quality = "Poor"  # 表现不佳
```

**结果**：✅ RankIC=0.031 > 0.02，因子质量：High-Quality

---

#### 阶段5：反馈生成（Feedback Generation）

**5.1 结果对比**

系统对比当前因子与历史最佳因子（SOTA）：

```python
# 当前结果
current_result = {
    "IC": 0.023,
    "ICIR": 0.45,
    "RankIC": 0.031,
    "annualized_return": 0.15,
}

# SOTA结果（假设是Alpha158基准）
sota_result = {
    "IC": 0.018,
    "ICIR": 0.38,
    "RankIC": 0.025,
    "annualized_return": 0.12,
}

# 生成对比表
comparison_df = pd.DataFrame({
    "Current Result": current_result,
    "SOTA Result": sota_result,
})
# 标记哪个更好
comparison_df["Better"] = comparison_df.apply(
    lambda row: "Current" if row["Current Result"] > row["SOTA Result"] 
                else "SOTA", axis=1
)
```

**5.2 LLM 生成反馈**

系统调用LLM生成反馈：

**Prompt 示例**：

```
基于以下信息生成反馈：
- 假设：高波动率往往意味着市场过度反应...
- 因子表达式：DELTA($close, 20) / TS_STD($close, 20)
- 回测结果对比：
  Current Result: IC=0.023, ICIR=0.45, RankIC=0.031, Return=0.15
  SOTA Result: IC=0.018, ICIR=0.38, RankIC=0.025, Return=0.12

请提供：
- Observations: 对结果的观察
- Feedback for Hypothesis: 对假设的评价
- New Hypothesis: 基于结果的新假设建议（如有）
- Reasoning: 决策理由
- Replace Best Result: 是否替换最佳结果（yes/no）
```

**LLM 反馈响应**：

```json
{
  "Observations": "因子在训练集上表现良好，RankIC=0.031超过基准。波动率调整机制有效，年化收益15%优于基准12%。",
  "Feedback for Hypothesis": "假设得到验证。波动率确实可以作为噪音过滤工具，提高动量因子的有效性。",
  "New Hypothesis": "可以进一步探索不同时间窗口的波动率计算，或者结合成交量信息增强因子。",
  "Reasoning": "当前因子在多个指标上优于基准，建议保留并继续优化。",
  "Replace Best Result": "yes"
}
```

**5.3 反馈对象创建**

系统创建 `HypothesisFeedback` 对象：

```python
feedback = HypothesisFeedback(
    observations="因子在训练集上表现良好...",
    hypothesis_evaluation="假设得到验证...",
    new_hypothesis="可以进一步探索不同时间窗口...",
    reason="当前因子在多个指标上优于基准...",
    decision=True  # 替换最佳结果
)
```

**结果**：✅ 反馈生成成功，因子被标记为新的最佳结果

---

#### 阶段6：知识库更新（Knowledge Base Update）

**6.1 因子入库**

系统将成功因子添加到因子库：

```python
# 添加到因子正则化器的因子库
factor_regulator.add_factor(
    factor_name="volatility_adjusted_momentum",
    factor_expression="DELTA($close, 20) / TS_STD($close, 20)"
)

# 保存到因子库CSV
factor_regulator.save_factor_zoo("factor_zoo/alphaagent_factors.csv")
```

**6.2 历史记录更新**

系统更新 `Trace` 对象：

```python
trace.hist.append((
    hypothesis,  # 假设
    experiment,  # 实验（包含因子和回测结果）
    feedback     # 反馈
))
```

**结果**：✅ 知识库更新完成，为下一轮迭代提供参考

---

#### 异常情况处理示例

**情况1：语法解析失败**

**场景**：LLM生成的表达式有语法错误

```python
# LLM生成
expr = "DELTA($close, 20) / TS_STD($close"  # 缺少右括号

# 解析检查
try:
    ast = parse_expression(expr)
except ValueError as e:
    # 解析失败
    is_parsable = False
    error_message = "Failed to parse expression: Missing closing parenthesis"
```

**处理**：
- 系统记录错误信息
- 将错误信息加入Prompt反馈给LLM
- LLM重新生成表达式
- 最多重试3次

**情况2：正则化检查失败（重复度过高）**

**场景**：生成的因子与Alpha101中的因子过于相似

```python
# 生成的表达式
expr = "TS_MAX($high, 20) - TS_MIN($low, 20)"  # 与Alpha101中的因子重复

# 正则化检查
duplicated_subtree_size = 12  # 超过阈值8
matched_alpha = "TS_MAX($high, 20) - TS_MIN($low, 20)"  # Alpha101中的因子

# 判断
if duplicated_subtree_size > 8:
    is_acceptable = False
    feedback = f"因子与已有因子过于相似，最大公共子树大小为{duplicated_subtree_size}，超过阈值8。匹配到的因子：{matched_alpha}"
```

**处理**：
- 系统生成重复度反馈
- 将反馈加入Prompt，要求LLM生成更独特的因子
- LLM重新生成，尝试不同的函数组合或参数

**情况3：因子计算失败（全NaN）**

**场景**：因子表达式语法正确，但计算结果全为NaN

```python
# 执行因子计算
factor_df = execute_factor_code()

# 检查结果
if factor_df.isna().all().all():
    execution_feedback = "因子计算结果全为NaN，可能原因：除零错误、数据不足、函数参数错误"
```

**处理**：
- 系统记录失败原因
- 在下一轮假设生成时，将失败信息作为反馈
- LLM根据反馈调整假设或因子设计

**情况4：回测表现不佳（IC为负）**

**场景**：因子计算成功，但回测IC为负

```python
# 回测结果
result = {
    "IC": -0.015,  # 负IC，方向反了
    "RankIC": -0.012,
}

# 反馈生成
feedback = {
    "Observations": "因子IC为负，表明因子方向与收益方向相反",
    "Feedback for Hypothesis": "假设可能需要调整方向，或者考虑使用负号反转因子",
    "New Hypothesis": "尝试反转因子方向：使用 -1 * 原因子，或者重新设计假设",
    "Replace Best Result": "no"
}
```

**处理**：
- 系统生成反馈，指出方向问题
- 在下一轮迭代中，LLM根据反馈调整因子方向
- 例如：将 `DELTA($close, 20)` 改为 `-DELTA($close, 20)`

**情况5：因子质量中等（需要优化）**

**场景**：因子有效但表现一般

```python
# 回测结果
result = {
    "RankIC": 0.015,  # 略大于0，但小于0.02阈值
    "ICIR": 0.25,     # 低于0.3阈值
}

# 反馈生成
feedback = {
    "Observations": "因子有效但表现一般，RankIC=0.015略低于优质因子阈值0.02",
    "Feedback for Hypothesis": "假设方向正确，但因子设计可能需要优化参数或增加特征",
    "New Hypothesis": "可以尝试：1) 调整时间窗口（如改为15日或25日）；2) 增加成交量信息；3) 使用更复杂的波动率计算方法",
    "Replace Best Result": "no"
}
```

**处理**：
- 因子被标记为"Valid"但非"High-Quality"
- 反馈中包含优化建议
- 在后续迭代中，LLM可以基于这些建议生成改进版本

---

#### 完整迭代循环示例

**第1轮迭代**：

```
输入: "基于波动率调整的动量因子"
假设: "高波动率意味着过度反应，波动率调整后的动量更有效"
因子: "DELTA($close, 20) / TS_STD($close, 20)"
结果: RankIC=0.031, ICIR=0.45 ✅ High-Quality
反馈: "假设得到验证，因子表现良好"
决策: 替换最佳结果 ✅
```

**第2轮迭代**（基于第1轮反馈）：

```
输入: 第1轮的反馈 + 新假设建议
假设: "可以结合成交量信息，构建价量结合的波动率调整动量因子"
因子: "DELTA($close, 20) * RANK($volume) / TS_STD($close, 20)"
结果: RankIC=0.028, ICIR=0.42
反馈: "加入成交量后IC略有下降，可能成交量信息引入噪音"
决策: 不替换最佳结果
```

**第3轮迭代**（继续优化）：

```
输入: 前两轮的反馈
假设: "尝试不同的波动率计算方法，使用滚动窗口内的价格变化标准差"
因子: "DELTA($close, 20) / TS_STD(DELTA($close, 1), 20)"
结果: RankIC=0.035, ICIR=0.51 ✅ 新的最佳结果
反馈: "使用价格变化的标准差作为波动率代理，效果更好"
决策: 替换最佳结果 ✅
```

---

#### 统计信息示例

基于上述流程，在一次完整的实验（10 Trials, 5 Rounds/Trial）中：

- **生成总量**: 150+ 个因子表达式
  - 每轮LLM生成1-3个因子
  - 10 Trials × 5 Rounds × 平均2个因子/轮 = 100个
  - 加上重试和优化，总计150+

- **有效因子**: 64个
  - 通过语法检查：~120个
  - 通过正则化检查：~80个
  - 计算结果非全NaN：~70个
  - 最终有效：64个

- **优质因子**: 23个
  - 筛选标准：RankIC > 0.02 且与Alpha158相关性 < 0.7
  - 64个有效因子中，23个达到优质标准

- **因子类型分布**：
  - 价量相关性因子：~40%（26个）
  - 波动率修正动量：~30%（19个）
  - 市场微结构：~20%（13个）
  - 其他：~10%（6个）

---

#### 总结

通过上述完整流程，AlphaAgent实现了：

1. **自动化假设生成**：从用户输入到结构化假设
2. **智能因子构建**：从假设到可执行表达式，包含多重验证
3. **自动回测评估**：计算关键指标，判断因子质量
4. **反馈驱动优化**：基于结果生成反馈，指导下一轮改进
5. **知识积累**：将成功因子入库，避免重复生成

整个过程形成了一个完整的"假设-实现-反馈"闭环，实现了因子挖掘的自动化和智能化。

## 🎯 项目特点

1. **自动化程度高**：从假设到因子到回测全流程自动化
2. **可解释性强**：基于金融理论生成可解释因子
3. **抗衰减机制**：通过正则化避免因子重复和过拟合
4. **迭代优化**：基于反馈持续改进因子性能
5. **易于扩展**：模块化设计，易于添加新场景和组件

## 📚 相关资源

- **论文链接**: https://arxiv.org/abs/2502.16789
- **Qlib项目**: https://github.com/microsoft/qlib
- **RD-Agent**: https://github.com/microsoft/RD-Agent（AlphaAgent基于此项目）

## 🔧 开发指南

### 项目结构设计原则

1. **核心框架**（core/）：定义抽象接口和基础框架
2. **组件实现**（components/）：实现具体功能组件
3. **场景适配**（scenarios/）：针对不同场景的适配实现
4. **应用入口**（app/）：提供用户接口和命令行工具

### 扩展新功能

1. **添加新场景**：在 `scenarios/` 下创建新场景目录
2. **添加新组件**：在 `components/` 下实现新组件
3. **添加新评估器**：继承 `core/evaluation.py` 中的Evaluator类
4. **添加新编码器**：继承 `core/developer.py` 中的Developer类

## 📄 许可证

MIT License（见 LICENSE 文件）

---

**注意**：本文档基于代码结构分析生成，具体实现细节请参考源代码和官方文档。


---

## 🧩 mini-SWE-agent 项目概览（对比理解用）

> 这一节是基于 `/home/tjxy/quantagent/mini-se-agent` 仓库代码结构整理，用来和 AlphaAgent 做“Agent 框架层面”的对比理解。  
> 核心思路：mini-SWE-agent 做的是“代码问题求解”（SWE-bench / GitHub issue），AlphaAgent 做的是“量化因子挖掘”，但二者在 **Agent-Model-Environment-Run** 这一层有很多共通的设计思想。

### 📖 项目简介

**mini-SWE-agent（mini-swe-agent）** 是一个极简的 AI 软件工程 Agent，通过让大模型只使用一个工具——**bash**——来解决 GitHub issue / SWE-bench 这类代码问题。  

- **目标**：在保证效果（SWE-bench verified 上 >74% 解决率）的前提下，把 Agent 框架压缩到 **100 行级别的核心逻辑**，方便研究、调参和复现。
- **核心理念**：
  - Agent 框架尽量简单，把“智能”交给大模型本身
  - 所有动作都通过 `subprocess.run` 的一次性 shell 命令完成，不维护长连接 shell session
  - 历史完全线性：所有轮次的 messages 直接累积，方便调试与微调

项目主代码包位于：`mini-se-agent/src/minisweagent/`。

### 🏗️ 顶层架构

mini-SWE-agent 的核心抽象和 AlphaAgent 很像，也可以概括为：

- **Model**：大语言模型接口
- **Environment**：执行环境（本地 bash / docker / singularity 等）
- **Agent**：控制循环 + 与 LLM 对话 + 解析并执行动作
- **Run scripts**：命令行入口（CLI），拼装 `Agent + Model + Environment`

#### 1. 顶层协议与全局配置（`minisweagent/__init__.py`）

这一文件定义了三个关键 Protocol（接口约束）：

- `Model`：
  - 属性：`config`, `cost`, `n_calls`
  - 方法：
    - `query(self, messages: list[dict[str, str]], **kwargs) -> dict`
    - `get_template_vars(self) -> dict[str, Any]`
- `Environment`：
  - 属性：`config`
  - 方法：
    - `execute(self, command: str, cwd: str = "") -> dict[str, str]`
    - `get_template_vars(self) -> dict[str, Any]`
- `Agent`：
  - 属性：`model`, `env`, `messages`, `config`
  - 方法：
    - `run(self, task: str, **kwargs) -> tuple[str, str]`

同时，这里还负责：

- `__version__`（版本号）
- 全局配置目录：`global_config_dir = user_config_dir("mini-swe-agent")`
- 全局 `.env` 配置文件：`global_config_file = global_config_dir / ".env"`（通过 `dotenv.load_dotenv` 自动加载）
- 默认 logger：`minisweagent.utils.log.logger`

可以把它理解为：

- AlphaAgent 的 `alphaagent/core` + `.env` 加载逻辑的结合体
- 但 mini 把 **Model / Environment / Agent** 这三种角色通过 `typing.Protocol` 抽象出来，方便替换实现。

### 🧠 Agent 层：DefaultAgent 控制循环

**位置**：`minisweagent/agents/default.py`  
**核心类**：`DefaultAgent`

和 AlphaAgent 的 `AlphaAgentLoop` 相比，`DefaultAgent` 是一个更“极简”的单任务 Agent：

- **配置类 `AgentConfig`（dataclass）**：
  - `system_template`：System Prompt，默认是一个通用“你是一个万能助手”
  - `instance_template`：任务 Prompt 模板（关键）
    - 要求模型输出“一个三引号包裹的 shell 命令”
    - 命令执行的输出第一行如果是 `'COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT'` 或 `'MINI_SWE_AGENT_FINAL_OUTPUT'`，则视为任务完成
  - `timeout_template`：命令超时后的反馈模板
  - `format_error_template`：模型输出格式错误时的反馈
  - `action_observation_template`：把命令执行结果包装成 Observation 的模板
  - `action_regex`：用于从 LLM 输出中抽取 shell 命令的正则（默认匹配 ```bash ... ```）
  - `step_limit` / `cost_limit`：迭代步数 / 成本上限（与模型的 `n_calls` 和 `cost` 联动）

- **运行主循环 `run(self, task: str, **kwargs)`**：
  1. 组装模板变量：`extra_template_vars |= {"task": task, **kwargs}`
  2. 重置 `messages`
  3. 加入 system 消息（渲染 `system_template`）
  4. 加入 user 消息（渲染 `instance_template`）
  5. `while True`：
     - 调用 `self.step()`
     - 捕获 `NonTerminatingException`（格式错误、超时等），把异常文本作为新的 user 消息反馈给模型
     - 捕获 `TerminatingException`（已提交结果、超限等），返回 `(异常类名, 异常文案)`

- **单步逻辑 `step()`**：
  - `response = self.query()`：调用模型
  - `output = self.get_observation(response)`：解析 action、执行命令、生成观察

- **模型调用 `query()`**：
  - 先检查 `step_limit` 和 `cost_limit`（读取 `model.n_calls`、`model.cost`）
  - 调用 `self.model.query(self.messages)`
  - 将返回的 `response` 作为 assistant 消息加入 `messages`

- **动作解析与执行**：
  - `parse_action(response)`：
    - 用 `action_regex` 从 `response["content"]` 中抽取 ```bash ... ``` 段
    - 如果不等于 1 条，抛出 `FormatError`，触发下一轮带错误信息的 Prompt
  - `execute_action(action)`：
    - 调用 `env.execute(action["action"])`
    - 捕获超时异常（`TimeoutError`, `subprocess.TimeoutExpired`），封装为 `ExecutionTimeoutError`
    - 执行成功后调用 `has_finished(output)` 来检测是否已经完成任务
  - `has_finished(output)`：
    - 检查命令输出的第一行是否是结束标记
    - 如果是，则抛出 `Submitted` 异常，结束整个 Agent

**可以看到：**

- mini-SWE-agent 的 Agent 主循环非常“裸”：  
  - 不做复杂工具调度  
  - 不维护 shell session  
  - 不做多 Agent 协作  
- 复杂度集中在：**Prompt 设计 + bash 命令的“自我规划能力”** 上。

### 🌍 Environment 层：本地 / 容器执行环境

**核心文件**：

- `minisweagent/environments/local.py`：本地环境
  - `LocalEnvironmentConfig`（dataclass）：`cwd`, `env`, `timeout`
  - `execute(command, cwd="", timeout=None)`：
    - 使用 `subprocess.run` 直接执行 shell 命令
    - `cwd`：优先使用传入 cwd，其次配置中的 cwd，最后 `os.getcwd()`
    - 返回 `{"output": stdout+stderr, "returncode": returncode}`
  - `get_template_vars()`：
    - 返回 `asdict(self.config) | platform.uname()._asdict() | os.environ`
    - 这部分会注入到 Prompt 模板变量里，让模型知道系统环境信息

- `minisweagent/environments/docker.py` / `singularity.py`：
  - 提供容器化执行环境，相当于把 `subprocess.run` 的目标换成 `docker exec` / `singularity exec`

**对比 AlphaAgent**：

- AlphaAgent 的“执行环境”更多是 Qlib + Python 回测框架
- mini-SWE-agent 的 Environment 是“操作系统级别的 shell 环境”，用于跑 git / pytest / 编辑器 / 代码等命令

### 🧮 Model 层：基于 litellm 的统一模型接口

**核心文件**：`minisweagent/models/litellm_model.py`  
**核心类**：`LitellmModel`

- **配置类 `LitellmModelConfig`**：
  - `model_name`: 模型标识（例如 `gpt-4.1`, `openai/gpt-4.1-mini`, `claude-3.7-sonnet` 等，具体由 litellm 决定）
  - `model_kwargs`: 传给 litellm 的额外参数（温度、max_tokens 等）
  - `litellm_model_registry`: 模型注册文件路径，用于配置本地模型或自定义路由
  - `set_cache_control`: 是否对消息设置 cache control 标记（部分模型需要）
  - `cost_tracking`: 成本跟踪模式（`default` or `ignore_errors`）
  - `skip_global_stats`: 是否跳过全局统计（用于一些辅助模型）

- **请求重试机制 `_query()`**：
  - 使用 `tenacity.retry` 装饰：
    - 最多重试 `MSWEA_MODEL_RETRY_STOP_AFTER_ATTEMPT`（默认 20 次）
    - 指数退避等待（`wait_exponential(multiplier=1, min=4, max=60)`）
    - 在非致命异常（网络错误、限流等）上自动重试
  - 底层调用 `litellm.completion(model=self.config.model_name, messages=messages, ...)`

- **公开方法 `query(messages: list[dict[str, str]], **kwargs)`**：
  - 如果配置了 `set_cache_control`，先对 messages 做 cache-control 标记
  - 调用 `_query`，得到 litellm response
  - 如果未 `skip_global_stats`：
    - 尝试用 `litellm.cost_calculator.completion_cost` 计算花费
    - 累加到 `self.cost`，并更新全局 `GLOBAL_MODEL_STATS`
  - 返回：
    - `{"content": response.choices[0].message.content or "", "extra": {"response": response.model_dump()}}`

这层相当于：

- 把各种模型（OpenAI / Anthropic / OpenRouter / 本地模型等）统一封装在 litellm 之上
- 对上暴露统一的 `Model` 协议接口

### 🚀 Run 层：`mini` CLI 入口

**位置**：`minisweagent/run/mini.py`  
**入口脚本**：在 `pyproject.toml` 中注册：

- `mini = "minisweagent.run.mini:app"`
- `mini-swe-agent = "minisweagent.run.mini:app"`
- `mini-extra = "minisweagent.run.mini_extra:main"`
- `mini-se = "minisweagent.se.run:app"`

**命令行接口（Typer 应用）**：

- Typer app：`app = typer.Typer(rich_markup_mode="rich")`
- 默认配置路径：
  - `DEFAULT_CONFIG = builtin_config_dir / "mini.yaml"`（可被环境变量 `MSWEA_MINI_CONFIG_PATH` 覆盖）
  - `DEFAULT_OUTPUT = global_config_dir / "last_mini_run.traj.json"`
- `main()` 参数（核心）：
  - `visual`: `-v/--visual`，是否使用 Textual 可视化 UI
  - `model_name`: `-m/--model`，指定模型名字
  - `model_class`: 指定使用哪种模型实现类（如 `anthropic` 或 `minisweagent.models.anthropic.AnthropicModel`）
  - `task`: `-t/--task`，任务描述（可以直接传 issue 描述）
  - `yolo`: 不经过确认直接执行
  - `cost_limit`: 成本限制
  - `config_spec`: 配置文件路径
  - `output`: 轨迹保存路径
  - `exit_immediately`: Agent 想结束时是否直接退出（跳过确认）

**执行流程**：

1. `configure_if_first_time()`：首次运行时做一些初始化（如生成默认配置）
2. 解析配置文件：`config = yaml.safe_load(config_path.read_text())`
3. 如未提供 `task`，用 `PromptSession`（带历史记录）交互式询问任务
4. 根据命令行参数更新配置中的 `agent`、`model` 字段（如 `cost_limit`、`model_class` 等）
5. 创建模型：`model = get_model(model_name, config.get("model", {}))`
6. 创建环境：`env = LocalEnvironment(**config.get("env", {}))`
7. 选择 Agent 类：
   - `InteractiveAgent`：简单 REPL 界面
   - `TextualAgent`：基于 Textual 的可视化 UI
8. 运行：
   - `agent = agent_class(model, env, **config.get("agent", {}))`
   - `exit_status, result = agent.run(task)`
9. 无论成功/失败，都将轨迹保存到 `output`：`save_traj(agent, output, exit_status=..., result=..., extra_info=...)`

这相当于 AlphaAgent 的：

- `alphaagent/app/cli.py` + `alphaagent/app/qlib_rd_loop/factor_mining.py` 的组合版本

### 📂 项目目录总览（简化版）

结合目录结构与上文，可以用一张树概括 mini-SWE-agent：

```bash
mini-se-agent/
├── pyproject.toml                  # 项目配置 & 依赖 & entrypoints
├── README.md                       # 官方说明
├── src/
│   └── minisweagent/
│       ├── __init__.py            # 版本号、全局配置、Model/Env/Agent 协议
│       ├── agents/                # 各种 Agent 实现（默认/交互式/Textual UI）
│       │   ├── default.py         # DefaultAgent：100 行主循环核心
│       │   ├── interactive.py
│       │   └── interactive_textual.py
│       ├── environments/          # 执行环境（local / docker / singularity 等）
│       │   ├── local.py           # LocalEnvironment：直接在本机执行 bash
│       │   ├── docker.py
│       │   └── singularity.py
│       ├── models/                # 模型接口与具体实现（litellm / anthropic / openrouter 等）
│       │   ├── __init__.py        # get_model 工厂
│       │   ├── litellm_model.py   # LitellmModel：统一封装 LLM 调用
│       │   ├── anthropic.py
│       │   ├── openrouter_model.py
│       │   └── utils/...
│       ├── run/                   # 运行脚本（CLI 入口）
│       │   ├── mini.py            # `mini` 命令主入口
│       │   ├── mini_extra.py      # 扩展命令
│       │   ├── github_issue.py    # 针对 GitHub issue 的专用入口
│       │   └── inspector.py       # 轨迹浏览器
│       ├── se/                    # 与 SWE-bench / 评测相关的逻辑
│       │   ├── run.py             # `mini-se` 入口
│       │   ├── runner.py
│       │   ├── eval/...
│       │   └── operators/...
│       └── utils/                 # 日志、保存轨迹、通用工具等
│
└── tests/                         # 单元测试
```

### 🔍 与 AlphaAgent 的“心智模型”对齐

从你的使用视角看 mini-SWE-agent，可以把它类比为：

- **AlphaAgent 的“QLib 场景 + 因子挖掘主循环”**  
  ↔ **mini 的“代码库 + bash 环境 + issue 求解循环”**
- 在 AlphaAgent 里：
  - `HypothesisGen` + `FactorAgent` + `EvalAgent` 组成一个复杂多阶段循环
  - 执行环境是 Qlib 回测 & Python 代码
- 在 mini-SWE-agent 里：
  - 一个 `DefaultAgent` 就是完整的控制循环
  - 执行环境是 shell，模型通过 `bash` 自己调用 git / 编辑器 / 测试工具来修改代码并验证

如果你之后想把 “AlphaAgent 的量化 workflow” 和 “mini-SWE-agent 的代码修复 workflow” 结合起来，可以大致参考：

- 让 AlphaAgent 负责：**提出“怎么改策略/模型/因子”的高层想法**
- 让 mini-SWE-agent 负责：**在代码仓库里按这些想法真实改代码、跑测试、开 PR**

这样二者的定位就不会冲突，而是一个偏“金融研究 Agent”，一个偏“工程落地 Agent”。

