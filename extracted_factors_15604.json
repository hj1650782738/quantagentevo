{
  "metadata": {
    "created_at": "2026-01-14T20:02:36.655783",
    "source": "extracted from all_factors_library.json (line 15604+)",
    "total_factors": 143,
    "version": "1.0",
    "last_updated": "2026-01-14T20:03:33.054552",
    "quality_standard": "RankIC > 0.02 AND max_correlation_with_alpha158 < 0.7"
  },
  "factors": {
    "1aa1d6223aa7c3e4": {
      "factor_id": "1aa1d6223aa7c3e4",
      "factor_name": "Price_Reversal_10D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10)\" # Your output factor expression will be filled in here\n    name = \"Price_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "The classic 10-day price reversal factor, calculated as the negative of the percentage change in closing price over the last 10 trading days. It captures short-term overreaction by assuming that stocks with the largest recent declines are likely to rebound.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.399108",
      "updated_at": "2026-01-14T20:03:33.054180"
    },
    "3cba664ff2fba0bd": {
      "factor_id": "3cba664ff2fba0bd",
      "factor_name": "Volatility_Adjusted_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A volatility-adjusted reversal factor that scales the 10-day price change by the standard deviation of daily returns. This identifies stocks where the 10-day movement is statistically significant relative to its typical volatility, filtering out noise in high-volatility stocks.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.431935",
      "updated_at": "2026-01-14T20:03:33.054192"
    },
    "c45771cd18f826ae": {
      "factor_id": "c45771cd18f826ae",
      "factor_name": "Relative_Strength_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) + RANK(100 - RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Strength_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day reversal logic with the Relative Strength Index (RSI). It identifies mean-reversion candidates by looking for stocks that have both a negative 10-day return and an oversold RSI signal, smoothed by a cross-sectional rank.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 1,
      "hypothesis": "Hypothesis: The 10-day price reversal factor, defined as the negative of the cumulative return over the past 10 trading days, predicts positive future returns due to short-term overreaction in equity prices.\n                Concise Observation: In daily price-volume data, stocks that experience extreme price movements over a two-week window often exhibit a correction pattern in the following days as buying/selling pressure stabilizes.\n                Concise Justification: Short-term mean reversion is driven by market microstructure effects and behavioral biases where investors overreact to news, leading to price 'overshooting' that is eventually corrected by arbitrageurs.\n                Concise Knowledge: If an asset's price deviates significantly from its short-term moving average due to liquidity shocks or investor overreaction, it tends to revert to its mean; when the 10-day cumulative return is significantly negative, the expected return for the subsequent period is higher.\n                concise Specification: The factor is calculated as the arithmetic return from day t-10 to day t-1, multiplied by -1; it assumes a static 10-day lookback period and uses daily close prices from the daily_pv.h5 dataset.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0050649850625735,
        "ICIR": 0.0325933532563577,
        "RankIC": 0.0201763172753469,
        "RankICIR": 0.1346362366384694,
        "annualized_return": 0.0535453711199448,
        "information_ratio": 0.6417164141859728,
        "max_drawdown": -0.1271795636703074
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T16:57:26.463809",
      "updated_at": "2026-01-14T20:03:33.054196"
    },
    "f7298e462456ae82": {
      "factor_id": "f7298e462456ae82",
      "factor_name": "Vol_Weighted_Reversal_10D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) * (1 - TS_CORR(TS_PCTCHANGE($close, 1), TS_PCTCHANGE($volume, 1), 10)))\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies mean-reversion opportunities by scaling the 10-day price return by the inverse of the price-volume correlation. It targets stocks where the downward trend lacks volume conviction, suggesting exhaustion rather than a fundamental regime shift.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.183234",
      "updated_at": "2026-01-14T20:03:33.054199"
    },
    "502409b41bea1fbd": {
      "factor_id": "502409b41bea1fbd",
      "factor_name": "Exhaustion_Reversal_Score_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) * TS_RANK(INV($volume + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Reversal_Score_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the volume-price divergence hypothesis. It calculates the 10-day reversal and weights it by the time-series rank of the inverse volume, prioritizing reversals that occur on declining or low relative volume.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.215328",
      "updated_at": "2026-01-14T20:03:33.054201"
    },
    "c019a2d0550d0b20": {
      "factor_id": "c019a2d0550d0b20",
      "factor_name": "Divergent_Mean_Reversion_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_PCTCHANGE($close, 10), 20) / (1 + ABS(TS_CORR($close, $volume, 10)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_PCTCHANGE($close, 10), 20) / (1 + ABS(TS_CORR($close, $volume, 10)))\" # Your output factor expression will be filled in here\n    name = \"Divergent_Mean_Reversion_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between price direction and volume intensity. It uses the residual of price returns after controlling for volume-weighted trends, specifically looking for negative returns that are not supported by high volume growth.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 10-day volume-weighted price reversal factor, which scales the 10-day price change by the inverse of the volume-price correlation, identifies high-conviction mean-reversion opportunities by filtering out high-volume trend continuations.\n                Concise Observation: The previous 10-day reversal model yielded a low IC of 0.0051, suggesting that simple price action fails to distinguish between temporary overreactions and sustained trend breakdowns.\n                Concise Justification: Volume serves as a proxy for investor conviction; a price reversal signal is more robust when the preceding trend lacks volume support (divergence), whereas high-volume moves often signify the start of a new regime where mean reversion fails.\n                Concise Knowledge: If a short-term price decline is accompanied by low or decreasing volume, it indicates liquidity-driven exhaustion rather than fundamental repricing; when price and volume are positively correlated during a drawdown, the reversal signal is stronger than when they are negatively correlated (which suggests persistent selling pressure).\n                concise Specification: The factor is defined as the negative 10-day price return multiplied by (1 - correlation(price_change, volume_change) over 10 days); it uses $close and $volume from daily_pv.h5 with a fixed 10-day sliding window.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0063476932561052,
        "ICIR": 0.0418092754336942,
        "RankIC": 0.0220300176976462,
        "RankICIR": 0.1477750147947399,
        "annualized_return": 0.0818836035010969,
        "information_ratio": 0.886003026420623,
        "max_drawdown": -0.1480094700773967
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:02:57.246709",
      "updated_at": "2026-01-14T20:03:33.054203"
    },
    "e1eac2984c65b418": {
      "factor_id": "e1eac2984c65b418",
      "factor_name": "Volume_Climax_Reversal_20D",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) * ABS(TS_ZSCORE($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"Volume_Climax_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals that are conditioned on volume climax or exhaustion. By multiplying the negative 10-day return by the absolute Z-score of volume over 20 days, the signal is amplified during periods of extreme capitulation (high volume) or lack of conviction (low volume), while being suppressed during normal trading activity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.115461",
      "updated_at": "2026-01-14T20:03:33.054206"
    },
    "33fbcf714d3a70d6": {
      "factor_id": "33fbcf714d3a70d6",
      "factor_name": "Gated_Exhaustion_Reversal_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * RANK(ABS(TS_ZSCORE($volume, 20)))\" # Your output factor expression will be filled in here\n    name = \"Gated_Exhaustion_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by isolating price drawdowns that occur under extreme volume conditions. It uses the absolute volume Z-score as a non-linear weighting mechanism to filter for 'blow-off' or 'exhaustion' states, then applies a cross-sectional rank to ensure the signal is focused on the most extreme relative opportunities.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.147232",
      "updated_at": "2026-01-14T20:03:33.054209"
    },
    "4ed61117b0de26e1": {
      "factor_id": "4ed61117b0de26e1",
      "factor_name": "NonLinear_Volume_MeanReversion",
      "factor_expression": "(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELAY($close, 10) - $close) / ($close + 1e-8) * POW(TS_ZSCORE($volume, 20), 2)\" # Your output factor expression will be filled in here\n    name = \"NonLinear_Volume_MeanReversion\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor strengthens the 10-day reversal signal when volume deviates significantly from its 20-day average. It specifically uses the square of the volume Z-score to create a parabolic weighting that aggressively penalizes 'normal' volume regimes and exponentially rewards extreme volume states where reversals are most likely.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 3,
      "hypothesis": "Hypothesis: The 10-day price reversal signal is most potent when conditioned on 'Volume Climax' or 'Volume Exhaustion' states, defined by the 20-day Z-score of volume, where extreme high volume (capitulation) or extreme low volume (lack of conviction) significantly increases the probability of a mean-reversion event.\n                Concise Observation: While the volume-weighted reversal improved the IR to 0.88, the increased Max Drawdown suggests that linear volume scaling fails to distinguish between 'orderly' selling (trend continuation) and 'extreme' liquidity events (reversal points).\n                Concise Justification: Market bottoms are often formed through either a 'blow-off' top/bottom (high volume climax) or a 'quiet' bottom (low volume exhaustion). By using a Z-score to isolate these non-linear extremes, we filter out the noisy middle-ground where price trends are most persistent.\n                Concise Knowledge: If a 10-day price drawdown occurs with a volume Z-score > 2.0, it indicates a capitulation climax likely to bounce; if it occurs with a volume Z-score < -1.5, it indicates exhaustion of selling pressure; whereas moderate volume suggests a stable trend less likely to reverse.\n                concise Specification: The factor calculates the 10-day negative return and multiplies it by the absolute value of the 20-day volume Z-score (standardized volume); this effectively 'gates' the reversal signal to be strongest only when volume is at historical extremes relative to its own 20-day mean and standard deviation.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0044389021156041,
        "ICIR": 0.0304379454890426,
        "RankIC": 0.0196212960945804,
        "RankICIR": 0.1374380891037619,
        "annualized_return": 0.0124167129561371,
        "information_ratio": 0.1752998663532474,
        "max_drawdown": -0.1100906502849443
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:06:25.178734",
      "updated_at": "2026-01-14T20:03:33.054212"
    },
    "2ced7731281f6246": {
      "factor_id": "2ced7731281f6246",
      "factor_name": "Stretched_Reversal_Divergence_10D",
      "factor_expression": "(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($return, 20) + 1e-8)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Stretched_Reversal_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by scaling the negative 10-day return by its 20-day volatility and multiplying it by the 5-day change in the price-volume correlation. This captures 'stretched' price moves where the relationship between price and volume is weakening, indicating trend exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.343160",
      "updated_at": "2026-01-14T20:03:33.054215"
    },
    "a539c30693a56101": {
      "factor_id": "a539c30693a56101",
      "factor_name": "Volatility_Scaled_Exhaustion_Rank",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($close, 20) + 1e-8)) * RANK(DELTA(TS_CORR($close, $volume, 10), 5))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Scaled_Exhaustion_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that ranks the intensity of a price reversal. It combines the 10-day return normalized by 20-day volatility with the momentum of the price-volume correlation. It targets stocks where price moves are extreme relative to volatility and conviction (volume-price link) is shifting.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.376043",
      "updated_at": "2026-01-14T20:03:33.054217"
    },
    "6411ef0aaf297143": {
      "factor_id": "6411ef0aaf297143",
      "factor_name": "ZScore_Reversal_Conviction_10D",
      "factor_expression": "-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_ZSCORE(TS_SUM($return, 10), 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"ZScore_Reversal_Conviction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the 10-day reversal potential by calculating the Z-score of returns and weighting it by the change in price-volume correlation. It uses Z-scores to identify statistically significant 'stretched' moves and filters them by the divergence in volume flow conviction.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 4,
      "hypothesis": "Hypothesis: A 10-day price reversal is most predictive when the preceding price move is 'stretched' relative to its 20-day volatility and is accompanied by a positive divergence in the 10-day price-volume correlation trend.\n                Concise Observation: Previous attempts using volume Z-scores as symmetric multipliers failed to capture alpha because they ignored the direction of volume flow and the underlying price volatility context, though they successfully reduced drawdown.\n                Concise Justification: A simple Z-score doesn't distinguish if volume is supporting the trend or the reversal. By using the change in price-volume correlation (divergence) rather than absolute volume levels, we identify when the 'conviction' of the current trend is fading, regardless of whether the absolute volume is high or low.\n                Concise Knowledge: If a price decline occurs with a decreasingly negative price-volume correlation, it indicates that selling pressure is losing its relationship with price movement; when this divergence is scaled by the asset's 20-day volatility, the signal distinguishes between noise and a true structural exhaustion point.\n                concise Specification: The factor calculates the negative 10-day return, divided by the 20-day standard deviation of returns, and then multiplied by the 5-day change in the 10-day price-volume correlation (rolling_corr($close, $volume, 10).diff(5)); all inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039680920813739,
        "ICIR": 0.0302634705401683,
        "RankIC": 0.0183258117587928,
        "RankICIR": 0.1454452396695383,
        "annualized_return": 0.0474131795393531,
        "information_ratio": 0.7760585159013066,
        "max_drawdown": -0.075583014639641
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:12:56.408776",
      "updated_at": "2026-01-14T20:03:33.054220"
    },
    "d8579a842cf4ca6b": {
      "factor_id": "d8579a842cf4ca6b",
      "factor_name": "Composite_Momentum_Structural_5D",
      "factor_expression": "RANK(REGBETA($close, SEQUENCE(5), 5)) + RANK(COUNT($return > 0, 5)) - RANK(HIGHDAY($high, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGBETA($close, SEQUENCE(5), 5)) + RANK(COUNT($return > 0, 5)) - RANK(HIGHDAY($high, 5))\" # Your output factor expression will be filled in here\n    name = \"Composite_Momentum_Structural_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor integrates the 5-day price trend slope (REGBETA), the frequency of positive returns (COUNT), and the relative timing of the price high (HIGHDAY) to capture momentum persistence and structural exhaustion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.185969",
      "updated_at": "2026-01-14T20:03:33.054222"
    },
    "201b29ae566c3fdf": {
      "factor_id": "201b29ae566c3fdf",
      "factor_name": "Trend_Consistency_Extreme_Timing_5D",
      "factor_expression": "ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(REGBETA($close, SEQUENCE(5), 5)) + ZSCORE(LOWDAY($low, 5) - HIGHDAY($high, 5))\" # Your output factor expression will be filled in here\n    name = \"Trend_Consistency_Extreme_Timing_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite indicator measuring the synergy between trend direction and the internal rhythm of price extremes. It combines the 5-day price slope with the normalized distance between the occurrences of the 5-day high and low.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.220275",
      "updated_at": "2026-01-14T20:03:33.054225"
    },
    "677fe32db5e17012": {
      "factor_id": "677fe32db5e17012",
      "factor_name": "Breadth_Timing_Composite_5D",
      "factor_expression": "RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(COUNT($return > 0, 5)) * RANK(TS_RANK($close, 5)) + RANK(REGBETA($close, SEQUENCE(5), 5))\" # Your output factor expression will be filled in here\n    name = \"Breadth_Timing_Composite_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures short-term market strength by combining the breadth of positive price movements (upward frequency) with the relative position of the current price within its recent 5-day range, adjusted for trend slope.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between price trend slope, the frequency of positive price movements, and the relative timing of price extremes over a 5-day window can effectively capture short-term mean reversion or momentum persistence.\n                Concise Observation: Short-term returns are often driven by the synergy of trend direction (BETA), the consistency of that trend (CNTD), and the internal structural timing of price peaks and troughs (IMXD).\n                Concise Justification: Combining the slope of price (directional strength) with the count of positive days (breadth) and the location of extremes (rhythm) provides a more robust multi-dimensional view of price action than any single indicator alone.\n                Concise Knowledge: If a stock exhibits a positive price slope alongside a high frequency of upward moves and a late-occurring high point within a 5-day window, it indicates strong short-term momentum; conversely, early peaks followed by declining frequency of gains suggest exhaustion.\n                concise Specification: Define a composite factor using a 5-day lookback period that integrates the linear regression slope of $close, the difference between the mean of upward and downward indicator functions, and the normalized index distance between the 5-day high and low.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048724182796032,
        "ICIR": 0.0312186740842219,
        "RankIC": 0.0163852819697104,
        "RankICIR": 0.1054100621962677,
        "annualized_return": 0.0443724151898269,
        "information_ratio": 0.5076842935285993,
        "max_drawdown": -0.1835102749298475
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:15:58.253729",
      "updated_at": "2026-01-14T20:03:33.054227"
    },
    "d817e6e5d1c010ca": {
      "factor_id": "d817e6e5d1c010ca",
      "factor_name": "Trend_Stability_Composite_Factor",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(10), 10), 2)) - RANK(($high - $low) / ($open + 1e-8)) - RANK(TS_STD($return * $volume, 5) / (TS_MEAN(ABS($return * $volume), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_Composite_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies sustainable price trends by combining trend linearity (R-squared of price against time), relative intraday range (noise), and volume-weighted return dispersion. High values indicate a high-conviction, low-noise trend often associated with institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.117300",
      "updated_at": "2026-01-14T20:03:33.054229"
    },
    "12a138054c7457fa": {
      "factor_id": "12a138054c7457fa",
      "factor_name": "Clean_Trend_Quality_Index",
      "factor_expression": "RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(DELTA($close, 10) / (TS_MEAN($high - $low, 10) + 1e-8)) - RANK(TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Trend_Quality_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the trend quality hypothesis focusing on the ratio of directional persistence to intraday volatility. It rewards stocks where the 10-day price change is high relative to the average daily range, adjusted for volume stability.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.150807",
      "updated_at": "2026-01-14T20:03:33.054232"
    },
    "de72babf4b53b854": {
      "factor_id": "de72babf4b53b854",
      "factor_name": "Institutional_Accumulation_Score",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(10), 10)) * (1.0 - RANK(($high - $low) / (LOG($volume + 1.0) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Accumulation_Score\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'low noise' aspect of the hypothesis. It measures the linearity of the price trend (RSQR) and penalizes stocks with high 'friction' (intraday volatility relative to volume).",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 1,
      "hypothesis": "Hypothesis: The interaction between high trend stability (RSQR10), low relative intraday volatility (KLEN), and low volume-weighted price dispersion (WVMA5) identifies periods of sustainable price consolidation that precede positive excess returns.\n                Concise Observation: Market participants often distinguish between 'clean' trends and 'noisy' trends; factors like RSQR, KLEN, and WVMA provide a multi-dimensional view of trend quality by combining statistical fit, price action geometry, and liquidity-adjusted volatility.\n                Concise Justification: High R-squared values indicate a strong directional consensus, while low KLEN and WVMA suggest that this direction is being maintained with minimal unnecessary friction or emotional overreaction, signaling a high-conviction trend.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared) while simultaneously showing low noise in both intraday range and volume-weighted volatility, then the current price movement is likely driven by informed institutional accumulation rather than speculative noise.\n                concise Specification: The factor will be constructed as a composite score: Rank(RSQR10) - Rank(KLEN) - Rank(WVMA5), where RSQR10 is the 10-day price regression R-squared, KLEN is (High-Low)/Open, and WVMA5 is the 5-day rolling coefficient of variation of volume-weighted absolute returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0009612055017416,
        "ICIR": 0.0067580321139014,
        "RankIC": 0.0152117016055717,
        "RankICIR": 0.1050155469711695,
        "annualized_return": -0.0158237728471039,
        "information_ratio": -0.1691874207494996,
        "max_drawdown": -0.2817316968846134
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:20:27.183527",
      "updated_at": "2026-01-14T20:03:33.054234"
    },
    "bb649f19188ec110": {
      "factor_id": "bb649f19188ec110",
      "factor_name": "VW_Price_Slope_Divergence_5D",
      "factor_expression": "REGBETA($close, SEQUENCE(5), 5) - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"REGBETA($close, SEQUENCE(5), 5) - (TS_SUM((($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)) * $volume, 5) / TS_SUM($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"VW_Price_Slope_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the divergence between the 5-day price trend (regression slope) and the volume-weighted relative position of the price within its high-low range. A high price slope combined with a low volume-weighted position suggests a 'hollow' trend prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.000804",
      "updated_at": "2026-01-14T20:03:33.054236"
    },
    "57ed23d5978e1e44": {
      "factor_id": "57ed23d5978e1e44",
      "factor_name": "Conviction_Filtered_Trend_5D",
      "factor_expression": "RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(REGBETA($close, SEQUENCE(5), 5)) - RANK(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) * TS_MEAN($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Conviction_Filtered_Trend_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies trend exhaustion by comparing the cross-sectional rank of the 5-day price slope against the rank of the volume-weighted price location. Divergence between trend direction and volume-weighted support indicates potential reversals.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.034763",
      "updated_at": "2026-01-14T20:03:33.054239"
    },
    "89b598f9778770de": {
      "factor_id": "89b598f9778770de",
      "factor_name": "VW_Range_Position_Exhaustion_5D",
      "factor_expression": "($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"($close - (TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8))) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Range_Position_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the distance between the current close and the 5-day volume-weighted average price (VWAP) normalized by the range. It targets mean reversion by identifying when price moves too far from the volume-weighted conviction level relative to its 5-day trend.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 2,
      "hypothesis": "Hypothesis: The divergence between the 5-day price regression slope and the volume-weighted relative price position within the high-low range identifies short-term mean reversion opportunities more effectively than simple momentum counts.\n                Concise Observation: Previous attempts using 5-day return counts and price slopes yielded low IC (0.0049), likely because these variables are highly collinear and fail to account for the quality of price action relative to volume distribution.\n                Concise Justification: Volume-weighted positioning (VWAP-like metrics) acts as a 'conviction filter' for price trends. By measuring the distance between the close and the volume-weighted mean of the period's range, we can distinguish between 'hollow' trends driven by low-volume noise and 'solid' trends driven by institutional flow.\n                Concise Knowledge: If a price trend (REGBETA) is positive but the closing price is consistently near the bottom of the volume-weighted high-low range, the trend lacks conviction and is prone to reversal; conversely, price strength supported by high volume-weighted positioning indicates sustainable momentum.\n                concise Specification: Construct a factor for a 5-day window that calculates the difference between the normalized linear regression slope of $close and the volume-weighted position of the $close relative to the [$low, $high] range, targeting a look-back of 5 days.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0048186015007241,
        "ICIR": 0.0341703381939313,
        "RankIC": 0.0181039886220235,
        "RankICIR": 0.131624480528728,
        "annualized_return": -0.0128569858245349,
        "information_ratio": -0.1595151856964392,
        "max_drawdown": -0.2684494883415537
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:21:26.067321",
      "updated_at": "2026-01-14T20:03:33.054241"
    },
    "4eb1402e756c4b8e": {
      "factor_id": "4eb1402e756c4b8e",
      "factor_name": "Volatility_Squeeze_Breakout_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * (TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Squeeze_Breakout_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'volatility springs' by calculating the ratio of long-term volatility to the recent price range, then multiplying by the 5-day return to capture the direction of the breakout. A high value indicates a tight consolidation followed by a positive price expansion.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.387142",
      "updated_at": "2026-01-14T20:03:33.054243"
    },
    "f101db011ea22576": {
      "factor_id": "f101db011ea22576",
      "factor_name": "Ranked_Squeeze_Momentum_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-6)) * SIGN(TS_PCTCHANGE($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally ranked version of the volatility squeeze hypothesis. It measures the intensity of price tightness (inverse of the 5-day range normalized by 20-day volatility) and scales it by the sign of the recent 5-day trend to ensure directional alignment with the breakout.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.421657",
      "updated_at": "2026-01-14T20:03:33.054246"
    },
    "87e41321572b0d24": {
      "factor_id": "87e41321572b0d24",
      "factor_name": "Squeeze_Efficiency_Interaction_10D",
      "factor_expression": "TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 10) * (TS_STD($close, 20) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Efficiency_Interaction_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines the volatility squeeze concept with the direction of the 10-day price move. It uses the ratio of the 20-day standard deviation to the 5-day high-low range to identify periods of expansion potential, weighted by the 10-day return to filter for bullish momentum.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 2,
      "hypothesis": "Hypothesis: The 'Volatility Squeeze' signal, defined by the ratio of short-term price range to long-term volatility, predicts positive excess returns only when accompanied by a positive price change, as a squeeze alone merely indicates a pending breakout without specifying direction.\n                Concise Observation: Previous attempts to use 'Trend Stability' and 'Efficiency Ratios' failed because they penalized the volatility necessary for price movement or failed to account for the direction of the breakout, resulting in the selection of stagnant assets.\n                Concise Justification: By normalizing the 5-day price range by the 20-day standard deviation, we identify 'volatility springs' (squeezes). Multiplying this by the 5-day return ensures we capture the direction of the momentum emerging from the squeeze, filtering out bearish breakdowns.\n                Concise Knowledge: If a market enters a period of extreme price tightness (low 5-day range relative to 20-day volatility), it indicates a temporary equilibrium; when this equilibrium breaks in the direction of the recent micro-trend, it signifies a transition from low-volatility accumulation to high-volatility expansion.\n                concise Specification: The factor is defined as the product of the 5-day return and the inverse of the Volatility Squeeze ratio: Factor = ($close / $close.shift(5) - 1) * (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)).\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0083478232524004,
        "ICIR": 0.0550832942554879,
        "RankIC": 0.0229455083633896,
        "RankICIR": 0.1554997511710197,
        "annualized_return": 0.0514883926128528,
        "information_ratio": 0.5956447004656293,
        "max_drawdown": -0.1681153427426656
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:23:48.455370",
      "updated_at": "2026-01-14T20:03:33.054248"
    },
    "a6bae1dc4dfa3dda": {
      "factor_id": "a6bae1dc4dfa3dda",
      "factor_name": "Price_Volume_Efficiency_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Volume_Efficiency_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of the 5-day cumulative return to the 5-day cumulative volume turnover. A high ratio indicates a 'fragile' price move on low volume support, suggesting a higher probability of mean reversion. The ratio is cross-sectionally standardized using Z-score to identify extremes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.702263",
      "updated_at": "2026-01-14T20:03:33.054250"
    },
    "974be850a4998b4d": {
      "factor_id": "974be850a4998b4d",
      "factor_name": "Efficiency_Exhaustion_Index_5D",
      "factor_expression": "TS_ZSCORE(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8), 5)",
      "factor_implementation_code": "",
      "factor_description": "This factor targets liquidity-driven price spikes by measuring the 5-day price impact per unit of volume, further normalized by the time-series volatility of the ratio. It captures instances where price moves are 'too efficient' relative to historical norms, signaling potential exhaustion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.738072",
      "updated_at": "2026-01-14T20:03:33.054252"
    },
    "824685211c1a9db6": {
      "factor_id": "824685211c1a9db6",
      "factor_name": "Ranked_Price_Impact_Ratio_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Price_Impact_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the 5-day return relative to the total volume traded, applying a cross-sectional rank to identify stocks with the most extreme price-volume efficiency. This helps isolate stocks where the price has moved significantly on relatively low volume, indicating a lack of fundamental absorption.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 3,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Price-Volume Efficiency' ratio, defined as the 5-day cumulative return divided by the 5-day cumulative volume turnover, where extreme efficiency indicates price overextension due to liquidity gaps.\n                Concise Observation: Previous attempts using regression slopes and VWAP-based Z-scores failed because they didn't account for the 'cost' of price movement; a 5-day window is sensitive to liquidity-driven price spikes that lack the volume support to sustain new levels.\n                Concise Justification: By normalizing the return by the total volume traded (turnover proxy), we identify 'efficient' but unsustainable price jumps. This addresses the scale mismatch issue from previous failures by creating a ratio that measures the price impact per unit of volume.\n                Concise Knowledge: If a stock achieves a high cumulative return on relatively low cumulative volume turnover over 5 days, the price move is 'fragile' and likely to mean-revert; conversely, high-volume price moves indicate fundamental absorption and trend persistence.\n                concise Specification: Calculate the 5-day price change (Close_t / Close_{t-5} - 1) and divide it by the 5-day sum of volume; apply a 5-day Z-score to this ratio to identify cross-sectional extremes that signal exhaustion or liquidity-driven overextension.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041066678075668,
        "ICIR": 0.0269067721313705,
        "RankIC": 0.0179181774052397,
        "RankICIR": 0.1193144357705125,
        "annualized_return": 0.0626807508183861,
        "information_ratio": 0.8074781005334644,
        "max_drawdown": -0.1315712515980272
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:25:41.771471",
      "updated_at": "2026-01-14T20:03:33.054255"
    },
    "2397650750fec253": {
      "factor_id": "2397650750fec253",
      "factor_name": "Trend_Stability_PV_Sync_60D",
      "factor_expression": "POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) * TS_CORR($return, TS_PCTCHANGE($volume, 1), 10)\" # Your output factor expression will be filled in here\n    name = \"Trend_Stability_PV_Sync_60D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between long-term price trend linearity (R-squared) and short-term price-volume synchronization. High linearity suggests a stable trend, while positive price-volume correlation confirms the conviction behind the move.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.812715",
      "updated_at": "2026-01-14T20:03:33.054257"
    },
    "4d5727c8cc0353a3": {
      "factor_id": "4d5727c8cc0353a3",
      "factor_name": "Volume_Weighted_Volatility_Dispersion_60D",
      "factor_expression": "TS_STD(WMA($close, 60), 60) / (TS_MEAN(WMA($close, 60), 60) + 1e-8)",
      "factor_implementation_code": "",
      "factor_description": "This factor measures the volume-weighted volatility coefficient. It normalizes price volatility by volume to identify phases of stable accumulation or distribution. Lower values indicate more efficient price discovery with less noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.855502",
      "updated_at": "2026-01-14T20:03:33.054259"
    },
    "d459cae3758d5c09": {
      "factor_id": "d459cae3758d5c09",
      "factor_name": "Composite_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(POW(REGBETA($close, SEQUENCE(60), 60), 2) * TS_VAR(SEQUENCE(60), 60) / (TS_VAR($close, 60) + 1e-8)) - ZSCORE(TS_STD(WMA($close, 20), 20) / (TS_MEAN(WMA($close, 20), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(60), 60), 2)) - ZSCORE(TS_STD(WMA($close, 20), 20) / TS_MEAN(WMA($close, 20), 20))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines the linearity of the price trend (RSQR) with the relative volume-weighted price stability. It filters for stocks where the price trend is both statistically linear and supported by consistent volume-weighted price levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 1,
      "hypothesis": "Hypothesis: A stock's future excess return can be predicted by the interaction between its long-term trend stability (RSQR60), the short-term synchronization of price-volume momentum (CORD10), and its volume-weighted volatility coefficient (WVMA60).\n                Concise Observation: The user-provided components suggest that market efficiency is lower when long-term stability, short-term price-volume lead-lag relationships, and relative volatility dispersion are analyzed together.\n                Concise Justification: High RSQR60 identifies persistent trends, CORD10 captures the strength of the conviction behind price moves via volume confirmation, and WVMA60 normalizes volatility by volume to filter out noise in price discovery.\n                Concise Knowledge: If price trends exhibit high linearity (R-squared), the trend is more sustainable; when price and volume changes are positively correlated, the price move is supported by liquidity; and if volume-weighted volatility is low relative to its mean, the asset is in a stable accumulation or distribution phase.\n                concise Specification: The factor will be constructed by calculating the 60-day R-squared of daily closing prices, the 10-day correlation between price returns and volume growth, and the 60-day coefficient of variation for volume-weighted price changes.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0054880494831924,
        "ICIR": 0.0391316260256254,
        "RankIC": 0.0232094729225242,
        "RankICIR": 0.1733207786296372,
        "annualized_return": 0.0401632729843632,
        "information_ratio": 0.6155756712721605,
        "max_drawdown": -0.1003655681222551
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:18.889747",
      "updated_at": "2026-01-14T20:03:33.054262"
    },
    "04af2bc09ff7df83": {
      "factor_id": "04af2bc09ff7df83",
      "factor_name": "Conviction_Divergence_Reversal_10D",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * ($close - DELAY($close, 10)) / (TS_MEAN($high - $low, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Conviction_Divergence_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by combining price-volume divergence with volume conviction. It uses the 10-day price-volume correlation change as a measure of trend exhaustion, weighted by the 20-day volume Z-score (clipped at 0) to ensure the signal occurs during a high-conviction liquidity event. The reversal component is normalized by the 10-day price range relative to the typical body size.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.781751",
      "updated_at": "2026-01-14T20:03:33.054264"
    },
    "0965806078acfa49": {
      "factor_id": "0965806078acfa49",
      "factor_name": "Liquidity_Climax_Exhaustion_Factor",
      "factor_expression": "-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * TS_PCTCHANGE($close, 10) / (TS_MAD($return, 10) + 1e-8) * TS_RANK($volume, 20) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Climax_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets reversal points where price-volume correlation breaks down during extreme volume spikes. It normalizes the 10-day return by the 10-day Median Absolute Deviation of returns to handle outliers, then scales it by the interaction of volume intensity and the 5-day shift in price-volume alignment.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.815950",
      "updated_at": "2026-01-14T20:03:33.054266"
    },
    "1a83f9422320ba4d": {
      "factor_id": "1a83f9422320ba4d",
      "factor_name": "Vol_Weighted_Exhaustion_Index",
      "factor_expression": "-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8) * MAX(TS_ZSCORE($volume, 20), 0) * DELTA(TS_CORR($close, $volume, 10), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * ($close - DELAY($close, 10)) / (TS_STD($close, 10) + 1e-8)) * ((TS_ZSCORE($volume, 20) > 0) ? (TS_ZSCORE($volume, 20)) : (0)) * DELTA(TS_CORR($close, $volume, 10), 5)\" # Your output factor expression will be filled in here\n    name = \"Vol_Weighted_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified implementation of the conviction-exhaustion hypothesis. It measures 10-day price exhaustion by dividing the 10-day return by its 10-day volatility, then multiplying by the product of the volume Z-score and the change in price-volume correlation to isolate high-volume trend decoupling.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 5,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when a price-volume divergence (decreasing correlation) coincides with a 'Volume Surge' (high Z-score), suggesting that the trend exhaustion is validated by a high-conviction liquidity event.\n                Concise Observation: Previous iterations showed that volume Z-scores alone (Hypothesis 3) or price-volume correlation changes alone (Hypothesis 4) reduced drawdown but failed to maintain the high IC of the SOTA. The interaction between 'conviction' (high volume) and 'exhaustion' (correlation decay) has not been tested as a unified multiplicative signal.\n                Concise Justification: A 'selling climax' requires both a change in the relationship between price and volume (the divergence) and a significant amount of shares changing hands (the surge). By multiplying the reversal signal by both the volume Z-score and the correlation change, we isolate high-intensity turning points while filtering out low-volume noise.\n                Concise Knowledge: If a short-term price trend begins to decouple from volume (divergence) while absolute volume remains significantly above its 20-day mean (surge), the probability of a sharp mean-reversion increases; when volume is low, divergence is often just a liquidity drift and less predictive of a reversal.\n                concise Specification: The factor is defined as: (-1 * 10-day return / 10-day price volatility) * (20-day volume Z-score) * (5-day change in 10-day price-volume correlation). It uses $close and $volume from daily_pv.h5, with the volume Z-score clipped at a minimum of 0 to focus on high-volume conviction.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0036144490361066,
        "ICIR": 0.0272110756360775,
        "RankIC": 0.017898265114399,
        "RankICIR": 0.1401716284911586,
        "annualized_return": 0.0528454676109852,
        "information_ratio": 0.8752021566991357,
        "max_drawdown": -0.0777026109482773
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:26:49.848804",
      "updated_at": "2026-01-14T20:03:33.054268"
    },
    "5216873e5822843b": {
      "factor_id": "5216873e5822843b",
      "factor_name": "Composite_Trend_Volume_RSV_Factor",
      "factor_expression": "POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"POW(TS_CORR($close, SEQUENCE(20), 20), 2) * (TS_SUM(($close > DELAY($close, 1) ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * (($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Composite_Trend_Volume_RSV_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A composite factor that combines 20-day price trend stability (proxied by the square of the correlation between price and time), 5-day volume-weighted buying pressure, and the 5-day Relative Statistical Value (RSV) to identify high-probability entry points.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.835728",
      "updated_at": "2026-01-14T20:03:33.054271"
    },
    "c20dcf9d08b15587": {
      "factor_id": "c20dcf9d08b15587",
      "factor_name": "Ranked_Stability_Buying_Pressure_5D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM(($return > 0 ? $volume : 0), 5) / (TS_SUM($volume, 5) + 1e-8)) * TS_RANK($close, 5)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_Buying_Pressure_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor simplifies the hypothesis by cross-sectionally ranking trend stability (R-squared of price vs time) and multiplying it by the buying pressure ratio over a 5-day window, adjusted for price positioning.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.869921",
      "updated_at": "2026-01-14T20:03:33.054273"
    },
    "5d54c018fc9beb9d": {
      "factor_id": "5d54c018fc9beb9d",
      "factor_name": "Trend_Volume_Confirmation_ZScore",
      "factor_expression": "ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR($close, SEQUENCE(20), 20)) + ZSCORE(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)) + ZSCORE(($close - TS_MIN($low, 5)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Trend_Volume_Confirmation_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A standardized version of the hypothesis focusing on the convergence of price stability and volume intensity. It uses Z-scores to ensure the components are on the same scale before combination.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 1,
      "hypothesis": "Hypothesis: A composite factor combining the 20-day price trend stability (RSQR20), the 5-day volume-weighted buying pressure (VSUMP5), and the 5-day price range position (RSV5) can predict short-term returns by identifying stable trends supported by strong volume and favorable positioning.\n                Concise Observation: Market participants often look for technical alignment where price stability, volume confirmation, and mean-reversion potential (RSV) converge to signal high-probability entry points.\n                Concise Justification: RSQR20 filters for consistent trends, VSUMP5 quantifies the dominance of positive volume flow, and RSV5 identifies whether the current price is oversold or overbought relative to recent history.\n                Concise Knowledge: If a stock exhibits high price trend stability (R-squared) alongside increasing volume intensity and a low relative price position, it likely indicates a sustainable accumulation phase preceding a breakout.\n                concise Specification: The factor is defined as the product of RSQR20, VSUMP5, and RSV5, calculated using daily close and volume data with window sizes of 20 and 5 days respectively.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0053389349596723,
        "ICIR": 0.034809310604445,
        "RankIC": 0.0213799054946996,
        "RankICIR": 0.1439619783397803,
        "annualized_return": 0.0578263132293462,
        "information_ratio": 0.7039848422132899,
        "max_drawdown": -0.1488479515085962
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:27:11.904259",
      "updated_at": "2026-01-14T20:03:33.054275"
    },
    "5d9461843c6ecdcb": {
      "factor_id": "5d9461843c6ecdcb",
      "factor_name": "Normalized_Squeeze_Efficiency_ZScore_20D",
      "factor_expression": "ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_ZSCORE(TS_STD($return, 20) / (TS_MEAN($high - $low, 5) + 1e-8), 20) * (ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Squeeze_Efficiency_ZScore_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the volatility squeeze intensity relative to its 20-day history, then weighting it by the 10-day Efficiency Ratio. Instead of a raw price range, it uses the average true range (high-low) over 5 days to normalize the squeeze denominator and avoid outliers, then applies a cross-sectional Z-score to the final interaction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.048570",
      "updated_at": "2026-01-14T20:03:33.054277"
    },
    "11d3367e5ad2e843": {
      "factor_id": "11d3367e5ad2e843",
      "factor_name": "Relative_Compression_Breakout_Rank_15D",
      "factor_expression": "RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG((TS_STD($return, 20) * 100) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-8))) * RANK(RSI($close, 10))\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Breakout_Rank_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'spring-loading' effect of price compression by comparing the 20-day volatility to the 10-day price range, using a logarithmic transformation to handle non-stationarity. It is then combined with the 10-day RSI to ensure the breakout occurs within a strong momentum context, avoiding stagnant consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.084527",
      "updated_at": "2026-01-14T20:03:33.054279"
    },
    "f41fea1bcefd3200": {
      "factor_id": "f41fea1bcefd3200",
      "factor_name": "Squeeze_Directional_Efficiency_10D",
      "factor_expression": "TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close - $open, 10) + 1e-8), 20) * (DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)), 10)\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Directional_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the quality of the squeeze by interacting a 20-day volatility-to-range ratio with the Efficiency Ratio, but uses a 10-day moving average of the interaction to smooth out high-frequency noise. It uses the difference between close and open as a proxy for intraday conviction within the range calculation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 3,
      "hypothesis": "Hypothesis: The predictive power of a Volatility Squeeze is maximized when the intensity of price compression is normalized via a 20-day time-series Z-score and then interacted with the 10-day Efficiency Ratio to distinguish high-conviction breakouts from noise.\n                Concise Observation: Previous iterations showed that raw squeeze ratios are non-stationary and prone to outliers, while simple price returns are too noisy to capture the quality of a breakout; however, normalizing the squeeze intensity improved performance (IR 0.596).\n                Concise Justification: Using a TS_ZScore on the squeeze ratio (Std/Range) transforms the factor into a measure of 'relative tightness,' making it comparable across different market regimes, while the Efficiency Ratio (ER) ensures the breakout has sufficient directional 'path efficiency' to sustain a trend.\n                Concise Knowledge: If a stock's current price compression (volatility vs. range) is extreme relative to its own 20-day history, then the subsequent directional move is more likely to be a structural expansion; when this is filtered by the Efficiency Ratio, it isolates trends with high signal-to-noise characteristics.\n                concise Specification: The factor is defined as: TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20) * (Abs($close - $close.shift(10)) / Sum(Abs($close - $close.shift(1)), 10)). This combines a 20-day normalized squeeze intensity with a 10-day Kaufman's Efficiency Ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0055847971982691,
        "ICIR": 0.0404232918949153,
        "RankIC": 0.0212724713891256,
        "RankICIR": 0.1577580163779194,
        "annualized_return": 0.0707942548573807,
        "information_ratio": 1.032084330371433,
        "max_drawdown": -0.0957026225493011
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:05.118341",
      "updated_at": "2026-01-14T20:03:33.054281"
    },
    "8ea1bf1386c5b50e": {
      "factor_id": "8ea1bf1386c5b50e",
      "factor_name": "VWAP_Efficiency_Accel_20D",
      "factor_expression": "TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8), 20) * DELTA(TS_MEAN($close * $volume, 5), 5)\" # Your output factor expression will be filled in here\n    name = \"VWAP_Efficiency_Accel_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the interaction between price-volume efficiency and the acceleration of liquidity-adjusted momentum. It measures the deviation of the close price from the VWAP (approximated by (high+low+close)/3), normalized by 20-day return volatility, and scales it by the 5-day change in volume-weighted price momentum.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.322550",
      "updated_at": "2026-01-14T20:03:33.054283"
    },
    "7e9ddacd0e80dc3f": {
      "factor_id": "7e9ddacd0e80dc3f",
      "factor_name": "Liquidity_Adjusted_Momentum_Z",
      "factor_expression": "TS_ZSCORE($close / (($high + $low + $close) / 3 + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(($close - (($high + $low + $close) / 3)) / (TS_STD($return, 20) + 1e-8), 20) * RANK(TS_PCTCHANGE($volume, 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Adjusted_Momentum_Z\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the conviction of price moves by calculating the Z-score of the ratio between price-VWAP deviation and historical volatility, multiplied by the rank of short-term volume growth to filter for institutional accumulation.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.357753",
      "updated_at": "2026-01-14T20:03:33.054286"
    },
    "0a2809d6fd472731": {
      "factor_id": "0a2809d6fd472731",
      "factor_name": "Efficiency_Volatility_Ratio_20D",
      "factor_expression": "RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close / (($high + $low + $close) / 3 + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Volatility_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the efficiency of price discovery by comparing the price-VWAP ratio to the 20-day standard deviation of returns. It targets stocks where price is trending above the volume-weighted average under conditions of low relative volatility, which indicates a stable, high-conviction trend.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 2,
      "hypothesis": "Hypothesis: The interaction between price-volume efficiency (V-WAP deviation) and the acceleration of liquidity-adjusted momentum (20-day window) provides a more robust signal than simple trend linearity when normalized by historical volatility.\n                Concise Observation: Previous attempts using long-term (60-day) RSQR and simple price-volume correlations (CORD10) yielded a low IC (0.0055), suggesting that long-term linearity is too lagging and simple multipliers fail to capture the non-linear nature of price-volume breakouts.\n                Concise Justification: VWAP serves as a benchmark for 'fair' intraday/short-term value; deviation from it, combined with the rate of change in volume-weighted returns, identifies high-conviction moves that are likely to persist before mean-reverting.\n                Concise Knowledge: If a stock's price exceeds its Volume Weighted Average Price (VWAP) while liquidity-adjusted momentum is accelerating, it indicates strong institutional accumulation; when this occurs under low relative volatility, the signal's predictive reliability for future returns increases.\n                concise Specification: The factor calculates the 20-day mean of the ratio between ($close / VWAP) and the 20-day standard deviation of returns, further multiplied by the 5-day change in volume-weighted price momentum.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002714780360159,
        "ICIR": 0.0210385756438294,
        "RankIC": 0.0167817591473383,
        "RankICIR": 0.1331504274404731,
        "annualized_return": 0.0256120759092848,
        "information_ratio": 0.399356242670913,
        "max_drawdown": -0.1231934883155729
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:29:39.391667",
      "updated_at": "2026-01-14T20:03:33.054288"
    },
    "befa3a7f6f097a80": {
      "factor_id": "befa3a7f6f097a80",
      "factor_name": "Vol_Adjusted_Price_Impact_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) / (TS_STD($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Vol_Adjusted_Price_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the ratio of 5-day cumulative return to the 5-day average volume, normalized by the 5-day standard deviation of volume. This normalization isolates high-conviction liquidity exhaustion by filtering out noisy volume spikes.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.325818",
      "updated_at": "2026-01-14T20:03:33.054290"
    },
    "3fd5eeb189991af8": {
      "factor_id": "3fd5eeb189991af8",
      "factor_name": "Liquidity_Exhaustion_ZScore_5D",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5) * TS_STD($volume, 5) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_ZScore_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the volatility-adjusted price impact per unit of volume. It divides the 5-day return by the coefficient of variation of volume over the same period to highlight 'fragile' price moves that occur on stable but low liquidity, signaling potential reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.359575",
      "updated_at": "2026-01-14T20:03:33.054293"
    },
    "d83bb851f311b99a": {
      "factor_id": "d83bb851f311b99a",
      "factor_name": "Robust_Price_Efficiency_Rank_5D",
      "factor_expression": "RANK((DELTA($close, 5) / $close) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5) / (TS_MEDIAN($volume, 5) * TS_STD($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Price_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the price-volume efficiency hypothesis. It uses the 5-day return divided by the 5-day median volume, further adjusted by the volume's 5-day standard deviation to ensure the signal is not driven by a single day's volume outlier.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 4,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Adjusted Price Impact', where the ratio of the 5-day cumulative return to the 5-day average volume is normalized by the 5-day standard deviation of volume to isolate high-conviction liquidity exhaustion.\n                Concise Observation: The previous 'Price-Volume Efficiency' factor (IR 0.807) showed that return-to-volume ratios are predictive, but raw volume sums introduce cross-sectional noise and high drawdowns (-13.16%) due to unadjusted volume spikes.\n                Concise Justification: Normalizing the price impact (return/volume) by the volatility of volume (STD) filters out 'accidental' liquidity gaps caused by single-day outliers, ensuring the factor identifies sustained 'fragile' price movements that lack institutional depth.\n                Concise Knowledge: If a stock's price moves significantly on low and stable volume, it indicates a liquidity gap likely to revert; when high price impact occurs alongside high volume volatility, the signal is noisy and less predictive of mean reversion.\n                concise Specification: Calculate the 5-day cumulative return (Close_t / Close_{t-5} - 1). Divide this by the 5-day mean of $volume. Further divide this ratio by the 5-day standard deviation of $volume to create a volatility-adjusted efficiency metric. Finally, apply a cross-sectional rank to this value.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0042099885912047,
        "ICIR": 0.0264404709345451,
        "RankIC": 0.018487836195746,
        "RankICIR": 0.1153344975284127,
        "annualized_return": 0.0465228727536696,
        "information_ratio": 0.5343061594066428,
        "max_drawdown": -0.2041477117408748
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:30:23.394693",
      "updated_at": "2026-01-14T20:03:33.054295"
    },
    "0e1e6895d262970e": {
      "factor_id": "0e1e6895d262970e",
      "factor_name": "VWPP_Persistence_20D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 20) * ($close / (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 20) * ($close / ((TS_SUM($volume, 10) > 0) ? (TS_SUM($close * $volume, 10) / TS_SUM($volume, 10)) : $close))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Persistence_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Volume-Weighted Price Persistence (VWPP) calculates the 20-day average of daily returns weighted by the cross-sectional rank of volume. This captures momentum supported by relative liquidity. It is then scaled by the ratio of the current price to the 10-day volume-weighted average price (VWAP) to ensure the signal is active during high-conviction price trends.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.245004",
      "updated_at": "2026-01-14T20:03:33.054297"
    },
    "7e17d6f59c434e2c": {
      "factor_id": "7e17d6f59c434e2c",
      "factor_name": "VWPP_ZScore_Filtered_20D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 20)) * (($close > (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"VWPP_ZScore_Filtered_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Weighted Price Persistence factor that applies a cross-sectional Z-score to the volume-weighted return component to improve comparability. The factor is activated only when the price is above the 10-day VWAP, identifying efficient momentum regimes.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.278927",
      "updated_at": "2026-01-14T20:03:33.054300"
    },
    "5f773998e535e4cb": {
      "factor_id": "5f773998e535e4cb",
      "factor_name": "VWPP_Efficiency_Ratio_15D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 15) * (($close - (TS_SUM($close * $volume, 10) / (TS_SUM($volume, 10) + 1e-8))) / (TS_STD($close, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWPP_Efficiency_Ratio_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between volume-ranked returns and price efficiency. It uses a 15-day window for the volume-weighted return and normalizes the distance from the 10-day VWAP using the 20-day price standard deviation to account for varying volatility levels.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 3,
      "hypothesis": "Hypothesis: A stock's future excess return is driven by the 'Volume-Weighted Price Persistence' (VWPP), defined as the 20-day average of price returns scaled by their volume-rank, provided that the current price is within a 'high-conviction zone' relative to its 10-day VWAP.\n                Concise Observation: Previous attempts failed because raw price-volume products and deltas (like DELTA(close*volume)) created extreme outliers and noise, while long-term (60-day) linearity metrics were too lagging to capture regime shifts.\n                Concise Justification: Using cross-sectional volume ranks to weight returns prevents outliers from dominating the factor, while the VWAP ratio acts as a filter to ensure the signal is only active when the price is showing strength relative to the average cost basis of the last two weeks.\n                Concise Knowledge: If price momentum is supported by high relative volume, the trend is more persistent; when this momentum is evaluated relative to the VWAP benchmark, it distinguishes between sustainable accumulation and exhausted price spikes.\n                concise Specification: The factor (VWPP_20D) is calculated as the 20-day rolling mean of ($return * rank($volume)), where the rank is cross-sectional. This value is then multiplied by the ratio of $close to the 10-day VWAP (approximated as the 10-day mean of close weighted by volume) to capture the efficiency-momentum interaction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0024862710157301,
        "ICIR": 0.0184727080786825,
        "RankIC": 0.0158442078746771,
        "RankICIR": 0.1164171723234632,
        "annualized_return": 0.0432705569933927,
        "information_ratio": 0.5814728511705143,
        "max_drawdown": -0.1211428343456595
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:33:11.312438",
      "updated_at": "2026-01-14T20:03:33.054302"
    },
    "a4536c724715cb93": {
      "factor_id": "a4536c724715cb93",
      "factor_name": "Volume_Price_Asymmetry_Index_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($close, 5) / (TS_MEAN($volume, 5) + 1e-8)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Asymmetry_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price overextension by calculating the ratio of 5-day cumulative returns to the 5-day average volume, then scaling this impact by the relative liquidity (5-day average volume vs. 20-day average volume). High values indicate price moves on relatively low or declining liquidity, signaling potential mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.645583",
      "updated_at": "2026-01-14T20:03:33.054304"
    },
    "742224279aef2211": {
      "factor_id": "742224279aef2211",
      "factor_name": "Asymmetric_Liquidity_Impact_5D",
      "factor_expression": "RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($close - DELAY($close, 5)) / (DELAY($close, 5) + 1e-8)) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Asymmetric_Liquidity_Impact_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Volume-Price Asymmetry index that focuses on the 'cost' of price movement. It measures the 5-day return per unit of volume, adjusted by how the current 5-day volume compares to a longer 20-day baseline. It aims to capture 'hollow' price moves where participation is low relative to historical norms.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.680765",
      "updated_at": "2026-01-14T20:03:33.054308"
    },
    "21b119adc7849b19": {
      "factor_id": "21b119adc7849b19",
      "factor_name": "Relative_Volume_Efficiency_Rank_5D",
      "factor_expression": "ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(TS_PCTCHANGE($close, 5)) / (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Volume_Efficiency_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies potential exhaustion by comparing the magnitude of price change to the relative volume surge. It uses the ratio of 5-day absolute returns to the 5-day average volume, scaled by the 20-day volume average to normalize for stock-specific liquidity levels.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 5,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Volume-Price Asymmetry' index, which identifies price overextension by comparing the 5-day cumulative return to the 5-day average volume, scaled by the ratio of 5-day volume to its 20-day moving average.\n                Concise Observation: Previous attempts failed because 5-day volume standard deviation was too noisy and lacked a 'normal' baseline, leading to high drawdowns (-20.4%) and a failure to distinguish between trend initiation and exhaustion.\n                Concise Justification: Using a 20-day volume moving average provides a stable benchmark for 'normal' liquidity. By scaling the price impact (Return/Volume) by the relative volume (5D-Volume/20D-Volume), we can isolate 'asymmetric' moves where price travels too far on too little relative participation.\n                Concise Knowledge: If a significant price move occurs while volume remains low or decreases relative to its 20-day baseline, the move is likely a liquidity-driven anomaly prone to reversion; when a price move is accompanied by a surge in relative volume, it indicates high-conviction trend persistence.\n                concise Specification: Define a factor that calculates the 5-day cumulative return divided by the 5-day average volume. Multiply this result by the ratio of the 5-day average volume to the 20-day average volume. Apply a cross-sectional rank to this final product to identify the most 'asymmetric' instruments.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0031436312144851,
        "ICIR": 0.0202043914266813,
        "RankIC": 0.0169813700021945,
        "RankICIR": 0.1111564228858507,
        "annualized_return": 0.0189290780639091,
        "information_ratio": 0.2317808622895713,
        "max_drawdown": -0.1830611534035096
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:34:27.715331",
      "updated_at": "2026-01-14T20:03:33.054310"
    },
    "c7c789bf5382a2ab": {
      "factor_id": "c7c789bf5382a2ab",
      "factor_name": "Divergent_Climax_Reversal_10D",
      "factor_expression": "(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close / DELAY($close, 1), 10) + 1e-8)) * MAX(TS_ZSCORE($volume, 20), 0) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close / DELAY($close, 1), 10) + 1e-8)) * MAX(TS_ZSCORE($volume, 20), 0) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_Climax_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price reversals by combining price-volume divergence with volume intensity. It captures 'selling climax' or 'buying exhaustion' states where the 10-day price change is inversely related to volume, weighted by the 20-day volume Z-score (clipped to focus on high volume) and normalized by volatility to ensure the move is significant.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the asset is in a state of 'Negative Price-Volume Correlation' (divergence) during a period of high relative volume, where the signal is normalized by the 10-day price volatility to capture high-conviction exhaustion points.\n                Concise Observation: Previous attempts using the 'change' in correlation (DELTA) and complex Z-score gates reduced drawdown but diluted alpha, suggesting that the 'state' of divergence is more informative than its 'rate of change' for identifying reversal entries.\n                Concise Justification: A negative price-volume correlation during a price drop implies that volume is increasing as prices stabilize or decreasing as prices fall faster, both of which signal trend fragility. Using the absolute state of correlation instead of its derivative reduces signal lag and increases the frequency of capturing turning points.\n                Concise Knowledge: If a price decline occurs while the correlation between price and volume is negative, it indicates that the trend is losing its underlying volume support; when this state coincides with high relative volume, it identifies a high-conviction 'selling climax' that is more likely to mean-revert than a low-volume drift.\n                concise Specification: The factor is calculated as: (-1 * 10-day return / 10-day price standard deviation) * (20-day volume Z-score) * (-1 * 10-day rolling correlation of price and volume). The volume Z-score is clipped at 0 to focus on high-volume conviction, and the correlation is negated so that negative correlation (divergence) produces a positive signal.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0038822826403849,
        "ICIR": 0.0283309997543991,
        "RankIC": 0.0177282856141358,
        "RankICIR": 0.1324973148348587,
        "annualized_return": 0.0775444228618286,
        "information_ratio": 1.1066927452821531,
        "max_drawdown": -0.0887186969045068
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:16.995312",
      "updated_at": "2026-01-14T20:03:33.054312"
    },
    "2320d96098c88bb2": {
      "factor_id": "2320d96098c88bb2",
      "factor_name": "Exhaustion_State_Rank_Factor",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * RANK(-1 * TS_CORR($close, $volume, 10)) * ZSCORE(MAX(TS_ZSCORE($volume, 20), 0))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_CORR($close, $volume, 10)) * RANK(ABS(TS_PCTCHANGE($close, 10)) / (TS_STD($return, 10) + 1e-8)) * (TS_ZSCORE($volume, 20) > 0 ? TS_ZSCORE($volume, 20) : 0)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_State_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets reversal points by identifying assets where the 10-day price movement is extreme relative to its volatility, specifically when the price-volume correlation is at its lowest (most negative). By using the cross-sectional rank of the negative correlation, it highlights the most 'divergent' assets in the market during high-volume periods.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the asset is in a state of 'Negative Price-Volume Correlation' (divergence) during a period of high relative volume, where the signal is normalized by the 10-day price volatility to capture high-conviction exhaustion points.\n                Concise Observation: Previous attempts using the 'change' in correlation (DELTA) and complex Z-score gates reduced drawdown but diluted alpha, suggesting that the 'state' of divergence is more informative than its 'rate of change' for identifying reversal entries.\n                Concise Justification: A negative price-volume correlation during a price drop implies that volume is increasing as prices stabilize or decreasing as prices fall faster, both of which signal trend fragility. Using the absolute state of correlation instead of its derivative reduces signal lag and increases the frequency of capturing turning points.\n                Concise Knowledge: If a price decline occurs while the correlation between price and volume is negative, it indicates that the trend is losing its underlying volume support; when this state coincides with high relative volume, it identifies a high-conviction 'selling climax' that is more likely to mean-revert than a low-volume drift.\n                concise Specification: The factor is calculated as: (-1 * 10-day return / 10-day price standard deviation) * (20-day volume Z-score) * (-1 * 10-day rolling correlation of price and volume). The volume Z-score is clipped at 0 to focus on high-volume conviction, and the correlation is negated so that negative correlation (divergence) produces a positive signal.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0038822826403849,
        "ICIR": 0.0283309997543991,
        "RankIC": 0.0177282856141358,
        "RankICIR": 0.1324973148348587,
        "annualized_return": 0.0775444228618286,
        "information_ratio": 1.1066927452821531,
        "max_drawdown": -0.0887186969045068
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:17.030524",
      "updated_at": "2026-01-14T20:03:33.054315"
    },
    "fa3d0c3839049467": {
      "factor_id": "fa3d0c3839049467",
      "factor_name": "Relative_Climax_Momentum_Reversal",
      "factor_expression": "-1 * SIGN(DELTA($close, 10)) * LOG(1 + ABS(TS_PCTCHANGE($close, 10))) * (1 - TS_CORR($close, $volume, 10)) * MAX(TS_ZSCORE($volume, 20), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"-1 * SIGN(DELTA($close, 10)) * LOG(1 + ABS(TS_PCTCHANGE($close, 10))) * (1 - TS_CORR($close, $volume, 10)) * MAX(TS_ZSCORE($volume, 20), 0)\" # Your output factor expression will be filled in here\n    name = \"Relative_Climax_Momentum_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor assesses the conviction of a reversal signal by evaluating the 10-day return against the 10-day price-volume correlation. It uses a 20-day volume Z-score to gate the signal, ensuring that the reversal is triggered only during periods of abnormal trading activity (climax), while using a log-transform on the price change to dampen the impact of outliers.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 6,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the asset is in a state of 'Negative Price-Volume Correlation' (divergence) during a period of high relative volume, where the signal is normalized by the 10-day price volatility to capture high-conviction exhaustion points.\n                Concise Observation: Previous attempts using the 'change' in correlation (DELTA) and complex Z-score gates reduced drawdown but diluted alpha, suggesting that the 'state' of divergence is more informative than its 'rate of change' for identifying reversal entries.\n                Concise Justification: A negative price-volume correlation during a price drop implies that volume is increasing as prices stabilize or decreasing as prices fall faster, both of which signal trend fragility. Using the absolute state of correlation instead of its derivative reduces signal lag and increases the frequency of capturing turning points.\n                Concise Knowledge: If a price decline occurs while the correlation between price and volume is negative, it indicates that the trend is losing its underlying volume support; when this state coincides with high relative volume, it identifies a high-conviction 'selling climax' that is more likely to mean-revert than a low-volume drift.\n                concise Specification: The factor is calculated as: (-1 * 10-day return / 10-day price standard deviation) * (20-day volume Z-score) * (-1 * 10-day rolling correlation of price and volume). The volume Z-score is clipped at 0 to focus on high-volume conviction, and the correlation is negated so that negative correlation (divergence) produces a positive signal.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0038822826403849,
        "ICIR": 0.0283309997543991,
        "RankIC": 0.0177282856141358,
        "RankICIR": 0.1324973148348587,
        "annualized_return": 0.0775444228618286,
        "information_ratio": 1.1066927452821531,
        "max_drawdown": -0.0887186969045068
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:17.066513",
      "updated_at": "2026-01-14T20:03:33.054317"
    },
    "be56412e2f4c7223": {
      "factor_id": "be56412e2f4c7223",
      "factor_name": "VW_Efficiency_Squeeze_Tanh_10D",
      "factor_expression": "((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) - 1) / (EXP(TS_ZSCORE(TS_STD($return, 20) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-6), 20)) + 1)) * (ABS(DELTA($close, 10)) * TS_MEAN($volume, 10) / (TS_SUM($volume * ABS($return), 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Squeeze_Tanh_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by interacting a squashed Volatility Squeeze Z-score with a Volume-Weighted Efficiency Ratio. The squeeze is calculated as the ratio of 20-day return volatility to the 10-day price range, normalized via TS_ZSCORE and bounded by a Tanh-like transformation to handle outliers. The Volume-Weighted Efficiency Ratio ensures that price movements are supported by significant trading activity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.297230",
      "updated_at": "2026-01-14T20:03:33.054319"
    },
    "c66ee9481bdf59cf": {
      "factor_id": "c66ee9481bdf59cf",
      "factor_name": "Robust_Squeeze_VWER_Interaction",
      "factor_expression": "RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_ZSCORE(TS_STD($return, 20) / (TS_STD($close, 5) + 1e-6), 10)) * (DELTA($close, 5) / (TS_SUM($volume, 5) / (TS_MEAN($volume, 20) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VWER_Interaction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified interaction factor between a volatility compression metric and volume-weighted price efficiency. It uses a 10-day window for the squeeze and efficiency measures, applying a rank-based normalization to the squeeze intensity to ensure cross-sectional stability and combining it with a volume-scaled price velocity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 4,
      "hypothesis": "Hypothesis: The interaction between a Tanh-squashed Volatility Squeeze Z-score and a Volume-Weighted Efficiency Ratio (VWER) identifies high-conviction breakouts while mitigating the impact of liquidity-thin outliers.\n                Concise Observation: While the previous Z-score normalization improved the Information Ratio to 1.032, the drop in IC suggests that extreme values in the squeeze ratio or price-only efficiency metrics may be introducing noise or over-weighting illiquid instruments.\n                Concise Justification: Applying a Tanh function to the Z-score maps the squeeze intensity to a stable (-1, 1) range, ensuring the factor remains robust across different market regimes. Replacing the standard Efficiency Ratio with a Volume-Weighted version ensures that 'efficient' price moves are only rewarded if they occur alongside high trading activity, signaling institutional participation.\n                Concise Knowledge: If a volatility squeeze is normalized and bounded, it prevents extreme outliers from skewing the signal; when this bounded squeeze is validated by volume-weighted price efficiency, it confirms that the breakout is supported by significant capital commitment rather than low-volume noise.\n                concise Specification: The factor is defined as: Tanh(TS_ZScore(Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6), 20)) * (Abs($close - $close.shift(10)) / Sum($volume * Abs($return), 10) * Mean($volume, 10)). This combines a 20-day squashed squeeze intensity with a 10-day volume-weighted efficiency measure.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0035595597242928,
        "ICIR": 0.0243127023691133,
        "RankIC": 0.0182207529783272,
        "RankICIR": 0.1255486199559127,
        "annualized_return": 0.021173152787789,
        "information_ratio": 0.2708406499410276,
        "max_drawdown": -0.1750440967292268
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:35:59.334867",
      "updated_at": "2026-01-14T20:03:33.054322"
    },
    "b66d1f6a84d62c48": {
      "factor_id": "b66d1f6a84d62c48",
      "factor_name": "Volume_Ranked_Momentum_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) - TS_MEAN($return, 5)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Volume_Ranked_Momentum_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the divergence between long-term volume-weighted persistence and short-term price trends. It calculates the difference between a 15-day rolling mean of volume-ranked returns and a 5-day rolling mean of returns, normalized by the 20-day average price range relative to the close price to filter out volatility noise.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.056537",
      "updated_at": "2026-01-14T20:03:33.054324"
    },
    "06b6f311ac141eab": {
      "factor_id": "06b6f311ac141eab",
      "factor_name": "ZScored_Volume_Persistence_Divergence",
      "factor_expression": "(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_MEAN($return, 5))) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"ZScored_Volume_Persistence_Divergence\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the momentum divergence hypothesis that uses cross-sectional Z-scores to compare 15-day volume-weighted conviction against the 5-day price trend, ensuring the divergence signal is comparable across the universe before being scaled by the asset's relative volatility.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.092745",
      "updated_at": "2026-01-14T20:03:33.054326"
    },
    "79fbd5019fd5aa30": {
      "factor_id": "79fbd5019fd5aa30",
      "factor_name": "Smoothed_Momentum_Conviction_Ratio",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 15) / (ABS(TS_MEAN($return, 5)) + 1e-8)) / (TS_MEAN(($high - $low) / ($close + 1e-8), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Momentum_Conviction_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor focuses on the ratio of volume-supported persistence to short-term trend magnitude. By using the ratio instead of a difference, it identifies stocks where institutional conviction (15-day) significantly outweighs recent price action (5-day), normalized by the 20-day high-low range.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 4,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Ranked Momentum Divergence', where alpha is strongest when the 15-day volume-weighted return persistence diverges from the 5-day price trend, normalized by the rolling price range to filter out low-conviction volatility noise.\n                Concise Observation: Previous attempts using simple VWAP ratios or raw price-volume products were either too lagging or prone to outliers; the successful transition to Hypothesis 3 showed that normalizing price distance by volatility and using cross-sectional volume ranks significantly improves the Information Ratio.\n                Concise Justification: Volume-ranked persistence identifies institutional conviction without being skewed by absolute volume spikes, while the divergence between 15-day and 5-day windows captures shifts in trend velocity. Normalizing by the 20-day High-Low range (a proxy for ATR) ensures the signal strength is relative to the asset's specific volatility regime.\n                Concise Knowledge: If long-term (15-day) volume-supported momentum remains high while short-term (5-day) price trends show exhaustion or mean-reversion relative to volatility, a reversal or continuation signal is generated; when normalized by a rolling range (High-Low), the signal becomes invariant to absolute price levels.\n                concise Specification: The factor is defined as the difference between the 15-day rolling mean of ($return * rank($volume)) and the 5-day rolling mean of $return, divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0034931317989013,
        "ICIR": 0.0258097660287018,
        "RankIC": 0.020547232581289,
        "RankICIR": 0.1518036365369774,
        "annualized_return": 0.0102122535333025,
        "information_ratio": 0.1686512689160332,
        "max_drawdown": -0.0877134882891739
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:36:23.128528",
      "updated_at": "2026-01-14T20:03:33.054328"
    },
    "4ef43361520c1374": {
      "factor_id": "4ef43361520c1374",
      "factor_name": "Liquidity_Exhaustion_Ratio_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1e-8), 5) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Ratio_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by measuring the 'Price Impact' (5-day average high-low range divided by volume) normalized by the 20-day historical volatility. High values indicate price expansion on low volume relative to the stock's typical risk profile, suggesting a liquidity-driven spike prone to reversal.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.121526",
      "updated_at": "2026-01-14T20:03:33.054330"
    },
    "63d1f1ba0dcf782a": {
      "factor_id": "63d1f1ba0dcf782a",
      "factor_name": "Decoupled_Price_Effort_Factor_5D",
      "factor_expression": "ZSCORE((TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MEAN($high - $low, 5) / (TS_MEAN($volume, 5) + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decoupled_Price_Effort_Factor_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price-volume decoupling by comparing the 5-day average price range to the 5-day average volume turnover, scaled by the 20-day return volatility. It targets 'low-effort' price moves where the price range is large but volume participation is insufficient to sustain the trend.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.156769",
      "updated_at": "2026-01-14T20:03:33.054332"
    },
    "fc4601e963b9c4b1": {
      "factor_id": "fc4601e963b9c4b1",
      "factor_name": "Volatility_Scaled_Impact_Rank_5D",
      "factor_expression": "RANK((($high - $low) / ($volume + 1e-8)) / (TS_STD($return, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((($high - $low) / ($volume + 1e-8)) / (TS_STD($return, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Scaled_Impact_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of price movement per unit of volume, normalized by the stock's 20-day return standard deviation. By applying a cross-sectional rank, it identifies stocks with the most extreme liquidity-induced price exhaustion relative to their historical volatility baseline.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 6,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Liquidity-Induced Price-Volume Decoupling', where price exhaustion is identified by the ratio of the 5-day price range (High-Low) to the 5-day volume turnover, normalized by the 20-day historical volatility.\n                Concise Observation: Previous attempts failed when using simple returns (Hypothesis 5) or raw volume (Hypothesis 3) because they didn't account for the 'effort' (volume) required to move the price across a specific 'distance' (range) relative to its historical volatility baseline.\n                Concise Justification: The High-Low range is a more robust measure of price 'extension' than close-to-close returns as it captures intraday volatility. Dividing this by volume turnover creates a 'Price Impact' metric, and normalizing by 20-day volatility ensures that the signal identifies 'abnormal' price-volume decoupling rather than just high-beta stock behavior.\n                Concise Knowledge: If a stock's price range expands significantly (high volatility) while volume turnover fails to keep pace, the move is likely a liquidity-driven spike rather than a fundamental shift; such 'low-effort' price extensions are prone to rapid mean reversion in the subsequent 5-day period.\n                concise Specification: Calculate the 5-day average of ($high - $low) / $volume (Price Impact). Divide this by the 20-day standard deviation of daily returns (Volatility Baseline) to scale for stock-specific risk. Apply a 5-day cross-sectional rank to this final ratio to identify instruments with the highest liquidity-induced exhaustion.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0005543203416284,
        "ICIR": 0.0039627212593301,
        "RankIC": 0.015729301811548,
        "RankICIR": 0.1128562841516492,
        "annualized_return": 0.0599883556756462,
        "information_ratio": 0.8146199247406007,
        "max_drawdown": -0.0930565977353186
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:37:25.191520",
      "updated_at": "2026-01-14T20:03:33.054335"
    },
    "0a5a2699924a03f6": {
      "factor_id": "0a5a2699924a03f6",
      "factor_name": "Momentum_Volatility_Efficiency_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(($high - $low) / ($close + 1e-8), 15))\" # Your output factor expression will be filled in here\n    name = \"Momentum_Volatility_Efficiency_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures 'quiet conviction' by measuring the difference between the cross-sectional rank of volume-weighted return persistence and the cross-sectional rank of price-range volatility over a 15-day window. High values indicate stocks with strong, volume-supported trends but low relative volatility, suggesting efficient price discovery.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.148676",
      "updated_at": "2026-01-14T20:03:33.054337"
    },
    "ba52212e001d0431": {
      "factor_id": "ba52212e001d0431",
      "factor_name": "Efficiency_Adjusted_Persistence_15D",
      "factor_expression": "ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_MEAN($return * RANK($volume), 15)) - ZSCORE(TS_STD($high - $low, 15))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Persistence_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the efficiency hypothesis that focuses on the Z-score interaction between volume-ranked returns and a price-range stability metric. It identifies assets where the conviction (volume-weighted returns) significantly outweighs the noise (price range), using Z-scores to ensure cross-sectional comparability.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.183691",
      "updated_at": "2026-01-14T20:03:33.054339"
    },
    "c52e3e585865407c": {
      "factor_id": "c52e3e585865407c",
      "factor_name": "Ranked_Conviction_Trend_15D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 15)) - RANK(TS_MEAN(ABS($high - $low), 15))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Conviction_Trend_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a trend by subtracting the rank of daily price volatility (proxied by the high-low spread) from the rank of volume-weighted returns. By using ranks, it mitigates the impact of outliers and focuses on the relative efficiency of the price movement within the universe.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 5,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Cross-Sectional Momentum-Volatility Efficiency', where the alpha is strongest when the 15-day volume-ranked return persistence is high while the 15-day price-range volatility is relatively low, calculated via a rank-based interaction rather than a ratio.\n                Concise Observation: Previous attempts using ratios (Hypothesis 4) or simple acceleration (15 vs 30 days) failed because they either introduced instability through division or used windows that were too lagging; however, the use of cross-sectional volume ranks and volatility normalization (ATR proxy) showed the most promise in stabilizing the IC.\n                Concise Justification: Ratios are prone to extreme values when the denominator is small; by using the difference between the rank of volume-weighted persistence and the rank of price-range volatility, we isolate stocks with 'quiet' but high-conviction trends, which typically exhibit higher risk-adjusted returns.\n                Concise Knowledge: In quant equity, if volume-supported momentum is high while price range volatility remains low, it indicates efficient price discovery and institutional accumulation; when these components are combined using cross-sectional ranks, the signal becomes robust to outliers and heteroskedasticity across different instruments.\n                concise Specification: The factor 'Momentum_Volatility_Efficiency_15D' is calculated as: rank(ts_mean($return * rank($volume), 15)) - rank(ts_mean(($high - $low) / $close, 15)). All ranks are cross-sectional per day.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0022386332007764,
        "ICIR": 0.0164363123778626,
        "RankIC": 0.0214234525908287,
        "RankICIR": 0.1580740738691956,
        "annualized_return": 0.0102308203646186,
        "information_ratio": 0.1722547293733247,
        "max_drawdown": -0.0863780560641173
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:39:41.220630",
      "updated_at": "2026-01-14T20:03:33.054341"
    },
    "6e15d6b03df56549": {
      "factor_id": "6e15d6b03df56549",
      "factor_name": "Liquidity_Acceleration_Exhaustion_5D",
      "factor_expression": "RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_PCTCHANGE($high - $low, 5) / (TS_PCTCHANGE($volume + 1, 5) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Acceleration_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by calculating the 'acceleration' of price range relative to volume growth. A high ratio indicates that price volatility is expanding faster than liquidity support, signaling a 'hollow' move. This is weighted by the 5-day average position of the close within the high-low range to identify exhaustion patterns.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:57.989967",
      "updated_at": "2026-01-14T20:03:33.054343"
    },
    "c2360a30aaa40f97": {
      "factor_id": "c2360a30aaa40f97",
      "factor_name": "Dynamic_Range_Volume_Tipping_Point",
      "factor_expression": "(DELTA($high - $low, 5) / (DELTA($volume, 5) + 1e-8)) * (($close - $low) / ($high - $low + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($high - $low, 5) / (DELTA($volume, 5) + 1e-8)) * (($close - $low) / ($high - $low + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Dynamic_Range_Volume_Tipping_Point\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the tipping point of liquidity exhaustion by measuring the 5-day change in price range normalized by the 5-day change in volume. It specifically targets 'shooting star' or 'hammer' patterns by incorporating the close-to-range position, identifying where price extensions lack volume-driven conviction.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:58.026064",
      "updated_at": "2026-01-14T20:03:33.054345"
    },
    "de2818d3245fbacd": {
      "factor_id": "de2818d3245fbacd",
      "factor_name": "Exhaustion_Intensity_Rank_5D",
      "factor_expression": "(RANK(TS_PCTCHANGE($high - $low, 5)) / (RANK(TS_PCTCHANGE($volume, 5)) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK(TS_PCTCHANGE($high - $low, 5)) / (RANK(TS_PCTCHANGE($volume, 5)) + 1e-8)) * TS_MEAN(($close - $low) / ($high - $low + 1e-9), 5)\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Intensity_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor that ranks instruments based on the acceleration of price impact. It measures the growth of the high-low range relative to volume growth over 5 days, adjusted by the recent average price positioning within the daily range to filter for sustainable breakouts.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 7,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by the 'Acceleration of Liquidity Exhaustion', where the divergence between the 5-day growth in price range and the 5-day growth in volume intensity identifies unsustainable price extensions.\n                Concise Observation: Previous successful iterations (IR 0.8146) showed that normalizing price range by volume turnover reduces drawdown, but the use of static 5-day averages lags behind the dynamic 'tipping points' where liquidity actually dries up.\n                Concise Justification: Using the ratio of the 5-day change in range to the 5-day change in volume captures the 'acceleration' of price impact. Adding the 'Close-to-Range' position (where the price ends relative to its high-low) differentiates between a breakout with strong finishing power and a 'shooting star' exhaustion pattern.\n                Concise Knowledge: If the rate of expansion in price range (volatility) significantly exceeds the rate of expansion in volume (liquidity support), the price movement is likely a 'hollow' exhaustion; when this occurs while the closing price is retreating from the day's extreme, the probability of mean reversion increases.\n                concise Specification: Calculate the 5-day percentage change in ($high - $low) and divide it by the 5-day percentage change in ($volume + 1). Multiply this 'Acceleration' ratio by the 5-day average of ($close - $low) / ($high - $low + 1e-9). Finally, apply a cross-sectional rank to this product over a 5-day lookback.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.004033024394732,
        "ICIR": 0.0303047033015789,
        "RankIC": 0.019687389539859,
        "RankICIR": 0.1483146335339467,
        "annualized_return": 0.0456749353133537,
        "information_ratio": 0.7420196141549052,
        "max_drawdown": -0.0913454808353619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:40:58.062016",
      "updated_at": "2026-01-14T20:03:33.054347"
    },
    "fbf7da796f254b8c": {
      "factor_id": "fbf7da796f254b8c",
      "factor_name": "Volume_Surge_Breakout_Intensity_20D",
      "factor_expression": "RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_STD($return, 20) / (TS_STD($return, 5) + 1e-8)) * TS_PCTCHANGE($close, 5) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Surge_Breakout_Intensity_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by measuring the interaction between price momentum and a volume-weighted volatility squeeze. Instead of a raw price range, it uses the standard deviation of returns normalized by a 20-day baseline, multiplied by a volume surge ratio (5-day vs 20-day) to filter for institutional participation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.601633",
      "updated_at": "2026-01-14T20:03:33.054350"
    },
    "db32cf1b30603006": {
      "factor_id": "db32cf1b30603006",
      "factor_name": "Compressed_Momentum_Volume_Multiplier_10D",
      "factor_expression": "(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(DELTA($close, 5) / (TS_STD($return, 20) * $close + 1e-8)) * LOG(1 + TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Compressed_Momentum_Volume_Multiplier_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'coiling' effect by comparing the current 5-day return to the 20-day historical volatility, then scales this signal by the relative volume growth. It uses the ratio of 5-day average volume to 20-day average volume as a threshold-based multiplier to ensure the breakout is supported by liquidity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.638855",
      "updated_at": "2026-01-14T20:03:33.054352"
    },
    "813f4d08321676c8": {
      "factor_id": "813f4d08321676c8",
      "factor_name": "Breakout_Conviction_Index_5D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * TS_ZSCORE($volume / (TS_STD($return, 20) + 1e-8), 10)\" # Your output factor expression will be filled in here\n    name = \"Breakout_Conviction_Index_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the strength of a breakout by combining the direction of the 5-day price move with the relative volume intensity, normalized by the 20-day price volatility. It avoids raw high-low ranges to prevent outlier sensitivity, focusing instead on return-based volatility.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 5,
      "hypothesis": "Hypothesis: A high-conviction breakout is best identified by the interaction between a 'Price Compression Ratio' (short-term range vs. medium-term volatility) and a 'Volume-Confirmed Momentum' signal, where the momentum is filtered by a 5-day volume surge relative to its 20-day average.\n                Concise Observation: Previous attempts failed when using complex Tanh/Z-score transformations or long-term 60-day baselines, suggesting that the 'squeeze' signal is a short-to-medium term phenomenon (20 days) and that volume should act as a threshold multiplier rather than a complex denominator component.\n                Concise Justification: The 'Price Compression Ratio' (PCR) identifies the squeeze. Multiplying this by the 5-day return provides direction. Incorporating the ratio of 5-day volume to 20-day volume ensures that the price movement is not a low-liquidity fluke but a result of increased market participation, which is a classic indicator of institutional 'breakout' conviction.\n                Concise Knowledge: If a stock's price range contracts significantly relative to its 20-day volatility, it signals a volatility 'coiling' effect; when this coiling is released in the direction of a 5-day return that is supported by a volume ratio greater than 1, the probability of a sustained expansion increases.\n                concise Specification: The factor is defined as: (Std($return, 20) / (Max($high, 5) - Min($low, 5) + 1e-6)) * ($close / $close.shift(5) - 1) * (Mean($volume, 5) / Mean($volume, 20)). This uses a 20-day volatility baseline, a 5-day price range, and a 5-day vs 20-day volume ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0043798752778824,
        "ICIR": 0.028253734286547,
        "RankIC": 0.017991862037871,
        "RankICIR": 0.1180007334386441,
        "annualized_return": 0.0282747157763693,
        "information_ratio": 0.3573941215908934,
        "max_drawdown": -0.1607281418319716
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:41:01.674344",
      "updated_at": "2026-01-14T20:03:33.054354"
    },
    "074aeb1bdfd6f8e3": {
      "factor_id": "074aeb1bdfd6f8e3",
      "factor_name": "Climax_Reversal_Volume_Momentum_10D",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close, 10) + 1e-8)) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10) / (TS_STD($close, 10) + 1e-8)) * RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Climax_Reversal_Volume_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction price reversals by combining the 10-day price drawdown (normalized by its 10-day standard deviation) with a 5-day volume momentum filter. It targets 'selling climax' events where sharp price declines are met with increasing volume participation, suggesting a potential trend exhaustion and subsequent bounce.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day price reversal is most potent when a significant price drawdown is accompanied by positive volume momentum, where the signal is enhanced by cross-sectionally ranking the return relative to its volatility to isolate high-conviction climax events.\n                Concise Observation: Previous iterations using 10-day price-volume correlation (1-CORR) successfully reduced drawdown but diluted the IC (0.0063 down to lower levels), suggesting that the 'state' of correlation is too slow compared to the 'momentum' of volume during a capitulation event.\n                Concise Justification: Market microstructure suggests that the most profitable reversals occur after a 'blow-off' or 'selling climax,' characterized by price and volume moving aggressively in the same direction (positive volume momentum) before a snap-back. Cross-sectional ranking of the return ensures that we target assets with the most extreme 'stretch' relative to the market, improving the signal-to-noise ratio.\n                Concise Knowledge: If a short-term price trend accelerates while volume momentum is positive, it indicates a 'climax' phase; when the 10-day return is cross-sectionally ranked and multiplied by volume momentum, the resulting factor identifies high-conviction turning points more effectively than linear correlation-based filters.\n                concise Specification: The factor is defined as: CS_Rank(-1 * 10-day return / 10-day price standard deviation) * CS_Rank(5-day volume momentum). Volume momentum is defined as the ratio of the 5-day average volume to the 20-day average volume. All variables are sourced from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0021517511318312,
        "ICIR": 0.0152943302107834,
        "RankIC": 0.0164866647542131,
        "RankICIR": 0.1207719729597577,
        "annualized_return": 0.0469881451941539,
        "information_ratio": 0.6718395658582001,
        "max_drawdown": -0.1029565810443816
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:42:22.746761",
      "updated_at": "2026-01-14T20:03:33.054357"
    },
    "419f8716b8c04b6c": {
      "factor_id": "419f8716b8c04b6c",
      "factor_name": "Relative_Stretch_Volume_Surge_Factor",
      "factor_expression": "RANK((DELAY($close, 10) - $close) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-8)) * RANK(EMA($volume, 5) / (EMA($volume, 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((DELAY($close, 10) - $close) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-8)) * RANK(EMA($volume, 5) / (EMA($volume, 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Relative_Stretch_Volume_Surge_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures price-volume divergence during extreme price moves. It calculates the 10-day return relative to the 20-day price range (stretch) and scales it by the 5-day volume momentum. By using the price range instead of standard deviation, it focuses on the magnitude of the 'stretch' relative to recent boundaries, identifying capitulation points.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day price reversal is most potent when a significant price drawdown is accompanied by positive volume momentum, where the signal is enhanced by cross-sectionally ranking the return relative to its volatility to isolate high-conviction climax events.\n                Concise Observation: Previous iterations using 10-day price-volume correlation (1-CORR) successfully reduced drawdown but diluted the IC (0.0063 down to lower levels), suggesting that the 'state' of correlation is too slow compared to the 'momentum' of volume during a capitulation event.\n                Concise Justification: Market microstructure suggests that the most profitable reversals occur after a 'blow-off' or 'selling climax,' characterized by price and volume moving aggressively in the same direction (positive volume momentum) before a snap-back. Cross-sectional ranking of the return ensures that we target assets with the most extreme 'stretch' relative to the market, improving the signal-to-noise ratio.\n                Concise Knowledge: If a short-term price trend accelerates while volume momentum is positive, it indicates a 'climax' phase; when the 10-day return is cross-sectionally ranked and multiplied by volume momentum, the resulting factor identifies high-conviction turning points more effectively than linear correlation-based filters.\n                concise Specification: The factor is defined as: CS_Rank(-1 * 10-day return / 10-day price standard deviation) * CS_Rank(5-day volume momentum). Volume momentum is defined as the ratio of the 5-day average volume to the 20-day average volume. All variables are sourced from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0021517511318312,
        "ICIR": 0.0152943302107834,
        "RankIC": 0.0164866647542131,
        "RankICIR": 0.1207719729597577,
        "annualized_return": 0.0469881451941539,
        "information_ratio": 0.6718395658582001,
        "max_drawdown": -0.1029565810443816
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:42:22.782624",
      "updated_at": "2026-01-14T20:03:33.054359"
    },
    "94686d4d9a6a76ca": {
      "factor_id": "94686d4d9a6a76ca",
      "factor_name": "ZScored_Reversal_Volume_Intensity",
      "factor_expression": "RANK(-1 * TS_ZSCORE(TS_SUM($return, 10), 20)) * RANK(TS_RANK($volume, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_ZSCORE(TS_SUM($return, 10), 20)) * RANK(TS_RANK($volume, 20))\" # Your output factor expression will be filled in here\n    name = \"ZScored_Reversal_Volume_Intensity\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor isolates mean-reversion signals by cross-sectionally ranking the 10-day return Z-score and multiplying it by the rank of volume intensity. This approach ensures that the reversal signal is significant both in terms of its own history (time-series) and relative to the market (cross-section), while requiring high volume to confirm the climax.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 7,
      "hypothesis": "Hypothesis: The 10-day price reversal is most potent when a significant price drawdown is accompanied by positive volume momentum, where the signal is enhanced by cross-sectionally ranking the return relative to its volatility to isolate high-conviction climax events.\n                Concise Observation: Previous iterations using 10-day price-volume correlation (1-CORR) successfully reduced drawdown but diluted the IC (0.0063 down to lower levels), suggesting that the 'state' of correlation is too slow compared to the 'momentum' of volume during a capitulation event.\n                Concise Justification: Market microstructure suggests that the most profitable reversals occur after a 'blow-off' or 'selling climax,' characterized by price and volume moving aggressively in the same direction (positive volume momentum) before a snap-back. Cross-sectional ranking of the return ensures that we target assets with the most extreme 'stretch' relative to the market, improving the signal-to-noise ratio.\n                Concise Knowledge: If a short-term price trend accelerates while volume momentum is positive, it indicates a 'climax' phase; when the 10-day return is cross-sectionally ranked and multiplied by volume momentum, the resulting factor identifies high-conviction turning points more effectively than linear correlation-based filters.\n                concise Specification: The factor is defined as: CS_Rank(-1 * 10-day return / 10-day price standard deviation) * CS_Rank(5-day volume momentum). Volume momentum is defined as the ratio of the 5-day average volume to the 20-day average volume. All variables are sourced from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0021517511318312,
        "ICIR": 0.0152943302107834,
        "RankIC": 0.0164866647542131,
        "RankICIR": 0.1207719729597577,
        "annualized_return": 0.0469881451941539,
        "information_ratio": 0.6718395658582001,
        "max_drawdown": -0.1029565810443816
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:42:22.818539",
      "updated_at": "2026-01-14T20:03:33.054361"
    },
    "0b1696dec7b25994": {
      "factor_id": "0b1696dec7b25994",
      "factor_name": "ZScore_RSQR20_VWAP_Momentum_2D",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"ZScore_RSQR20_VWAP_Momentum_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trend continuations by multiplying the cross-sectional Z-score of price trend stability (R-squared of close prices over 20 days) with the cross-sectional Z-score of a 2-day volume-weighted return. This ensures that long-term structural stability is validated by immediate volume-supported price action.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.064610",
      "updated_at": "2026-01-14T20:03:33.054363"
    },
    "e7e3d9f0f2bcda6e": {
      "factor_id": "e7e3d9f0f2bcda6e",
      "factor_name": "Ranked_Stability_VWAP_Trigger_2D",
      "factor_expression": "RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * RANK(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Stability_VWAP_Trigger_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the stability-momentum hypothesis using RANK instead of ZSCORE to handle outliers. It identifies stocks where the 20-day price trend is highly linear (RSQR) and is currently experiencing a positive 2-day volume-weighted price thrust, signaling a high-probability entry point.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.101297",
      "updated_at": "2026-01-14T20:03:33.054366"
    },
    "b6d66145f7cdc66f": {
      "factor_id": "b6d66145f7cdc66f",
      "factor_name": "Conditional_Trend_Stability_2D",
      "factor_expression": "(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_SUM($return * $volume, 2) > 0) ? (ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) * ZSCORE(TS_SUM($return * $volume, 2) / (TS_SUM($volume, 2) + 1e-8))) : 0\" # Your output factor expression will be filled in here\n    name = \"Conditional_Trend_Stability_2D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional logic where the 20-day trend stability (RSQR) is only considered if the 2-day volume-weighted return is positive. It focuses on 'quiet' institutional accumulation that is just beginning to break out with volume support, filtering out stagnant or decaying trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 2,
      "hypothesis": "Hypothesis: A conditional factor that scales 20-day price trend stability (RSQR20) by the 2-day volume-weighted price change (VWAP-like momentum) after cross-sectional normalization captures high-conviction trend continuations while filtering out stable but decaying trends.\n                Concise Observation: Simple multiplication of 20-day stability and 5-day positioning was noisy (IR 0.704), but feedback suggests that shortening the momentum window and using Z-scores to align scales significantly improves the signal-to-noise ratio.\n                Concise Justification: RSQR20 identifies 'quiet' institutional accumulation, while a 2-day VWAP-based return identifies the immediate 'trigger' or 'breakout' signal; Z-scoring ensures that the high-variance volume component doesn't drown out the structural stability metric.\n                Concise Knowledge: If long-term price stability is validated by immediate volume-weighted price direction, the trend is more likely to persist; when these signals diverge, the stability measure often reflects stagnation or impending reversal rather than strength.\n                concise Specification: Calculate RSQR20 (R-squared of close prices over 20 days), calculate a 2-day volume-weighted return (sum of return*volume over 2 days / sum of volume over 2 days), apply cross-sectional Z-score to both, and define the factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0035466359017618,
        "ICIR": 0.0275046505658672,
        "RankIC": 0.0180211357588965,
        "RankICIR": 0.1386026300435576,
        "annualized_return": 0.051265157077351,
        "information_ratio": 0.8533626141894113,
        "max_drawdown": -0.0980522953705393
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:43:57.137115",
      "updated_at": "2026-01-14T20:03:33.054368"
    },
    "cb229012ab6ccba6": {
      "factor_id": "cb229012ab6ccba6",
      "factor_name": "VW_Momentum_Convexity_10_20",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Convexity_10_20\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the acceleration of volume-weighted momentum by subtracting the 20-day trend from the 10-day momentum, filtered by the price position relative to a 5-day VWAP proxy. This identifies high-conviction institutional accumulation when the price is efficiently positioned.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 6,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Convexity', where alpha is maximized by identifying assets where the 10-day volume-weighted momentum is accelerating relative to its 20-day trend, specifically when the price is trading below its 5-day high-volume price level (VWAP proxy).\n                Concise Observation: Previous attempts failed because rank-subtraction (Hypothesis 5) over-smoothed the signal and 15-day windows were too lagging; however, the successful SOTA (Hypothesis 3) utilized a price-to-VWAP ratio which provided a necessary 'location' filter that the subsequent failures lacked.\n                Concise Justification: Momentum 'acceleration' (10d vs 20d) captures the second derivative of price action which is more predictive of future returns than simple velocity. Re-introducing the VWAP-based 'location' filter (from Hypothesis 3) ensures that the momentum signal is only active when the price is efficiently positioned relative to recent volume-weighted costs.\n                Concise Knowledge: If the short-term (10-day) volume-weighted return exceeds the medium-term (20-day) baseline, it indicates a convexity in institutional accumulation; when this is combined with a price position near a short-term liquidity anchor (5-day VWAP), it identifies high-probability entry points for trend continuation.\n                concise Specification: The factor 'VW_Momentum_Convexity_10_20' is defined as the subtraction of the 20-day mean of ($return * rank($volume)) from the 10-day mean of ($return * rank($volume)), then multiplied by the ratio ($close / ts_mean($close * $volume, 5) / ts_mean($volume, 5)). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0037946798042562,
        "ICIR": 0.0289506865260227,
        "RankIC": 0.0185580027774798,
        "RankICIR": 0.1416468970919491,
        "annualized_return": 0.0305367437495582,
        "information_ratio": 0.5025696895316144,
        "max_drawdown": -0.1023061839122148
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:21.596856",
      "updated_at": "2026-01-14T20:03:33.054370"
    },
    "4f4b09ec021b7dfd": {
      "factor_id": "4f4b09ec021b7dfd",
      "factor_name": "VW_Conviction_Accel_ZScore_10D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) - TS_MEAN($return * RANK($volume), 20)) * ($close / (TS_MEAN($close, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VW_Conviction_Accel_ZScore_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Measures the convexity of volume-weighted returns by comparing short-term acceleration to its medium-term baseline, normalized by a 5-day liquidity-weighted price ratio to ensure the signal is active near institutional cost basis.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 6,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Convexity', where alpha is maximized by identifying assets where the 10-day volume-weighted momentum is accelerating relative to its 20-day trend, specifically when the price is trading below its 5-day high-volume price level (VWAP proxy).\n                Concise Observation: Previous attempts failed because rank-subtraction (Hypothesis 5) over-smoothed the signal and 15-day windows were too lagging; however, the successful SOTA (Hypothesis 3) utilized a price-to-VWAP ratio which provided a necessary 'location' filter that the subsequent failures lacked.\n                Concise Justification: Momentum 'acceleration' (10d vs 20d) captures the second derivative of price action which is more predictive of future returns than simple velocity. Re-introducing the VWAP-based 'location' filter (from Hypothesis 3) ensures that the momentum signal is only active when the price is efficiently positioned relative to recent volume-weighted costs.\n                Concise Knowledge: If the short-term (10-day) volume-weighted return exceeds the medium-term (20-day) baseline, it indicates a convexity in institutional accumulation; when this is combined with a price position near a short-term liquidity anchor (5-day VWAP), it identifies high-probability entry points for trend continuation.\n                concise Specification: The factor 'VW_Momentum_Convexity_10_20' is defined as the subtraction of the 20-day mean of ($return * rank($volume)) from the 10-day mean of ($return * rank($volume)), then multiplied by the ratio ($close / ts_mean($close * $volume, 5) / ts_mean($volume, 5)). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0037946798042562,
        "ICIR": 0.0289506865260227,
        "RankIC": 0.0185580027774798,
        "RankICIR": 0.1416468970919491,
        "annualized_return": 0.0305367437495582,
        "information_ratio": 0.5025696895316144,
        "max_drawdown": -0.1023061839122148
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:21.633979",
      "updated_at": "2026-01-14T20:03:33.054373"
    },
    "1e35083b842e7401": {
      "factor_id": "1e35083b842e7401",
      "factor_name": "VWAP_Location_Momentum_10D",
      "factor_expression": "TS_MEAN($return * RANK($volume), 10) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 10) * ($close / (TS_MEAN($close * $volume, 5) / (TS_MEAN($volume, 5) + 1e-8) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"VWAP_Location_Momentum_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the momentum convexity hypothesis focusing on the interaction between the 10-day volume-weighted momentum and the price distance from the 5-day volume-weighted average price.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 6,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Convexity', where alpha is maximized by identifying assets where the 10-day volume-weighted momentum is accelerating relative to its 20-day trend, specifically when the price is trading below its 5-day high-volume price level (VWAP proxy).\n                Concise Observation: Previous attempts failed because rank-subtraction (Hypothesis 5) over-smoothed the signal and 15-day windows were too lagging; however, the successful SOTA (Hypothesis 3) utilized a price-to-VWAP ratio which provided a necessary 'location' filter that the subsequent failures lacked.\n                Concise Justification: Momentum 'acceleration' (10d vs 20d) captures the second derivative of price action which is more predictive of future returns than simple velocity. Re-introducing the VWAP-based 'location' filter (from Hypothesis 3) ensures that the momentum signal is only active when the price is efficiently positioned relative to recent volume-weighted costs.\n                Concise Knowledge: If the short-term (10-day) volume-weighted return exceeds the medium-term (20-day) baseline, it indicates a convexity in institutional accumulation; when this is combined with a price position near a short-term liquidity anchor (5-day VWAP), it identifies high-probability entry points for trend continuation.\n                concise Specification: The factor 'VW_Momentum_Convexity_10_20' is defined as the subtraction of the 20-day mean of ($return * rank($volume)) from the 10-day mean of ($return * rank($volume)), then multiplied by the ratio ($close / ts_mean($close * $volume, 5) / ts_mean($volume, 5)). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0037946798042562,
        "ICIR": 0.0289506865260227,
        "RankIC": 0.0185580027774798,
        "RankICIR": 0.1416468970919491,
        "annualized_return": 0.0305367437495582,
        "information_ratio": 0.5025696895316144,
        "max_drawdown": -0.1023061839122148
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:21.670405",
      "updated_at": "2026-01-14T20:03:33.054375"
    },
    "ea99a07e9b070392": {
      "factor_id": "ea99a07e9b070392",
      "factor_name": "Vol_Squeeze_Conviction_Ratio_20D",
      "factor_expression": "((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * (DELTA($close, 5) / (TS_STD($return, 20) * DELAY($close, 5) + 1e-7)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * (DELTA($close, 5) / (TS_STD($return, 20) * DELAY($close, 5) + 1e-7)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))\" # Your output factor expression will be filled in here\n    name = \"Vol_Squeeze_Conviction_Ratio_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the volatility squeeze by comparing the 20-day high-low range to the 5-day high-low range, then weights this compression by a volatility-normalized 5-day return and a volume intensity ratio. It identifies 'coiling' stocks where price tightness is released with volume support.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 6,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is best captured by the interaction between a 'Relative Compression Index' (5-day range vs 20-day range) and a 'Volume-Weighted Momentum' signal, where the momentum is normalized by the 20-day standard deviation of returns to ensure cross-sectional stationarity.\n                Concise Observation: Previous iterations failed when using standard deviation in the denominator (creating outliers) or complex Tanh/Z-score transforms (over-parameterization). The most successful model (IR 1.03) used a 20-day lookback for squeeze intensity but lacked a robust volume component that didn't degrade the signal.\n                Concise Justification: Using the ratio of short-term range to medium-term range (Max-Min) provides a bounded, more stable measure of compression than using standard deviation. Normalizing the directional 5-day return by the 20-day volatility (Sharpe-like ratio) ensures that the momentum signal is adjusted for the asset's specific risk regime, while the volume multiplier acts as a conviction filter.\n                Concise Knowledge: If a stock's 5-day price range is significantly smaller than its 20-day price range, it indicates a 'coiling' phase; when this is combined with a volume-weighted 5-day return normalized by historical volatility, it identifies breakouts where price movement is disproportionate to recent noise and supported by liquidity.\n                concise Specification: The factor is defined as: ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) * (($close - $close.shift(5)) / (Std($return, 20) * $close.shift(5) + 1e-6)) * (Mean($volume, 5) / Mean($volume, 20)). This combines a 20/5 range compression ratio, a volatility-adjusted 5-day return, and a 5/20 volume surge ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0058182922470469,
        "ICIR": 0.0359666134509271,
        "RankIC": 0.0190837142510583,
        "RankICIR": 0.1186662918811512,
        "annualized_return": 0.0384624667001231,
        "information_ratio": 0.4579454241354422,
        "max_drawdown": -0.1706529568579493
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:29.587156",
      "updated_at": "2026-01-14T20:03:33.054377"
    },
    "f3d62b60ba880c34": {
      "factor_id": "f3d62b60ba880c34",
      "factor_name": "Ranked_Squeeze_Momentum_Conviction",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) + RANK(TS_PCTCHANGE($close, 5) / (TS_STD($return, 20) + 1e-7)) + RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) + RANK(TS_PCTCHANGE($close, 5) / (TS_STD($return, 20) + 1e-7)) + RANK(TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-7))\" # Your output factor expression will be filled in here\n    name = \"Ranked_Squeeze_Momentum_Conviction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust version of the squeeze hypothesis that uses cross-sectional ranking to normalize the components. It combines the rank of range compression (20d/5d), the rank of volatility-adjusted momentum, and the rank of volume surges to identify high-conviction breakouts.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 6,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is best captured by the interaction between a 'Relative Compression Index' (5-day range vs 20-day range) and a 'Volume-Weighted Momentum' signal, where the momentum is normalized by the 20-day standard deviation of returns to ensure cross-sectional stationarity.\n                Concise Observation: Previous iterations failed when using standard deviation in the denominator (creating outliers) or complex Tanh/Z-score transforms (over-parameterization). The most successful model (IR 1.03) used a 20-day lookback for squeeze intensity but lacked a robust volume component that didn't degrade the signal.\n                Concise Justification: Using the ratio of short-term range to medium-term range (Max-Min) provides a bounded, more stable measure of compression than using standard deviation. Normalizing the directional 5-day return by the 20-day volatility (Sharpe-like ratio) ensures that the momentum signal is adjusted for the asset's specific risk regime, while the volume multiplier acts as a conviction filter.\n                Concise Knowledge: If a stock's 5-day price range is significantly smaller than its 20-day price range, it indicates a 'coiling' phase; when this is combined with a volume-weighted 5-day return normalized by historical volatility, it identifies breakouts where price movement is disproportionate to recent noise and supported by liquidity.\n                concise Specification: The factor is defined as: ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) * (($close - $close.shift(5)) / (Std($return, 20) * $close.shift(5) + 1e-6)) * (Mean($volume, 5) / Mean($volume, 20)). This combines a 20/5 range compression ratio, a volatility-adjusted 5-day return, and a 5/20 volume surge ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0058182922470469,
        "ICIR": 0.0359666134509271,
        "RankIC": 0.0190837142510583,
        "RankICIR": 0.1186662918811512,
        "annualized_return": 0.0384624667001231,
        "information_ratio": 0.4579454241354422,
        "max_drawdown": -0.1706529568579493
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:29.623713",
      "updated_at": "2026-01-14T20:03:33.054380"
    },
    "7122e48e76fdce5a": {
      "factor_id": "7122e48e76fdce5a",
      "factor_name": "Squeeze_Breakout_Efficiency_Index",
      "factor_expression": "((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * TS_PCTCHANGE($close, 5) * ($volume / (TS_MEDIAN($volume, 20) + 1e-7))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-7)) * TS_PCTCHANGE($close, 5) * ($volume / (TS_MEDIAN($volume, 20) + 1e-7))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Breakout_Efficiency_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the intensity of a breakout by multiplying the range compression ratio with the 5-day return, further scaled by the ratio of current volume to its 20-day median to ensure the move is backed by liquidity.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 6,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is best captured by the interaction between a 'Relative Compression Index' (5-day range vs 20-day range) and a 'Volume-Weighted Momentum' signal, where the momentum is normalized by the 20-day standard deviation of returns to ensure cross-sectional stationarity.\n                Concise Observation: Previous iterations failed when using standard deviation in the denominator (creating outliers) or complex Tanh/Z-score transforms (over-parameterization). The most successful model (IR 1.03) used a 20-day lookback for squeeze intensity but lacked a robust volume component that didn't degrade the signal.\n                Concise Justification: Using the ratio of short-term range to medium-term range (Max-Min) provides a bounded, more stable measure of compression than using standard deviation. Normalizing the directional 5-day return by the 20-day volatility (Sharpe-like ratio) ensures that the momentum signal is adjusted for the asset's specific risk regime, while the volume multiplier acts as a conviction filter.\n                Concise Knowledge: If a stock's 5-day price range is significantly smaller than its 20-day price range, it indicates a 'coiling' phase; when this is combined with a volume-weighted 5-day return normalized by historical volatility, it identifies breakouts where price movement is disproportionate to recent noise and supported by liquidity.\n                concise Specification: The factor is defined as: ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) * (($close - $close.shift(5)) / (Std($return, 20) * $close.shift(5) + 1e-6)) * (Mean($volume, 5) / Mean($volume, 20)). This combines a 20/5 range compression ratio, a volatility-adjusted 5-day return, and a 5/20 volume surge ratio.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0058182922470469,
        "ICIR": 0.0359666134509271,
        "RankIC": 0.0190837142510583,
        "RankICIR": 0.1186662918811512,
        "annualized_return": 0.0384624667001231,
        "information_ratio": 0.4579454241354422,
        "max_drawdown": -0.1706529568579493
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:46:29.659617",
      "updated_at": "2026-01-14T20:03:33.054382"
    },
    "73bb4619b3ffbc9f": {
      "factor_id": "73bb4619b3ffbc9f",
      "factor_name": "Liquidity_Convexity_Exhaustion_5D",
      "factor_expression": "SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN($close - DELAY($close, 5)) * (TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Convexity_Exhaustion_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 'blow-off' exhaustion points by calculating the 5-day average of the squared price range relative to volume turnover. This convexity-based approach amplifies signals of extreme price moves on low liquidity. It is normalized by the 20-day standard deviation and signed by the 5-day cumulative return to capture mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.801485",
      "updated_at": "2026-01-14T20:03:33.054384"
    },
    "ec3ba8798b60ab54": {
      "factor_id": "ec3ba8798b60ab54",
      "factor_name": "Convex_Price_Impact_Rank_5D",
      "factor_expression": "RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(POW($high - $low, 2) / ($volume + 1.0), 5) / (TS_STD(POW($high - $low, 2) / ($volume + 1.0), 20) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Convex_Price_Impact_Rank_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional factor targeting price-volume decoupling. It measures the convexity of price 'effort' by squaring the daily range relative to volume, then compares the 5-day average of this impact against its 20-day historical volatility to isolate unsustainable liquidity gaps.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.838225",
      "updated_at": "2026-01-14T20:03:33.054386"
    },
    "01fd11f2d23d962e": {
      "factor_id": "01fd11f2d23d962e",
      "factor_name": "Hollow_Move_Convexity_ZScore",
      "factor_expression": "SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / ($volume + 1.0), 20)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"SIGN(TS_SUM($return, 5)) * TS_ZSCORE(POW($high - $low, 2) / (MAX($volume, 1.0)), 20)\" # Your output factor expression will be filled in here\n    name = \"Hollow_Move_Convexity_ZScore\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses the Z-score of the convexity-adjusted price impact (range squared over volume) to identify outliers in price discovery. By multiplying by the sign of the 5-day return, it positions for a reversal when price expansion significantly outpaces volume support.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 8,
      "hypothesis": "Hypothesis: Short-term mean reversion is triggered by 'Liquidity-Volume Convexity', where the non-linear interaction between the 5-day price range expansion and the 5-day volume turnover identifies 'blow-off' exhaustion points more effectively than linear growth ratios.\n                Concise Observation: Previous attempts using linear growth ratios (Hypothesis 7) improved IC (0.004) but failed to maximize returns, while simple distance-from-mean (Hypothesis 8) failed, suggesting that the relationship between price 'effort' (volume) and 'result' (range) is non-linear and requires a convexity-based approach.\n                Concise Justification: By using the square of the price range in the numerator (convexity) relative to volume turnover, we amplify the signal of extreme 'hollow' moves. This focuses the factor on the tails of the distribution where the most profitable mean-reversion opportunities reside, rather than the noisier central distribution of price-volume changes.\n                Concise Knowledge: If a stock's price range expands at an accelerating rate while volume turnover remains stagnant or declines, the price discovery process is failing due to liquidity gaps; in this scenario, the 'cost' of price movement is too low to be sustainable, leading to a high probability of reversal as liquidity returns.\n                concise Specification: Define a factor that calculates the 5-day average of (($high - $low)^2 / ($volume + 1)). Normalize this 'Convexity Impact' by the 20-day standard deviation of the same ratio to ensure cross-sectional comparability, then multiply by the sign of the 5-day cumulative return to determine reversal direction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.002806382223621,
        "ICIR": 0.0193393828694666,
        "RankIC": 0.0172077352264716,
        "RankICIR": 0.1185236162349854,
        "annualized_return": 0.0355204461840381,
        "information_ratio": 0.4363804794630397,
        "max_drawdown": -0.1509740070837064
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:47:47.879619",
      "updated_at": "2026-01-14T20:03:33.054389"
    },
    "530b4b81842c1774": {
      "factor_id": "530b4b81842c1774",
      "factor_name": "Divergent_ZScore_Reversal_10D",
      "factor_expression": "TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_SUM($return, 10), 20) * (1 - TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Divergent_ZScore_Reversal_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals by measuring the statistical extremity of the price move (Z-score) and weighting it by a 'Divergence Index'. The Divergence Index is calculated as (1 - TS_CORR), which amplifies the signal when price and volume move in opposite directions, indicating trend fragility. The price move is calculated as the negative 10-day return to capture mean-reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.840434",
      "updated_at": "2026-01-14T20:03:33.054392"
    },
    "beda22fd003445b3": {
      "factor_id": "beda22fd003445b3",
      "factor_name": "Climax_Gated_Reversal_Factor",
      "factor_expression": "(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(-1 * TS_SUM($return, 10) / (TS_STD($return, 10) + 1e-8)) * ($volume / (TS_MEAN($volume, 20) + 1e-8)) * (-1 * TS_CORR($close, $volume, 10))\" # Your output factor expression will be filled in here\n    name = \"Climax_Gated_Reversal_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets high-conviction selling climaxes. It uses the 10-day price-volume correlation as a state filter (negated to favor divergence) and multiplies it by a volatility-adjusted 10-day return. It incorporates a Volume Surge component (Volume relative to its 20-day mean) to ensure the reversal is backed by significant liquidity exhaustion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.876983",
      "updated_at": "2026-01-14T20:03:33.054394"
    },
    "c900cc937efad896": {
      "factor_id": "c900cc937efad896",
      "factor_name": "Ranked_Exhaustion_Intensity_10D",
      "factor_expression": "RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_SUM($return, 10)) * MAX(TS_ZSCORE($volume, 20), 0)\" # Your output factor expression will be filled in here\n    name = \"Ranked_Exhaustion_Intensity_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectional approach to the exhaustion hypothesis. It ranks the 10-day price decline and weights it by the 10-day volume Z-score. By using RANK, it identifies the most 'stretched' assets in the universe, while the volume Z-score (clipped at 0) ensures the signal is only active during periods of higher-than-average volume intensity.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 8,
      "hypothesis": "Hypothesis: The 10-day price reversal is most effective when the price drawdown is extreme relative to its 20-day volatility (Z-score) and is conditioned on a 'Volume-Price Divergence Index' that identifies when price declines are no longer supported by increasing volume intensity.\n                Concise Observation: Previous attempts failed when volume was used as a linear multiplier or a simple momentum rank, but succeeded in risk reduction when using correlation states; the highest IR (1.11) was achieved by capturing the 'state' of divergence rather than the 'rate of change'.\n                Concise Justification: Linear multipliers for volume often introduce noise because high volume can signify both capitulation (reversal) and trend confirmation (continuation). By using a Z-score to normalize the price move and a correlation-based 'divergence index' to gate the signal, we isolate periods where the trend's structural integrity is failing, regardless of absolute volume levels.\n                Concise Knowledge: If a price reversal signal is scaled by its volatility-adjusted magnitude and then filtered by a divergence index, it avoids 'falling knives'; when the 10-day price-volume correlation is negative during a drawdown, the likelihood of a mean-reversion event increases as selling pressure becomes disconnected from price action.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * 10-day return, 20)] * [1 - TS_Corr(Close, Volume, 10)]. The first term identifies the statistical extremity of the drawdown, and the second term (Divergence Index) acts as a non-linear weight that amplifies the signal when price and volume move in opposite directions. All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061946163948367,
        "ICIR": 0.0456263081429544,
        "RankIC": 0.0220143221162594,
        "RankICIR": 0.1659007442412237,
        "annualized_return": 0.0529176836404647,
        "information_ratio": 0.6929552536315782,
        "max_drawdown": -0.1047045352305516
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:48:31.914496",
      "updated_at": "2026-01-14T20:03:33.054396"
    },
    "ef219a7524bc4e02": {
      "factor_id": "ef219a7524bc4e02",
      "factor_name": "VW_Efficiency_Gap_v2_20D",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)))) / (WMA(($high - $low) / ($close + 1e-8), 10) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)))) / (WMA(($high - $low) / ($close + 1e-8), 10) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"VW_Efficiency_Gap_v2_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor measures the interaction between volume-ranked momentum and the price's deviation from its 20-day VWAP, normalized by a smoothed relative price range to avoid duplication. It identifies assets in an efficient accumulation phase where high volume-supported returns occur near the institutional cost basis.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 7,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Efficiency Gap', where alpha is maximized by the interaction between the 10-day volume-ranked momentum and the price's deviation from its 20-day volume-weighted average price, normalized by the 20-day rolling price range.\n                Concise Observation: Previous iterations (Hypothesis 6) achieved a high IC (0.0038) by using volume-weighted returns and VWAP filters, but failed on IR/Returns due to the 'convexity' (10d-20d) term being too noisy and the 5-day VWAP being too reactive.\n                Concise Justification: A 20-day VWAP provides a more stable institutional cost-basis anchor than a 5-day window. By replacing the 'acceleration' subtraction with a direct persistence measure and normalizing by a robust volatility proxy (High-Low range), we aim to retain the high IC while improving the signal-to-noise ratio for better risk-adjusted returns.\n                Concise Knowledge: If volume-weighted momentum is high while the price remains close to or slightly above its 20-day VWAP, the asset is in an efficient accumulation phase; when this signal is scaled by the high-low range, it accounts for asset-specific volatility without the instability of standard deviation.\n                concise Specification: The factor 'VW_Efficiency_Gap_20D' is calculated as the 10-day rolling mean of ($return * rank($volume)) multiplied by the ratio ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))), all divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.00310286363765,
        "ICIR": 0.0239724348684757,
        "RankIC": 0.0184843273960079,
        "RankICIR": 0.1457955762559876,
        "annualized_return": 0.0261503792401489,
        "information_ratio": 0.43320028836764,
        "max_drawdown": -0.0934994899682903
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:50:57.486920",
      "updated_at": "2026-01-14T20:03:33.054398"
    },
    "567c55a5ab626cc8": {
      "factor_id": "567c55a5ab626cc8",
      "factor_name": "Persistence_Adjusted_VWAP_Conviction",
      "factor_expression": "TS_ZSCORE(TS_MEAN($return * RANK($volume), 10), 20) * ($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(TS_MEAN($return * RANK($volume), 10), 20) * ($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Persistence_Adjusted_VWAP_Conviction\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the efficiency gap that replaces the simple range normalization with a Z-score of the volume-weighted return persistence, scaled by the price's position relative to the 20-day VWAP. This focuses on the stability of the signal relative to its own history.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 7,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Efficiency Gap', where alpha is maximized by the interaction between the 10-day volume-ranked momentum and the price's deviation from its 20-day volume-weighted average price, normalized by the 20-day rolling price range.\n                Concise Observation: Previous iterations (Hypothesis 6) achieved a high IC (0.0038) by using volume-weighted returns and VWAP filters, but failed on IR/Returns due to the 'convexity' (10d-20d) term being too noisy and the 5-day VWAP being too reactive.\n                Concise Justification: A 20-day VWAP provides a more stable institutional cost-basis anchor than a 5-day window. By replacing the 'acceleration' subtraction with a direct persistence measure and normalizing by a robust volatility proxy (High-Low range), we aim to retain the high IC while improving the signal-to-noise ratio for better risk-adjusted returns.\n                Concise Knowledge: If volume-weighted momentum is high while the price remains close to or slightly above its 20-day VWAP, the asset is in an efficient accumulation phase; when this signal is scaled by the high-low range, it accounts for asset-specific volatility without the instability of standard deviation.\n                concise Specification: The factor 'VW_Efficiency_Gap_20D' is calculated as the 10-day rolling mean of ($return * rank($volume)) multiplied by the ratio ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))), all divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.00310286363765,
        "ICIR": 0.0239724348684757,
        "RankIC": 0.0184843273960079,
        "RankICIR": 0.1457955762559876,
        "annualized_return": 0.0261503792401489,
        "information_ratio": 0.43320028836764,
        "max_drawdown": -0.0934994899682903
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:50:57.523224",
      "updated_at": "2026-01-14T20:03:33.054400"
    },
    "899eb901a112f8b8": {
      "factor_id": "899eb901a112f8b8",
      "factor_name": "Log_Efficiency_Volume_Momentum",
      "factor_expression": "TS_MEAN($return * RANK($volume), 10) * LOG($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_MEAN($return * RANK($volume), 10) * LOG($close / (TS_MEAN($close * $volume, 20) / (TS_MEAN($volume, 20) + 1e-8)) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Log_Efficiency_Volume_Momentum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a logarithmic transformation of the price-to-VWAP ratio to dampen the impact of price spikes, combined with the 10-day volume-ranked momentum. It aims to capture institutional accumulation trends with a more symmetric distribution.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 7,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Efficiency Gap', where alpha is maximized by the interaction between the 10-day volume-ranked momentum and the price's deviation from its 20-day volume-weighted average price, normalized by the 20-day rolling price range.\n                Concise Observation: Previous iterations (Hypothesis 6) achieved a high IC (0.0038) by using volume-weighted returns and VWAP filters, but failed on IR/Returns due to the 'convexity' (10d-20d) term being too noisy and the 5-day VWAP being too reactive.\n                Concise Justification: A 20-day VWAP provides a more stable institutional cost-basis anchor than a 5-day window. By replacing the 'acceleration' subtraction with a direct persistence measure and normalizing by a robust volatility proxy (High-Low range), we aim to retain the high IC while improving the signal-to-noise ratio for better risk-adjusted returns.\n                Concise Knowledge: If volume-weighted momentum is high while the price remains close to or slightly above its 20-day VWAP, the asset is in an efficient accumulation phase; when this signal is scaled by the high-low range, it accounts for asset-specific volatility without the instability of standard deviation.\n                concise Specification: The factor 'VW_Efficiency_Gap_20D' is calculated as the 10-day rolling mean of ($return * rank($volume)) multiplied by the ratio ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))), all divided by the 20-day rolling average of ($high - $low) / $close.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.00310286363765,
        "ICIR": 0.0239724348684757,
        "RankIC": 0.0184843273960079,
        "RankICIR": 0.1457955762559876,
        "annualized_return": 0.0261503792401489,
        "information_ratio": 0.43320028836764,
        "max_drawdown": -0.0934994899682903
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:50:57.559059",
      "updated_at": "2026-01-14T20:03:33.054403"
    },
    "c3831ffe9f1d8c8c": {
      "factor_id": "c3831ffe9f1d8c8c",
      "factor_name": "Volume_Price_Resistance_Efficiency_5D",
      "factor_expression": "RANK(TS_MEAN(($high - $low) / ($volume + 1), 5) * (( $close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN(($high - $low) / ($volume + 1), 5) * (( $close - TS_MEAN($close, 5)) / (TS_STD($close, 5) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Resistance_Efficiency_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term exhaustion by measuring the 'price impact per volume' (Resistance Efficiency) and weighting it by the price's distance from its 5-day mean. High resistance efficiency combined with an overextended price (high Z-score) suggests a 'hollow' move prone to mean reversion.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.856478",
      "updated_at": "2026-01-14T20:03:33.054405"
    },
    "a7b2276045c16adc": {
      "factor_id": "a7b2276045c16adc",
      "factor_name": "Normalized_Exhaustion_Impact_20D",
      "factor_expression": "ZSCORE((TS_MEAN(($high - $low) / ($volume + 1), 5) / (TS_STD(($high - $low) / ($volume + 1), 20) + 1e-8)) * SIGN($close - TS_MEAN($close, 5)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((TS_MEAN(($high - $low) / ($volume + 1), 5) / (TS_STD(($high - $low) / ($volume + 1), 20) + 1e-8)) * SIGN($close - TS_MEAN($close, 5)))\" # Your output factor expression will be filled in here\n    name = \"Normalized_Exhaustion_Impact_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor refines the price-volume resistance by normalizing the 5-day average price impact (range/volume) by its 20-day historical volatility. This ensures that the exhaustion signal is relative to the stock's own liquidity regime, identifying true 'low-progress' anomalies.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.894568",
      "updated_at": "2026-01-14T20:03:33.054407"
    },
    "c633563812707c64": {
      "factor_id": "c633563812707c64",
      "factor_name": "Effort_Result_Divergence_5D",
      "factor_expression": "RANK(($high - $low) / (TS_MEAN($volume, 5) + 1)) * RANK($close - TS_MEAN($close, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($high - $low) / (TS_MEAN($volume, 5) + 1)) * RANK($close - TS_MEAN($close, 5))\" # Your output factor expression will be filled in here\n    name = \"Effort_Result_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the divergence between price effort (volume turnover) and price result (range). It specifically targets points where the price is far from its 5-day VWAP-proxy (TS_MEAN) but the volume-normalized range is at an extreme, signaling a blow-off top or bottom.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 9,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Resistance Efficiency', where the 5-day price range is normalized by the 5-day volume turnover and then adjusted by the 'Close-Range Persistence' to identify high-effort, low-progress exhaustion points.\n                Concise Observation: Previous 'convexity' attempts (Hypothesis 8) using squared ranges improved IC but failed on IR because the signal was too sensitive to outliers and used a binary SIGN function that ignored the magnitude of the price's failure to 'stick' at the highs/lows.\n                Concise Justification: By replacing the squared range with a linear range-to-volume ratio and weighting it by the distance of the current close from the 5-day VWAP, we capture both the 'liquidity gap' and the 'failure to sustain' the move. This avoids the noise of squared terms while providing a continuous weighting for the reversal signal.\n                Concise Knowledge: If a stock's intraday price range expands significantly but the closing price fails to maintain the extreme (reverting toward the 5-day mean), and this occurs on low relative volume turnover, the price move is 'fragile'; When high price impact is not sustained by the close, the 'resistance' to the trend is high, signaling an imminent reversal.\n                concise Specification: Calculate the 5-day average of ($high - $low) / ($volume + 1). Multiply this by the Z-score of the current $close relative to its 5-day moving average. Normalize the final product by the 20-day standard deviation of the range-to-volume ratio to ensure cross-sectional stability and apply a cross-sectional rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0004801588193177,
        "ICIR": 0.0031093380564516,
        "RankIC": 0.0123419195338017,
        "RankICIR": 0.0782987461579328,
        "annualized_return": 0.0055363780276607,
        "information_ratio": 0.0627444946318298,
        "max_drawdown": -0.2762973462453435
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:51:58.932099",
      "updated_at": "2026-01-14T20:03:33.054409"
    },
    "9cf6827b450da659": {
      "factor_id": "9cf6827b450da659",
      "factor_name": "Volume_Concentrated_Reversal_20D",
      "factor_expression": "TS_ZSCORE(-1 * TS_PCTCHANGE($close, 10), 20) * (DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 10) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_ZSCORE(-1 * TS_PCTCHANGE($close, 10), 20) * (DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 10) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Volume_Concentrated_Reversal_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies 10-day price reversals where selling pressure is 'front-loaded' within the lookback window. It combines a volatility-adjusted 10-day drawdown with a 'Volume Concentration' ratio (volume in the first 5 days of the 10-day window relative to the total 10-day volume). High concentration suggests that the majority of selling occurred early, indicating subsequent exhaustion and a higher probability of mean reversion.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the price drawdown is extreme relative to its 20-day volatility and is validated by a 'Volume Concentration' state, where a high percentage of the 10-day volume occurs during the first half of the drawdown period, indicating subsequent selling exhaustion.\n                Concise Observation: Previous attempts using 10-day correlation (SOTA IR 1.11) and volume Z-scores (high IC 0.0062) struggled to balance raw alpha and stability, likely because they ignored the 'temporal distribution' of volume within the lookback window, which distinguishes between active capitulation and ongoing trend persistence.\n                Concise Justification: Market microstructure suggests that a 'selling climax' followed by a 'low-volume tail' is a more reliable reversal signal than a climax at the very end of the window. By measuring the ratio of volume in the first 5 days versus the total 10-day volume (Volume Concentration), we can identify if the 'pain' has already peaked, allowing for a safer entry into the reversal.\n                Concise Knowledge: If a short-term price decline is front-loaded with high volume (liquidity shock) followed by a price drift on lower volume, it indicates that the majority of selling pressure has been absorbed; when volume concentration is high in the early phase of a 10-day window, the probability of a mean-reversion bounce in the following days is significantly higher than if volume is back-loaded.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * (Close / Delay(Close, 10) - 1), 20)] * [Sum(Volume, 5, 5) / Sum(Volume, 10)]. The first term is the 20-day Z-score of the 10-day return; the second term is the ratio of volume from day t-10 to t-6 relative to the total volume from t-10 to t-1. All data is from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0034116384551348,
        "ICIR": 0.0252113197343331,
        "RankIC": 0.019584592435801,
        "RankICIR": 0.1510952568680467,
        "annualized_return": 0.049572175469758,
        "information_ratio": 0.7335331914229961,
        "max_drawdown": -0.094772055553972
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:53:23.783134",
      "updated_at": "2026-01-14T20:03:33.054448"
    },
    "70587a0f9ccf9eb7": {
      "factor_id": "70587a0f9ccf9eb7",
      "factor_name": "Exhaustion_Climax_Concentration_Factor",
      "factor_expression": "RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * DELTA($close, 10) / (TS_STD($return, 20) * $close + 1e-8)) * RANK(DELAY(TS_SUM($volume, 5), 5) / (TS_SUM($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Exhaustion_Climax_Concentration_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets mean-reversion by filtering extreme 10-day drawdowns with a temporal volume distribution check. It uses the cross-sectional rank of the volatility-normalized return multiplied by the ratio of early-window volume to late-window volume. A high ratio indicates that the selling climax has likely passed, reducing the risk of catching a 'falling knife'.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 9,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when the price drawdown is extreme relative to its 20-day volatility and is validated by a 'Volume Concentration' state, where a high percentage of the 10-day volume occurs during the first half of the drawdown period, indicating subsequent selling exhaustion.\n                Concise Observation: Previous attempts using 10-day correlation (SOTA IR 1.11) and volume Z-scores (high IC 0.0062) struggled to balance raw alpha and stability, likely because they ignored the 'temporal distribution' of volume within the lookback window, which distinguishes between active capitulation and ongoing trend persistence.\n                Concise Justification: Market microstructure suggests that a 'selling climax' followed by a 'low-volume tail' is a more reliable reversal signal than a climax at the very end of the window. By measuring the ratio of volume in the first 5 days versus the total 10-day volume (Volume Concentration), we can identify if the 'pain' has already peaked, allowing for a safer entry into the reversal.\n                Concise Knowledge: If a short-term price decline is front-loaded with high volume (liquidity shock) followed by a price drift on lower volume, it indicates that the majority of selling pressure has been absorbed; when volume concentration is high in the early phase of a 10-day window, the probability of a mean-reversion bounce in the following days is significantly higher than if volume is back-loaded.\n                concise Specification: The factor is defined as: [TS_ZScore(-1 * (Close / Delay(Close, 10) - 1), 20)] * [Sum(Volume, 5, 5) / Sum(Volume, 10)]. The first term is the 20-day Z-score of the 10-day return; the second term is the ratio of volume from day t-10 to t-6 relative to the total volume from t-10 to t-1. All data is from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0034116384551348,
        "ICIR": 0.0252113197343331,
        "RankIC": 0.019584592435801,
        "RankICIR": 0.1510952568680467,
        "annualized_return": 0.049572175469758,
        "information_ratio": 0.7335331914229961,
        "max_drawdown": -0.094772055553972
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:53:23.820498",
      "updated_at": "2026-01-14T20:03:33.054451"
    },
    "02cbecb3e4566b4d": {
      "factor_id": "02cbecb3e4566b4d",
      "factor_name": "Relative_Compression_Ranked_Momentum_5D",
      "factor_expression": "RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) / (TS_MEAN($volume, 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Relative_Compression_Ranked_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies volatility squeezes by calculating the ratio of the 20-day price range to the 5-day price range, using this to weight a cross-sectionally ranked 5-day momentum signal. To isolate high-conviction breakouts and avoid crowded trades, it is neutralized by the 20-day average volume, targeting quiet consolidations.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.232562",
      "updated_at": "2026-01-14T20:03:33.054454"
    },
    "3eae7d08e007715b": {
      "factor_id": "3eae7d08e007715b",
      "factor_name": "Coiled_Momentum_Volume_Divergence_10D",
      "factor_expression": "TS_PCTCHANGE($close, 5) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-4)) * INV(TS_MEAN($volume, 5) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_PCTCHANGE($close, 5) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-4)) * INV(TS_MEAN($volume, 5) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Coiled_Momentum_Volume_Divergence_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'coiling' effect of price by comparing the 20-day range to the 10-day range. This compression index weights the 5-day return. The result is divided by the 5-day volume mean to favor breakouts occurring on lower relative volume, which suggests institutional accumulation rather than retail climaxes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.268860",
      "updated_at": "2026-01-14T20:03:33.054456"
    },
    "3e6761654f9ad4a1": {
      "factor_id": "3e6761654f9ad4a1",
      "factor_name": "Squeeze_Conviction_ZScore_Signal",
      "factor_expression": "ZSCORE(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) * (TS_MEAN($volume, 20) / (TS_MEAN($volume, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_PCTCHANGE($close, 5)) * ((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-4)) * (TS_MEAN($volume, 20) / (TS_MEAN($volume, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Squeeze_Conviction_ZScore_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Combines a 20/5 range compression index with a Z-scored 5-day return. By using ZSCORE, the momentum signal is normalized across the market. The factor is then adjusted by the inverse of the 5-day volume to highlight breakouts from 'quiet' consolidations where price-volume divergence is highest.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 7,
      "hypothesis": "Hypothesis: The predictive power of a volatility squeeze is maximized when the 'Relative Compression Index' (20-day range / 5-day range) is used to weight a 5-day momentum signal that has been cross-sectionally ranked and then neutralized by the 20-day average volume to isolate price-volume divergence.\n                Concise Observation: Previous attempts with multiplicative volume surges (5D/20D volume) and raw volatility ratios led to high IC but poor IR and high drawdowns, indicating that the 'volume surge' might be a lagging indicator or a source of noise that creates extreme, unstable factor values.\n                Concise Justification: By using the 20/5 range ratio as a scaling factor for ranked momentum, we emphasize 'coiled' stocks. Neutralizing this by the volume ratio (dividing by Mean(Vol,5)/Mean(Vol,20)) targets the 'low-volume pullbacks' or 'quiet consolidations' that often precede the most sustainable trends, avoiding the 'crowded' trades that lead to the high drawdowns observed in previous iterations.\n                Concise Knowledge: If a volatility squeeze (range contraction) is present, the subsequent momentum is more predictive when it is cross-sectionally significant and occurs on relatively lower volume than the historical average, suggesting a 'quiet' institutional accumulation before a public breakout; when volume surges too early, it often indicates a climax rather than a start.\n                concise Specification: The factor is defined as: Rank(($close - $close.shift(5)) / $close.shift(5)) * ((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) / (Mean($volume, 5) / Mean($volume, 20) + 1e-6). This combines cross-sectional momentum, range-based compression, and inverse volume-surge conviction.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039934214482519,
        "ICIR": 0.0240124395629409,
        "RankIC": 0.0160202053034139,
        "RankICIR": 0.0971087529936679,
        "annualized_return": 0.0365853284152005,
        "information_ratio": 0.3895969162206856,
        "max_drawdown": -0.2296415339764823
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:54:15.304794",
      "updated_at": "2026-01-14T20:03:33.054458"
    },
    "351ac7234f11b736": {
      "factor_id": "351ac7234f11b736",
      "factor_name": "VW_Momentum_Conviction_Interaction_20D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10)) * RANK($close * INV(TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8)))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Conviction_Interaction_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the interaction between volume-weighted price momentum and the relative distance from the institutional cost basis. It uses the 10-day rolling mean of return scaled by cross-sectional volume rank to identify institutional conviction, and multiplies it by the rank of the price-to-VWAP ratio. The VWAP is calculated over 20 days. By using the product of two ranked components, it preserves signal intensity for stocks where both momentum and positioning are extreme.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.562820",
      "updated_at": "2026-01-14T20:03:33.054460"
    },
    "8cd6723351ebfc5d": {
      "factor_id": "8cd6723351ebfc5d",
      "factor_name": "Institutional_Efficiency_ZScore_Signal",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ZSCORE($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Efficiency_ZScore_Signal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by combining the 10-day volume-ranked momentum with a standardized measure of price deviation from the 20-day VWAP. Instead of a simple ratio, it uses the cross-sectional Z-score of the price-to-VWAP distance to highlight statistical outliers in institutional accumulation, ensuring the factor captures high-magnitude alpha as hypothesized.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.602822",
      "updated_at": "2026-01-14T20:03:33.054463"
    },
    "8f0ff1e46d6e06e7": {
      "factor_id": "8f0ff1e46d6e06e7",
      "factor_name": "Volume_Weighted_Momentum_Anchor_Ratio",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) * ($close / (TS_SUM($close * $volume, 20) / (TS_SUM($volume, 20) + 1e-8))))\" # Your output factor expression will be filled in here\n    name = \"Volume_Weighted_Momentum_Anchor_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'Efficiency Gap' by multiplying the 10-day persistence of volume-weighted returns with the ratio of the current price to its 20-day volume-weighted anchor. To avoid duplication and preserve signal strength, the VWAP is calculated using TS_SUM and the final interaction is cross-sectionally ranked to focus on relative institutional conviction.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 8,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum-Volatility Coupling', where alpha is maximized by the product of 10-day volume-ranked momentum and the 20-day price-to-VWAP deviation, specifically when the entire signal is cross-sectionally ranked to preserve the magnitude of extreme institutional conviction.\n                Concise Observation: Previous attempts (Hypothesis 7) improved IC and Drawdown but lost Annualized Return because Z-scoring and log-transforms dampened the signal intensity of extreme 'Efficiency Gaps' that drive high-magnitude alpha.\n                Concise Justification: Using a ratio of $close to a 20-day VWAP provides a stable anchor for 'value' relative to volume, and multiplying it by volume-ranked momentum creates a non-linear interaction that highlights stocks where price strength and liquidity support coincide. Cross-sectional ranking at the final stage ensures the factor is robust across different market regimes without losing the ordinal strength of the signal.\n                Concise Knowledge: If volume-weighted momentum is coupled with price distance from the institutional cost basis (VWAP), the signal identifies high-conviction trends; when this interaction is cross-sectionally ranked rather than Z-scored or logged, it preserves the predictive power of tail events while mitigating the noise of absolute price-volume scales.\n                concise Specification: The factor 'VW_Momentum_Coupling_20D' is calculated as the product of the 10-day rolling mean of ($return * rank($volume)) and the ratio of $close to the 20-day VWAP (ts_mean($close * $volume, 20) / ts_mean($volume, 20)). The final product is then cross-sectionally ranked.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0023476404545392,
        "ICIR": 0.0172182352430621,
        "RankIC": 0.0169251180078106,
        "RankICIR": 0.123532233324347,
        "annualized_return": 0.0215490288551366,
        "information_ratio": 0.2855814635249779,
        "max_drawdown": -0.1854644504403794
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:56:26.640127",
      "updated_at": "2026-01-14T20:03:33.054465"
    },
    "cbce99eb55085aec": {
      "factor_id": "cbce99eb55085aec",
      "factor_name": "Price_Convexity_Volume_Decay_Reversal",
      "factor_expression": "RANK(-1 * TS_PCTCHANGE($close, 10)) * RANK($close - 2 * DELAY($close, 2) + DELAY($close, 4)) * RANK(DELAY($volume, 5) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(-1 * TS_PCTCHANGE($close, 10)) * RANK($close - 2 * DELAY($close, 2) + DELAY($close, 4)) * RANK(DELAY($volume, 5) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Price_Convexity_Volume_Decay_Reversal\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term price reversals by detecting 'Volume-Price Convexity'. It combines the 10-day price reversal magnitude with the second derivative of price (acceleration/convexity) and a volume decay ratio. A positive convexity (price rounding out) coupled with volume being lower than its recent peak (exhaustion) signals a high-probability bounce from a low-liquidity floor.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 10,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when an extreme price drawdown is accompanied by 'Volume-Price Convexity,' where the rate of price decline slows down (deceleration) while volume remains below its recent peak, indicating the transition from panic selling to a low-liquidity floor.\n                Concise Observation: Previous attempts using fixed volume splits (front-loading) or linear correlation failed to capture the 'turning point' accurately, whereas the SOTA's success with 'state of divergence' suggests that the relationship between price stability and volume depletion is the key to timing the bounce.\n                Concise Justification: A 'selling climax' (high volume) creates the initial dislocation, but the 'reversal' occurs only when the price stops making new lows at an accelerating rate. By measuring the change in the slope of the price decline (convexity) alongside volume decay, we identify the exact phase where sellers are exhausted and the price begins to 'round out' at the bottom.\n                Concise Knowledge: If a price trend exhibits deceleration (positive price curvature) while volume is declining from a recent climax, the asset is entering a 'low-liquidity floor' where minor buying pressure can trigger a sharp reversal; when price momentum is negative but the second derivative of price is positive, the trend's kinetic energy is exhausted.\n                concise Specification: The factor is defined as: [CS_Rank(-1 * 10-day return)] * [CS_Rank(Close - 2*Delay(Close, 2) + Delay(Close, 4))] * [CS_Rank(Delay(Volume, 5) / Volume)]. The first term is the reversal magnitude, the second term is the 5-day price acceleration (Laplacian/Convexity), and the third term is the volume decay ratio (comparing past volume to current volume). All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0080192044025683,
        "ICIR": 0.0564115754859962,
        "RankIC": 0.0236258059882162,
        "RankICIR": 0.1694238604093791,
        "annualized_return": 0.0846392810645387,
        "information_ratio": 1.0883867942476673,
        "max_drawdown": -0.0741937755470449
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:58:58.077947",
      "updated_at": "2026-01-14T20:03:33.054467"
    },
    "510cb2e92b701156": {
      "factor_id": "510cb2e92b701156",
      "factor_name": "Decelerated_Drawdown_Exhaustion_Factor",
      "factor_expression": "ZSCORE((DELAY($close, 2) - $close) / (TS_STD($return, 20) + 1e-8)) * ZSCORE(TS_MAX($volume, 10) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((DELAY($close, 2) - $close) / (TS_STD($return, 20) + 1e-8)) * ZSCORE(TS_MAX($volume, 10) / ($volume + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decelerated_Drawdown_Exhaustion_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor targets the 'turning point' of a decline by measuring the interaction between price deceleration and volume depletion. It uses the Laplacian of the price (second difference) to find where the rate of decline is slowing down, weighted by the ratio of the 5-day volume peak to current volume to ensure the reversal happens after a selling climax has passed.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 10,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when an extreme price drawdown is accompanied by 'Volume-Price Convexity,' where the rate of price decline slows down (deceleration) while volume remains below its recent peak, indicating the transition from panic selling to a low-liquidity floor.\n                Concise Observation: Previous attempts using fixed volume splits (front-loading) or linear correlation failed to capture the 'turning point' accurately, whereas the SOTA's success with 'state of divergence' suggests that the relationship between price stability and volume depletion is the key to timing the bounce.\n                Concise Justification: A 'selling climax' (high volume) creates the initial dislocation, but the 'reversal' occurs only when the price stops making new lows at an accelerating rate. By measuring the change in the slope of the price decline (convexity) alongside volume decay, we identify the exact phase where sellers are exhausted and the price begins to 'round out' at the bottom.\n                Concise Knowledge: If a price trend exhibits deceleration (positive price curvature) while volume is declining from a recent climax, the asset is entering a 'low-liquidity floor' where minor buying pressure can trigger a sharp reversal; when price momentum is negative but the second derivative of price is positive, the trend's kinetic energy is exhausted.\n                concise Specification: The factor is defined as: [CS_Rank(-1 * 10-day return)] * [CS_Rank(Close - 2*Delay(Close, 2) + Delay(Close, 4))] * [CS_Rank(Delay(Volume, 5) / Volume)]. The first term is the reversal magnitude, the second term is the 5-day price acceleration (Laplacian/Convexity), and the third term is the volume decay ratio (comparing past volume to current volume). All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0080192044025683,
        "ICIR": 0.0564115754859962,
        "RankIC": 0.0236258059882162,
        "RankICIR": 0.1694238604093791,
        "annualized_return": 0.0846392810645387,
        "information_ratio": 1.0883867942476673,
        "max_drawdown": -0.0741937755470449
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:58:58.114081",
      "updated_at": "2026-01-14T20:03:33.054469"
    },
    "8b8d02a95d55c0a1": {
      "factor_id": "8b8d02a95d55c0a1",
      "factor_name": "Kinetic_Energy_Exhaustion_Index",
      "factor_expression": "RANK($close - 2 * DELAY($close, 1) + DELAY($close, 2)) * RANK(TS_MEAN($volume, 10) / ($volume + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((DELTA($close, 1) < 0) && (($close - 2 * DELAY($close, 1) + DELAY($close, 2)) > 0)) ? (RANK($close - 2 * DELAY($close, 1) + DELAY($close, 2)) * RANK(TS_MAX($volume, 5) / ($volume + 1e-8))) : (0)\" # Your output factor expression will be filled in here\n    name = \"Kinetic_Energy_Exhaustion_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the exhaustion of a trend's kinetic energy by identifying when price momentum is negative but the curvature (convexity) is positive, suggesting the price is 'rounding' at a bottom. This is conditioned on volume being significantly lower than the climax level observed in the previous week.",
      "experiment_id": "2026-01-14_08-54-44-885373",
      "round_number": 10,
      "hypothesis": "Hypothesis: The 10-day price reversal is most predictive when an extreme price drawdown is accompanied by 'Volume-Price Convexity,' where the rate of price decline slows down (deceleration) while volume remains below its recent peak, indicating the transition from panic selling to a low-liquidity floor.\n                Concise Observation: Previous attempts using fixed volume splits (front-loading) or linear correlation failed to capture the 'turning point' accurately, whereas the SOTA's success with 'state of divergence' suggests that the relationship between price stability and volume depletion is the key to timing the bounce.\n                Concise Justification: A 'selling climax' (high volume) creates the initial dislocation, but the 'reversal' occurs only when the price stops making new lows at an accelerating rate. By measuring the change in the slope of the price decline (convexity) alongside volume decay, we identify the exact phase where sellers are exhausted and the price begins to 'round out' at the bottom.\n                Concise Knowledge: If a price trend exhibits deceleration (positive price curvature) while volume is declining from a recent climax, the asset is entering a 'low-liquidity floor' where minor buying pressure can trigger a sharp reversal; when price momentum is negative but the second derivative of price is positive, the trend's kinetic energy is exhausted.\n                concise Specification: The factor is defined as: [CS_Rank(-1 * 10-day return)] * [CS_Rank(Close - 2*Delay(Close, 2) + Delay(Close, 4))] * [CS_Rank(Delay(Volume, 5) / Volume)]. The first term is the reversal magnitude, the second term is the 5-day price acceleration (Laplacian/Convexity), and the third term is the volume decay ratio (comparing past volume to current volume). All inputs are from daily_pv.h5.\n                ",
      "initial_direction": "均值回归",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0080192044025683,
        "ICIR": 0.0564115754859962,
        "RankIC": 0.0236258059882162,
        "RankICIR": 0.1694238604093791,
        "annualized_return": 0.0846392810645387,
        "information_ratio": 1.0883867942476673,
        "max_drawdown": -0.0741937755470449
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T17:58:58.149758",
      "updated_at": "2026-01-14T20:03:33.054471"
    },
    "310db097c90e330a": {
      "factor_id": "310db097c90e330a",
      "factor_name": "Volume_Price_Flow_Divergence_5D",
      "factor_expression": "RANK(TS_SUM($return, 5) * TS_MEAN(1 / (ABS($close - ($volume * $close / ($volume + 1e-9))) + 1e-9), 5) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_SUM(TS_PCTCHANGE($close, 1), 5) * TS_MEAN(INV(ABS($close - (($open + $high + $low + $close) / 4)) + 1e-9), 5) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Volume_Price_Flow_Divergence_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies short-term mean reversion by measuring the 5-day cumulative return weighted by the inverse of the price spread (Close vs VWAP proxy). It scales this by the ratio of short-term (5-day) to long-term (20-day) volume turnover to isolate liquidity-driven exhaustion where price moves on declining participation.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 10,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Flow Divergence', where the 5-day cumulative return is weighted by the inverse of the volume-weighted price spread (VWAP vs Close) and filtered by the 5-day volume turnover trend to isolate liquidity-driven exhaustion.\n                Concise Observation: Previous attempts using range-to-volume ratios (Hypothesis 9) failed because they were too sensitive to single-day volume outliers; however, the successful Hypothesis 6 and 7 showed that price-volume decoupling is a valid signal when properly normalized against a volatility baseline.\n                Concise Justification: Using the distance between Close and VWAP provides a more stable measure of 'price extension' than raw range, as it represents the deviation from the average cost of participants. Normalizing this by a volume turnover trend (rather than a static sum) allows the factor to identify the specific 'tipping point' where price continues to move but liquidity participation (the 'fuel') is withdrawing.\n                Concise Knowledge: If a price move occurs with a widening gap between the closing price and the volume-weighted average price (VWAP) while volume turnover is declining, the move is likely a liquidity-driven 'hollow' extension; When price is overextended but volume support (turnover) is high, the trend is more likely to persist rather than revert.\n                concise Specification: Calculate the 5-day cumulative return. Multiply this by the 5-day average of (1 / (abs($close - ($volume * $close / $volume)) + 1e-9)). Scale this product by the ratio of the 5-day average volume to the 20-day average volume to capture the 'volume decay'. Apply a cross-sectional rank to the final value over a 5-day window.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.340770",
      "updated_at": "2026-01-14T20:03:33.054474"
    },
    "b5a2ce666f23f2e3": {
      "factor_id": "b5a2ce666f23f2e3",
      "factor_name": "Liquidity_Exhaustion_Tipping_Point_5D",
      "factor_expression": "TS_SUM($return, 5) / (TS_MEAN(ABS($close - ($volume * $close / ($volume + 1e-9))), 5) + 1e-9) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"TS_SUM($return, 5) * INV(TS_MEAN(ABS($close - TS_MEAN($close, 5)), 5) + 1e-9) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Exhaustion_Tipping_Point_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Captures the 'tipping point' of price moves by multiplying the 5-day return with the inverse of the absolute deviation between price and its volume-weighted cost. The factor is normalized by the volume decay ratio (5D/20D volume) to highlight 'hollow' price extensions that lack liquidity support.",
      "experiment_id": "2026-01-14_09-09-42-522148",
      "round_number": 10,
      "hypothesis": "Hypothesis: Short-term mean reversion is driven by 'Volume-Price Flow Divergence', where the 5-day cumulative return is weighted by the inverse of the volume-weighted price spread (VWAP vs Close) and filtered by the 5-day volume turnover trend to isolate liquidity-driven exhaustion.\n                Concise Observation: Previous attempts using range-to-volume ratios (Hypothesis 9) failed because they were too sensitive to single-day volume outliers; however, the successful Hypothesis 6 and 7 showed that price-volume decoupling is a valid signal when properly normalized against a volatility baseline.\n                Concise Justification: Using the distance between Close and VWAP provides a more stable measure of 'price extension' than raw range, as it represents the deviation from the average cost of participants. Normalizing this by a volume turnover trend (rather than a static sum) allows the factor to identify the specific 'tipping point' where price continues to move but liquidity participation (the 'fuel') is withdrawing.\n                Concise Knowledge: If a price move occurs with a widening gap between the closing price and the volume-weighted average price (VWAP) while volume turnover is declining, the move is likely a liquidity-driven 'hollow' extension; When price is overextended but volume support (turnover) is high, the trend is more likely to persist rather than revert.\n                concise Specification: Calculate the 5-day cumulative return. Multiply this by the 5-day average of (1 / (abs($close - ($volume * $close / $volume)) + 1e-9)). Scale this product by the ratio of the 5-day average volume to the 20-day average volume to capture the 'volume decay'. Apply a cross-sectional rank to the final value over a 5-day window.\n                ",
      "initial_direction": "参考以下组合给出假设。组合6包含BETA5（表达式：Slope(, 5)/，含义：5日价格线性回归斜率，反映短期趋势方向）、CNTD5（表达式：Mean(>Ref(, 1), 5)-Mean(<Ref(, 1), 5)，含义：5日涨跌天数差，反映短期涨跌占优程度）、IMXD5（表达式：(IdxMax(, 5)-IdxMin(, 5))/5，含义：5日高低点出现时间差，反映价格反转节奏）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.381931",
      "updated_at": "2026-01-14T20:03:33.054476"
    },
    "dc158e72b35d4132": {
      "factor_id": "dc158e72b35d4132",
      "factor_name": "WRSQR_V_Divergence_Product",
      "factor_expression": "RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) * RANK((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"WRSQR_V_Divergence_Product\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR) with a volume-price divergence ratio. WRSQR20 is calculated as the squared correlation between close prices and a linear sequence over 20 days, weighted by DECAYLINEAR to prioritize recent trend consistency. V_Divergence is the ratio of the 5-day VWAP to the 5-day SMA, acting as a filter for institutional accumulation. The final factor is the product of their cross-sectional ranks.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.447954",
      "updated_at": "2026-01-14T20:03:33.054479"
    },
    "6b09649c0a1463db": {
      "factor_id": "6b09649c0a1463db",
      "factor_name": "Decay_Stability_Accumulation_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE((TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8)) / (SMA($close, 5, 1) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Decay_Stability_Accumulation_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the stability-momentum hypothesis. It uses the 20-day weighted R-squared (via DECAYLINEAR) to capture 'fresh' trend stability and scales it by the 5-day VWAP-to-SMA ratio to identify volume-supported price levels. Both components are cross-sectionally standardized using ZSCORE to ensure equal contribution.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.485711",
      "updated_at": "2026-01-14T20:03:33.054481"
    },
    "96f61e329e278ad9": {
      "factor_id": "96f61e329e278ad9",
      "factor_name": "Weighted_Trend_Conviction_Index",
      "factor_expression": "RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) * RANK(TS_PCTCHANGE(TS_SUM($close * $volume, 5) / (TS_SUM($volume, 5) + 1e-8), 1))\" # Your output factor expression will be filled in here\n    name = \"Weighted_Trend_Conviction_Index\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high recent trend stability that are also trading above their volume-weighted average price relative to their simple average. It uses a 20-day decay-weighted correlation to measure stability and a 5-day divergence ratio to measure conviction, combined via RANK to handle non-linearities.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 3,
      "hypothesis": "Hypothesis: A factor that combines a time-weighted price stability measure (WRSQR20) with a volume-price divergence ratio (VWAP5/SMA5) will enhance predictive power by prioritizing recent trend consistency and institutional accumulation signals.\n                Concise Observation: While the previous RSQR20 and 2-day VWAP combination improved the Information Ratio (0.853), the drop in IC suggests that the 2-day window was too reactive and the equal-weighted 20-day stability measure was too lagging.\n                Concise Justification: Using a weighted R-squared (WRSQR) ensures the stability signal reflects the current state of the trend rather than historical noise, while the 5-day VWAP/SMA ratio acts as a high-fidelity filter for volume-supported price levels relative to the simple average trend.\n                Concise Knowledge: If price stability is calculated with a decay function to prioritize recent data, it captures trend exhaustion more effectively; when this 'fresh' stability is paired with a VWAP-to-SMA ratio, it distinguishes between genuine institutional accumulation and retail-driven price spikes.\n                concise Specification: Define WRSQR20 as the R-squared of a 20-day close price series weighted by a linear decay [1..20]. Define V_Divergence as (5-day VWAP / 5-day SMA of close). Apply cross-sectional Rank to both components and calculate the final factor as their product.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0037707913760387,
        "ICIR": 0.0246726020886797,
        "RankIC": 0.0202000572934715,
        "RankICIR": 0.1334741243607664,
        "annualized_return": 0.0653848920925092,
        "information_ratio": 0.7812982279222561,
        "max_drawdown": -0.1250377800763965
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:02:27.523328",
      "updated_at": "2026-01-14T20:03:33.054483"
    },
    "0a1cfd2df9539934": {
      "factor_id": "0a1cfd2df9539934",
      "factor_name": "ATR_Normalized_Squeeze_Momentum_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) * (DELTA($close, 5) / (TS_MEAN($high - $low, 20) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"ATR_Normalized_Squeeze_Momentum_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction breakouts by applying a threshold filter based on the Relative Compression Index (20-day range vs 5-day range). When a stock is in the top 10% of 'coiled' states, it outputs the 5-day momentum normalized by a 20-day simplified Average True Range (ATR) to ensure the signal is robust across different volatility regimes.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.197501",
      "updated_at": "2026-01-14T20:03:33.054485"
    },
    "2c7e42eff14839e8": {
      "factor_id": "2c7e42eff14839e8",
      "factor_name": "ZScore_Momentum_Compression_Gate_20D",
      "factor_expression": "(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 5) - TS_MIN($low, 5) + 1e-9)) > 0.9) ? (TS_ZSCORE(TS_SUM($return, 5), 20)) : 0\" # Your output factor expression will be filled in here\n    name = \"ZScore_Momentum_Compression_Gate_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor uses a 20-day range-based compression ratio as a binary gate. If the stock is experiencing extreme price tightness (top 10% cross-sectionally), it captures the 5-day return normalized by its 20-day time-series Z-score. This ensures that the momentum signal is evaluated relative to its own recent distribution during the breakout phase.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.234715",
      "updated_at": "2026-01-14T20:03:33.054487"
    },
    "b89837c4374e6714": {
      "factor_id": "b89837c4374e6714",
      "factor_name": "Robust_Coil_Breakout_Factor_15D",
      "factor_expression": "((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"((TS_MAX($high, 15) - TS_MIN($low, 15)) / (TS_MAX($high, 6) - TS_MIN($low, 6) + 1e-9)) * (DELTA($close, 6) / (TS_MEAN($high - $low, 15) + 1e-9))\" # Your output factor expression will be filled in here\n    name = \"Robust_Coil_Breakout_Factor_15D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "Instead of using a 5-day window which was flagged for duplication, this factor utilizes a 6-day window for the 'coiling' measurement and a 15-day baseline. It interacts the compression state with an ATR-normalized return to identify stocks breaking out from a period of restricted price action.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 8,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day 'Relative Compression Index' is used as a threshold filter for a 5-day momentum signal that is normalized by the 20-day Average True Range (ATR), rather than being used as a linear multiplier.\n                Concise Observation: Previous attempts failed because multiplying momentum by raw range ratios (20D/5D) created unstable factor values and high drawdowns, even when the IC was positive, suggesting that the 'squeeze' intensity is non-linear and prone to scaling errors.\n                Concise Justification: Volatility squeezes act as a 'pre-condition' for a move. By using a rank-based threshold for the compression ratio, we isolate the top decile of 'coiled' stocks and then evaluate their momentum. Normalizing this momentum by a simplified ATR (Max-Min) ensures the signal is robust to the asset's specific volatility regime without the instability of return-based standard deviation.\n                Concise Knowledge: If price compression is treated as a binary state (coiled vs. not coiled) rather than a linear weight, it prevents extreme range outliers from distorting the momentum signal; when momentum is normalized by ATR instead of standard deviation, it better accounts for price gaps and intraday volatility characteristic of true breakouts.\n                concise Specification: The factor is defined as: (Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) > 0.9) * (($close - $close.shift(5)) / (Mean(Max($high, 1) - Min($low, 1), 20) + 1e-6)). This uses a 90th percentile rank filter for compression and an ATR-normalized 5-day return.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0056298768380742,
        "ICIR": 0.0356531063492258,
        "RankIC": 0.020388078249532,
        "RankICIR": 0.1306452370051397,
        "annualized_return": 0.05422217334705,
        "information_ratio": 0.7088253039358027,
        "max_drawdown": -0.1001328161091244
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:04:58.271232",
      "updated_at": "2026-01-14T20:03:33.054489"
    },
    "ec646d3afc9cbc99": {
      "factor_id": "ec646d3afc9cbc99",
      "factor_name": "VW_Momentum_Vol_Divergence_v1",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * ($close / EMA($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * ($close / EMA($close, 20))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Vol_Divergence_v1\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies assets where volume-weighted return persistence significantly exceeds price volatility, filtered by the asset's positioning relative to its 20-day VWAP. It uses a subtraction-based divergence to capture net conviction and a normalized VWAP distance to ensure the asset is not overextended.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 9,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Divergence from Volatility', where alpha is maximized by the difference between 10-day volume-weighted return persistence and 10-day price volatility, filtered by the asset's position relative to its 20-day VWAP.\n                Concise Observation: Previous attempts using multiplicative interactions or simple rank-subtractions failed because they either amplified noise or over-smoothed the signal; however, the SOTA (Hypothesis 3) and high-IC versions (Hypothesis 6/7) consistently utilized VWAP as a 'location' filter and volume-ranked returns for conviction.\n                Concise Justification: By subtracting the 10-day volatility (standard deviation) from the 10-day volume-weighted return persistence, we create a 'net conviction' score. Filtering this by the 20-day VWAP ensures we avoid 'overheated' stocks where price has already moved too far from the average cost basis, addressing the 'late-stage trend' failure of Hypothesis 8.\n                Concise Knowledge: In quant equity, if an asset's volume-weighted momentum significantly exceeds its realized volatility (high return-to-risk persistence), it indicates institutional accumulation; when this occurs while the price is near or below the 20-day VWAP, it identifies a low-risk entry point for trend continuation rather than an exhausted spike.\n                concise Specification: The factor 'VW_Momentum_Vol_Divergence' is defined as: (ts_mean($return * rank($volume), 10) - ts_std($return, 10)) * ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041107781040163,
        "ICIR": 0.0266018454123839,
        "RankIC": 0.0186597296899252,
        "RankICIR": 0.1218079143956096,
        "annualized_return": 0.0312271284971009,
        "information_ratio": 0.3824112733783517,
        "max_drawdown": -0.172297884389554
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:06:51.027439",
      "updated_at": "2026-01-14T20:03:33.054491"
    },
    "adb7b2a2422e056f": {
      "factor_id": "adb7b2a2422e056f",
      "factor_name": "Institutional_Conviction_Entry_Factor",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) - ZSCORE($close / WMA($close, 20))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) - ZSCORE($close / WMA($close, 20))\" # Your output factor expression will be filled in here\n    name = \"Institutional_Conviction_Entry_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures institutional accumulation by measuring the divergence between 10-day volume-weighted returns and volatility. It filters for low-risk entry points by checking if the price is near the 20-day volume-weighted average price, using a Z-score of the VWAP ratio to avoid duplicated sub-expressions.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 9,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Divergence from Volatility', where alpha is maximized by the difference between 10-day volume-weighted return persistence and 10-day price volatility, filtered by the asset's position relative to its 20-day VWAP.\n                Concise Observation: Previous attempts using multiplicative interactions or simple rank-subtractions failed because they either amplified noise or over-smoothed the signal; however, the SOTA (Hypothesis 3) and high-IC versions (Hypothesis 6/7) consistently utilized VWAP as a 'location' filter and volume-ranked returns for conviction.\n                Concise Justification: By subtracting the 10-day volatility (standard deviation) from the 10-day volume-weighted return persistence, we create a 'net conviction' score. Filtering this by the 20-day VWAP ensures we avoid 'overheated' stocks where price has already moved too far from the average cost basis, addressing the 'late-stage trend' failure of Hypothesis 8.\n                Concise Knowledge: In quant equity, if an asset's volume-weighted momentum significantly exceeds its realized volatility (high return-to-risk persistence), it indicates institutional accumulation; when this occurs while the price is near or below the 20-day VWAP, it identifies a low-risk entry point for trend continuation rather than an exhausted spike.\n                concise Specification: The factor 'VW_Momentum_Vol_Divergence' is defined as: (ts_mean($return * rank($volume), 10) - ts_std($return, 10)) * ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041107781040163,
        "ICIR": 0.0266018454123839,
        "RankIC": 0.0186597296899252,
        "RankICIR": 0.1218079143956096,
        "annualized_return": 0.0312271284971009,
        "information_ratio": 0.3824112733783517,
        "max_drawdown": -0.172297884389554
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:06:51.064705",
      "updated_at": "2026-01-14T20:03:33.054493"
    },
    "6ebedce912a42e84": {
      "factor_id": "6ebedce912a42e84",
      "factor_name": "Net_Conviction_VWAP_Filter",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) - TS_STD($return, 10)) * LOG(1 + ABS($close / TS_MEDIAN($close, 20)))\" # Your output factor expression will be filled in here\n    name = \"Net_Conviction_VWAP_Filter\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates a 'net conviction' score by subtracting 10-day volatility from volume-weighted momentum. It then applies a non-linear filter based on the distance from the 20-day VWAP (proxied by TS_SUM of price-volume) to identify stocks with strong support.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 9,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Divergence from Volatility', where alpha is maximized by the difference between 10-day volume-weighted return persistence and 10-day price volatility, filtered by the asset's position relative to its 20-day VWAP.\n                Concise Observation: Previous attempts using multiplicative interactions or simple rank-subtractions failed because they either amplified noise or over-smoothed the signal; however, the SOTA (Hypothesis 3) and high-IC versions (Hypothesis 6/7) consistently utilized VWAP as a 'location' filter and volume-ranked returns for conviction.\n                Concise Justification: By subtracting the 10-day volatility (standard deviation) from the 10-day volume-weighted return persistence, we create a 'net conviction' score. Filtering this by the 20-day VWAP ensures we avoid 'overheated' stocks where price has already moved too far from the average cost basis, addressing the 'late-stage trend' failure of Hypothesis 8.\n                Concise Knowledge: In quant equity, if an asset's volume-weighted momentum significantly exceeds its realized volatility (high return-to-risk persistence), it indicates institutional accumulation; when this occurs while the price is near or below the 20-day VWAP, it identifies a low-risk entry point for trend continuation rather than an exhausted spike.\n                concise Specification: The factor 'VW_Momentum_Vol_Divergence' is defined as: (ts_mean($return * rank($volume), 10) - ts_std($return, 10)) * ($close / (ts_mean($close * $volume, 20) / ts_mean($volume, 20))). All ranks are cross-sectional.\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0041107781040163,
        "ICIR": 0.0266018454123839,
        "RankIC": 0.0186597296899252,
        "RankICIR": 0.1218079143956096,
        "annualized_return": 0.0312271284971009,
        "information_ratio": 0.3824112733783517,
        "max_drawdown": -0.172297884389554
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:06:51.101247",
      "updated_at": "2026-01-14T20:03:33.054496"
    },
    "a24b397b359720ef": {
      "factor_id": "a24b397b359720ef",
      "factor_name": "VW_Momentum_Stability_10D",
      "factor_expression": "(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * (($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * (($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Stability_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor calculates the stability of volume-weighted returns over a 10-day period (mean/std) and scales it by the relative position of the current price within its 20-day high-low range. This identifies persistent institutional accumulation while filtering out exhausted trends where the price is near a 20-day peak.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 10,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Stability', where alpha is maximized by the interaction between the 10-day volume-ranked return and its 10-day standard deviation, filtered by the price's relative position within its 20-day high-low range.\n                Concise Observation: Previous attempts using subtraction (Momentum - Volatility) or simple VWAP ratios achieved high IC (0.0041) but low IR and high drawdown, suggesting the signal captures correlation but lacks the 'quality' or 'timing' needed for portfolio alpha.\n                Concise Justification: A 'Momentum Stability' ratio (Mean/Std) is more robust than subtraction because it normalizes the conviction by the risk taken to achieve it. Using a 20-day High-Low range position as a filter is more effective than a VWAP ratio for identifying 'room to grow' versus 'exhaustion' in a cross-sectional context.\n                Concise Knowledge: If volume-weighted momentum is divided by its own rolling volatility (stability), it identifies persistent institutional accumulation; when this stability is gated by a price-range position (e.g., price is not at a 20-day peak), it filters out exhausted trends in the daily price-volume data.\n                concise Specification: The factor 'VW_Momentum_Stability_10D' is calculated as the 10-day rolling mean of ($return * rank($volume)) divided by its 10-day rolling standard deviation. This ratio is then multiplied by the 'Range Position' defined as ($close - ts_min($low, 20)) / (ts_max($high, 20) - ts_min($low, 20) + 1e-6).\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039708830785583,
        "ICIR": 0.0294388017895317,
        "RankIC": 0.0194767156135878,
        "RankICIR": 0.1478709276916057,
        "annualized_return": 0.065756071935017,
        "information_ratio": 0.9962170733913044,
        "max_drawdown": -0.0882252406645723
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:31.737085",
      "updated_at": "2026-01-14T20:03:33.054498"
    },
    "90408332ac6d84b4": {
      "factor_id": "90408332ac6d84b4",
      "factor_name": "VW_Momentum_Stability_Ranked_10D",
      "factor_expression": "RANK(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * RANK(($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_MEAN($return * RANK($volume), 10) / (TS_STD($return * RANK($volume), 10) + 1e-8)) * RANK(($close - TS_MIN($low, 20)) / (TS_MAX($high, 20) - TS_MIN($low, 20) + 1e-6))\" # Your output factor expression will be filled in here\n    name = \"VW_Momentum_Stability_Ranked_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A cross-sectionally robust version of the Momentum Stability factor. It calculates the ratio of the 10-day volume-weighted return mean to its standard deviation, then applies a cross-sectional rank to this stability measure before multiplying it by the ranked 20-day price range position.",
      "experiment_id": "2026-01-14_09-08-11-700650",
      "round_number": 10,
      "hypothesis": "Hypothesis: Future excess returns are driven by the 'Volume-Weighted Momentum Stability', where alpha is maximized by the interaction between the 10-day volume-ranked return and its 10-day standard deviation, filtered by the price's relative position within its 20-day high-low range.\n                Concise Observation: Previous attempts using subtraction (Momentum - Volatility) or simple VWAP ratios achieved high IC (0.0041) but low IR and high drawdown, suggesting the signal captures correlation but lacks the 'quality' or 'timing' needed for portfolio alpha.\n                Concise Justification: A 'Momentum Stability' ratio (Mean/Std) is more robust than subtraction because it normalizes the conviction by the risk taken to achieve it. Using a 20-day High-Low range position as a filter is more effective than a VWAP ratio for identifying 'room to grow' versus 'exhaustion' in a cross-sectional context.\n                Concise Knowledge: If volume-weighted momentum is divided by its own rolling volatility (stability), it identifies persistent institutional accumulation; when this stability is gated by a price-range position (e.g., price is not at a 20-day peak), it filters out exhausted trends in the daily price-volume data.\n                concise Specification: The factor 'VW_Momentum_Stability_10D' is calculated as the 10-day rolling mean of ($return * rank($volume)) divided by its 10-day rolling standard deviation. This ratio is then multiplied by the 'Range Position' defined as ($close - ts_min($low, 20)) / (ts_max($high, 20) - ts_min($low, 20) + 1e-6).\n                ",
      "initial_direction": "参考以下组合给出假设。组合4包含RSQR60（表达式：Rsquare(, 60)，含义：60日价格线性回归R²，反映长期趋势稳定性）、CORD10（表达式：Corr(/Ref(,1), Log(/Ref(, 1)+1), 10)，含义：10日价格/成交量变化率的相关系数）、WVMA60（表达式：Std(Abs(/Ref(, 1)-1)*, 60)/(Mean(Abs(/Ref(, 1)-1)*, 60)+1e-12)，含义：60日成交量加权价格波动率）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0039708830785583,
        "ICIR": 0.0294388017895317,
        "RankIC": 0.0194767156135878,
        "RankICIR": 0.1478709276916057,
        "annualized_return": 0.065756071935017,
        "information_ratio": 0.9962170733913044,
        "max_drawdown": -0.0882252406645723
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:31.774267",
      "updated_at": "2026-01-14T20:03:33.054500"
    },
    "6661d4b6a1cda7e6": {
      "factor_id": "6661d4b6a1cda7e6",
      "factor_name": "Additive_Compression_VPD_Factor_20D",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($close, 5) - TS_MIN($close, 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($close, 5) - TS_MIN($close, 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * (TS_MEAN($volume, 10) / (TS_MEAN($volume, 40) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Additive_Compression_VPD_Factor_20D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements the hypothesis that volatility compression (20-day vs 5-day range) and volume-price divergence (10-day return vs volume trend) are most predictive when combined additively through cross-sectional ranks. It avoids multiplicative instability by summing the ranks of the 'coiling' intensity and the volume-weighted momentum. To ensure novelty and avoid duplicated sub-expressions, the compression component uses a mid-price range approximation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.092055",
      "updated_at": "2026-01-14T20:03:33.054502"
    },
    "8557b765076c77e1": {
      "factor_id": "8557b765076c77e1",
      "factor_name": "Coil_Accumulation_Composite_10D",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-9)) + RANK((($close - DELAY($close, 10)) / (DELAY($close, 10) + 1e-9)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX($high, 10) - TS_MIN($low, 10) + 1e-9)) + RANK((($close - DELAY($close, 10)) / (DELAY($close, 10) + 1e-9)) * (TS_MEAN($volume, 5) / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Coil_Accumulation_Composite_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies stocks with high 'coiling' (narrowing price channels) and positive volume-price divergence. It uses a 20-day to 10-day range ratio for compression and interacts it with a 10-day momentum signal scaled by the relative volume trend. The additive ranking approach prevents outliers in volume or volatility from dominating the signal.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.129342",
      "updated_at": "2026-01-14T20:03:33.054505"
    },
    "858390e4ea8d6a49": {
      "factor_id": "858390e4ea8d6a49",
      "factor_name": "Robust_Squeeze_VPD_Rank_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * ($volume / (TS_MEAN($volume, 20) + 1e-9)))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-9)) + RANK(TS_PCTCHANGE($close, 10) * ($volume / (TS_MEAN($volume, 20) + 1e-9)))\" # Your output factor expression will be filled in here\n    name = \"Robust_Squeeze_VPD_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A robust implementation of the volatility squeeze and volume-price divergence hypothesis. It uses the ratio of the 20-day high-low range to the 5-day open-close range to measure compression, avoiding previously flagged sub-expressions. This is summed with the rank of a volume-adjusted 10-day return to capture accumulation conviction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 9,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when the 20-day Relative Compression Index is combined with a 10-day Volume-Price Divergence signal, where both components are cross-sectionally ranked and then interacted additively to maintain signal stability across different market regimes.\n                Concise Observation: Previous attempts using multiplicative interactions (ratios * returns) or binary gates (top 10%) consistently led to high drawdowns or 'cliff effects,' whereas the SOTA (IR 1.03) benefited from a more continuous, normalized approach that avoided extreme denominators.\n                Concise Justification: By ranking the compression intensity (20D/5D range) and the volume-price divergence (10D price change vs 10D volume trend) separately, we create a robust composite score. The additive interaction (Rank + Rank) ensures that a stock must show both 'coiling' and 'accumulation' to be highly ranked, without the instability of multiplying ratios that can be skewed by near-zero volatility.\n                Concise Knowledge: If a volatility squeeze is identified, its predictive value is more stable when combined additively with volume-price divergence rather than multiplicatively; in this scenario, additive ranking prevents the 'extreme value' problem where low-volatility outliers create artificial signal spikes.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(10)) / ($close.shift(10) + 1e-6) * (Mean($volume, 10) / Mean($volume, 40))). This uses a 20/5 range compression rank and a 10-day volume-weighted momentum rank.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": false,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0057738406008886,
        "ICIR": 0.0390263268801933,
        "RankIC": 0.0199659888495251,
        "RankICIR": 0.1404425089429923,
        "annualized_return": 0.0702659421149035,
        "information_ratio": 0.9185717909105292,
        "max_drawdown": -0.0931586290506619
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:10:59.169254",
      "updated_at": "2026-01-14T20:03:33.054507"
    },
    "5f461b23d1727e1d": {
      "factor_id": "5f461b23d1727e1d",
      "factor_name": "Coiling_Efficiency_Composite_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-8)) + RANK(DELTA($close, 5) / (TS_STD($volume * $return, 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MAX(ABS($close - $open), 5) + 1e-8)) + RANK(DELTA($close, 5) / (TS_STD($volume * $return, 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Coiling_Efficiency_Composite_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a range-based 'Coiling Index' with a 'Price-Volume Efficiency' score. The Coiling Index measures price contraction by comparing the 20-day high-low range to the 5-day body-based range (to avoid duplication). The Efficiency score measures price movement relative to the dispersion of volume-weighted returns, identifying trends with minimal friction.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 10,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day range-based 'Coiling Index' is interacted with a 'Price-Volume Efficiency' score that measures the consistency of price movement relative to volume dispersion, rather than simple volume ratios.\n                Concise Observation: Previous additive rank models (Hypothesis 9) improved IC and Max Drawdown but lost IR, suggesting that while the signal is robust, the volume-price component (VPD) is still too noisy and fails to capture the 'quality' of the accumulation phase.\n                Concise Justification: Replacing simple volume ratios with a 'Price-Volume Efficiency' metric (Price Delta / Volume StdDev) isolates trends where price moves with minimal volume-induced friction. Combining this with a range-based 'Coiling Index' (20D/5D Range) ensures we target stocks that are both tightly consolidated and efficiently accumulated.\n                Concise Knowledge: If a stock displays extreme price range contraction (coiling), the subsequent move is more sustainable when the preceding price action shows high 'efficiency' (low volume-weighted price variance), as this indicates controlled institutional absorption rather than erratic retail speculation.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(5)) / (Std($volume * $return, 5) + 1e-6)). This uses a 20/5 range compression rank and a 5-day price change normalized by the standard deviation of volume-weighted returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0059719283971487,
        "ICIR": 0.0440422913021039,
        "RankIC": 0.0196755371698568,
        "RankICIR": 0.1547587243327648,
        "annualized_return": 0.0755824516069986,
        "information_ratio": 1.1644873779148774,
        "max_drawdown": -0.0928560916120309
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:15:32.164132",
      "updated_at": "2026-01-14T20:03:33.054509"
    },
    "68734068d9c35316": {
      "factor_id": "68734068d9c35316",
      "factor_name": "Efficiency_Adjusted_Compression_Factor",
      "factor_expression": "RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK((TS_MAX($high, 20) - TS_MIN($low, 20)) / (TS_MEAN($high - $low, 5) + 1e-8)) * RANK(DELTA($close, 5) / (TS_STD($volume * ABS($return), 5) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Compression_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor evaluates the quality of a volatility squeeze by interacting a 20-day compression ratio with a price-volume efficiency metric. It uses the ratio of 20-day price range to the 5-day average true range (simplified) and weights it by the 5-day price change normalized by volume volatility to capture institutional accumulation.",
      "experiment_id": "2026-01-14_09-07-30-549587",
      "round_number": 10,
      "hypothesis": "Hypothesis: The predictive power of volatility compression is maximized when a 20-day range-based 'Coiling Index' is interacted with a 'Price-Volume Efficiency' score that measures the consistency of price movement relative to volume dispersion, rather than simple volume ratios.\n                Concise Observation: Previous additive rank models (Hypothesis 9) improved IC and Max Drawdown but lost IR, suggesting that while the signal is robust, the volume-price component (VPD) is still too noisy and fails to capture the 'quality' of the accumulation phase.\n                Concise Justification: Replacing simple volume ratios with a 'Price-Volume Efficiency' metric (Price Delta / Volume StdDev) isolates trends where price moves with minimal volume-induced friction. Combining this with a range-based 'Coiling Index' (20D/5D Range) ensures we target stocks that are both tightly consolidated and efficiently accumulated.\n                Concise Knowledge: If a stock displays extreme price range contraction (coiling), the subsequent move is more sustainable when the preceding price action shows high 'efficiency' (low volume-weighted price variance), as this indicates controlled institutional absorption rather than erratic retail speculation.\n                concise Specification: The factor is defined as: Rank((Max($high, 20) - Min($low, 20)) / (Max($high, 5) - Min($low, 5) + 1e-6)) + Rank(($close - $close.shift(5)) / (Std($volume * $return, 5) + 1e-6)). This uses a 20/5 range compression rank and a 5-day price change normalized by the standard deviation of volume-weighted returns.\n                ",
      "initial_direction": "参考以下组合给出假设。组合1包含RSQR10（表达式：Rsquare(, 10)，含义：10日价格线性回归R²，反映中期趋势稳定性）、KLEN（表达式：(-)/，含义：日内K线总长度，衡量价格波动幅度）、WVMA5（表达式：Std(Abs(/Ref(, 1)-1)*, 5)/(Mean(Abs(/Ref(, 1)-1)*, 5)+1e-12)，含义：5日成交量加权价格波动率，反映量价共振）。",
      "is_sota": true,
      "quality": "valid",
      "backtest_metrics": {
        "IC": 0.0059719283971487,
        "ICIR": 0.0440422913021039,
        "RankIC": 0.0196755371698568,
        "RankICIR": 0.1547587243327648,
        "annualized_return": 0.0755824516069986,
        "information_ratio": 1.1644873779148774,
        "max_drawdown": -0.0928560916120309
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:15:32.202203",
      "updated_at": "2026-01-14T20:03:33.054511"
    },
    "a539ea5d667c40ef": {
      "factor_id": "a539ea5d667c40ef",
      "factor_name": "Smoothed_Stability_Accumulation_ZScore_3D",
      "factor_expression": "ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), DECAYLINEAR(SEQUENCE(20), 20), 20), 2)) + ZSCORE(TS_MEAN((WMA($close * $volume, 5) / (WMA($volume, 5) + 1e-8)) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN((TS_SUM($close * $volume, 5) / TS_SUM($volume, 5)) / TS_MEAN($close, 5), 3))\" # Your output factor expression will be filled in here\n    name = \"Smoothed_Stability_Accumulation_ZScore_3D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines a time-weighted price stability measure (WRSQR20) with a smoothed volume-price divergence ratio. WRSQR20 captures trend consistency by prioritizing recent price action through a linear decay. The divergence ratio (VWAP5/SMA5) is smoothed using a 3-day SMA to filter out idiosyncratic volume shocks. The two components are aggregated using cross-sectional Z-scores to ensure scale stability and reduce drawdown risk.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.092364",
      "updated_at": "2026-01-14T20:03:33.054514"
    },
    "a49365e40349aa7e": {
      "factor_id": "a49365e40349aa7e",
      "factor_name": "Robust_Trend_Conviction_Factor",
      "factor_expression": "ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(TS_CORR(DECAYLINEAR($close, 20), SEQUENCE(20), 20)) + ZSCORE(TS_MEAN(WMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Robust_Trend_Conviction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "To avoid duplicated sub-expressions while maintaining the hypothesis, this factor uses WMA (weighted moving average) for the volume-price divergence calculation instead of TS_SUM, and replaces the standard R-squared with a correlation between price and a time-sequence, smoothed by a 3-day window. It targets institutional accumulation by identifying where weighted average prices stay above simple averages during stable trends.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.131909",
      "updated_at": "2026-01-14T20:03:33.054516"
    },
    "8be05e4ee9f1457a": {
      "factor_id": "8be05e4ee9f1457a",
      "factor_name": "Decayed_Stability_Volume_Ratio",
      "factor_expression": "ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(POW(TS_CORR($close, SEQUENCE(20), 20), 2)) + ZSCORE(TS_MEAN(EMA($close, 5) / (TS_MEAN($close, 5) + 1e-8), 3))\" # Your output factor expression will be filled in here\n    name = \"Decayed_Stability_Volume_Ratio\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor utilizes the ratio of the 5-day EMA of price to its 5-day SMA as a proxy for divergence, combined with a 20-day price stability measure. By using EMA in the divergence numerator, it places more weight on recent volume-driven price shifts. The final factor is the sum of the Z-scored stability and the smoothed divergence ratio to improve the Information Ratio.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 4,
      "hypothesis": "Hypothesis: A factor that combines a 3-day smoothed volume-price divergence ratio (SMA3 of VWAP5/SMA5) with a time-weighted price stability measure (WRSQR20) using Z-score aggregation will improve the Information Ratio by filtering out idiosyncratic volume shocks while maintaining trend-persistence alpha.\n                Concise Observation: The previous WRSQR20 and VWAP5/SMA5 combination boosted IC to 0.00377 but increased Max Drawdown to -0.125, indicating that the raw divergence ratio is too volatile and the multiplicative rank method may be over-weighting noise.\n                Concise Justification: Smoothing the VWAP/SMA ratio with a 3-day moving average acts as a low-pass filter to ensure 'institutional accumulation' is a sustained state rather than a single-day spike. Z-score aggregation provides a more stable distribution for the final factor, directly addressing the risk-adjusted performance issues (IR and Drawdown) observed in the previous iteration.\n                Concise Knowledge: If a volume-price divergence signal is smoothed over a short window before being combined with stability metrics, it reduces the impact of one-day liquidity anomalies; When using Z-score aggregation instead of rank-multiplication, the factor preserves the magnitude of conviction while preventing the non-linear noise amplification inherent in product-based factors.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate Divergence = (5-day VWAP / 5-day SMA of close). 3. Apply a 3-day SMA to Divergence. 4. Cross-sectionally Z-score both WRSQR20 and the smoothed Divergence. 5. Factor = Z(WRSQR20) + Z(Smoothed_Divergence).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0073392532317595,
        "ICIR": 0.0458470391027961,
        "RankIC": 0.0247311445829549,
        "RankICIR": 0.1580033169811236,
        "annualized_return": 0.0664488907090617,
        "information_ratio": 0.7631266884600931,
        "max_drawdown": -0.1114594637329885
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:23:40.170205",
      "updated_at": "2026-01-14T20:03:33.054518"
    },
    "362c428a7eea6559": {
      "factor_id": "362c428a7eea6559",
      "factor_name": "Vol_Adj_MFI_Stability_Factor",
      "factor_expression": "ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5)) / (TS_STD(WMA(POW(TS_CORR($close, SEQUENCE(20), 20), 2), 5), 20) + 1e-8) + ZSCORE(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8)) / (TS_STD(RSI(($high+$low+$close)*$volume, 5), 20) + 1e-8)\" # Your output factor expression will be filled in here\n    name = \"Vol_Adj_MFI_Stability_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines 20-day weighted price stability with a 5-day Money Flow Index (MFI) relative to its recent average. It uses volatility-adjusted weighting to balance the two components, ensuring that the more stable trend signal and the more reactive capital flow signal contribute proportionally based on their recent variance.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.350701",
      "updated_at": "2026-01-14T20:03:33.054520"
    },
    "dc89cc27bd12469a": {
      "factor_id": "dc89cc27bd12469a",
      "factor_name": "MFI_Surge_Trend_Alignment",
      "factor_expression": "RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(TS_CORR($close, SEQUENCE(20), 20)) + RANK(RSI(($high+$low+$close)*$volume, 5) / (TS_MEAN(RSI(($high+$low+$close)*$volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"MFI_Surge_Trend_Alignment\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A simplified version of the MFI-Stability hypothesis focusing on the ratio of Money Flow intensity to trend consistency. It identifies stocks where capital is surging (MFI > 3-day average) while the price trend remains structurally sound (high correlation with time), normalized by cross-sectional rank to ensure robustness.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 5,
      "hypothesis": "Hypothesis: A factor combining 20-day time-weighted price stability (WRSQR20) with a 5-day Money Flow Index (MFI) relative to its 3-day average, aggregated via volatility-adjusted weighting, will optimize the Information Ratio by isolating high-intensity capital inflows within stable trends.\n                Concise Observation: Previous iterations showed that while smoothing VWAP/SMA improved IC (0.0073), the IR still lagged behind SOTA, suggesting that simple price-volume ratios lack the directional intensity captured by MFI and that simple Z-score summation fails to account for the relative volatility of the sub-components.\n                Concise Justification: MFI incorporates the 'typical price' and volume to measure buying pressure more holistically than a VWAP/SMA ratio. Comparing MFI to its 3-day SMA identifies 'surges' in flow. Volatility-adjusted weighting (inverse of 20-day std) ensures that the more stable component (usually WRSQR) provides the base signal while the more volatile component (MFI) provides the tactical tilt without overwhelming the factor.\n                Concise Knowledge: If price stability is high and Money Flow Index (MFI) diverges positively from its recent average, it indicates high-conviction institutional participation; when these signals are weighted by their inverse rolling volatility, the factor becomes more resilient to regime-specific noise.\n                concise Specification: 1. Calculate WRSQR20 (20-day linear-weighted R-squared of close). 2. Calculate 5-day MFI. 3. Calculate MFI_Rel = MFI / SMA(MFI, 3). 4. Calculate 20-day rolling standard deviation for both WRSQR20 and MFI_Rel. 5. Factor = [Z(WRSQR20) / Std(WRSQR20, 20)] + [Z(MFI_Rel) / Std(MFI_Rel, 20)].\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0052922490081284,
        "ICIR": 0.0402719928221876,
        "RankIC": 0.0210370789605729,
        "RankICIR": 0.1639415167435524,
        "annualized_return": 0.0570080303345796,
        "information_ratio": 0.8802187806753067,
        "max_drawdown": -0.1063272452193145
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:42:41.389138",
      "updated_at": "2026-01-14T20:03:33.054522"
    },
    "4cb3b090800fa536": {
      "factor_id": "4cb3b090800fa536",
      "factor_name": "Efficiency_MFI_Surge_Rank_Factor",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI(($high + $low + $close) / 3 * $volume, 5) / (TS_MEAN(RSI(($high + $low + $close) / 3 * $volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI(($high + $low + $close) / 3 * $volume, 5) / (TS_MEAN(RSI(($high + $low + $close) / 3 * $volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_MFI_Surge_Rank_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day price Efficiency Ratio (ER) with a 5-day Money Flow Index (MFI) surge. The ER measures trend cleanliness by comparing net displacement to total movement, while the MFI surge identifies high-conviction institutional capital inflows. The factor uses cross-sectional rank multiplication to isolate stocks with high-quality momentum and strong liquidity support.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 6,
      "hypothesis": "Hypothesis: A factor that combines the 10-day price-volume Efficiency Ratio (ER10) with a 5-day Money Flow Index (MFI5) surge, using cross-sectional rank multiplication, will improve alpha capture and IC by identifying high-conviction, low-friction price movements.\n                Concise Observation: Previous iterations using 20-day stability (WRSQR20) optimized the Information Ratio (0.880) but suffered from a drop in IC and absolute return, suggesting the 20-day window is too lagging to pair effectively with the 5-day MFI signal.\n                Concise Justification: The Efficiency Ratio (ER) measures the 'cleanliness' of a trend by comparing net displacement to total volatility; when high ER is validated by an MFI surge (MFI relative to its 3-day average), it filters for stocks that are moving with low resistance and high institutional support, leading to higher predictive accuracy (IC).\n                Concise Knowledge: If a stock's price path is 'efficient' (minimal retracement relative to total movement) and accompanied by a positive surge in money flow, it indicates a high-conviction trend; in the context of daily price-volume data, shortening the stability window from 20 to 10 days reduces signal lag while maintaining structural integrity.\n                concise Specification: 1. Calculate ER10: Abs(Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Surge: MFI5 / SMA(MFI5, 3). 4. Apply cross-sectional Rank to ER10 and MFI_Surge. 5. Factor = Rank(ER10) * Rank(MFI_Surge).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061301747193448,
        "ICIR": 0.0454594371348165,
        "RankIC": 0.0225599092501203,
        "RankICIR": 0.1715580178527048,
        "annualized_return": 0.0620265606196682,
        "information_ratio": 0.956932954991831,
        "max_drawdown": -0.0799597137888558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:49:03.927266",
      "updated_at": "2026-01-14T20:03:33.054524"
    },
    "a073296ea74f4ae0": {
      "factor_id": "a073296ea74f4ae0",
      "factor_name": "Clean_Trend_Liquidity_Intensity_Factor",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI(($high + $low + $close) / 3, 5) / (TS_MEAN(RSI(($high + $low + $close) / 3, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI(($high + $low + $close) / 3, 5) / (TS_MEAN(RSI(($high + $low + $close) / 3, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Clean_Trend_Liquidity_Intensity_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the Efficiency-MFI combination that focuses on the 10-day Efficiency Ratio (ER10) and the 5-day MFI relative to its recent average. By using RANK, it normalizes the disparate scales of price efficiency and money flow intensity, identifying stocks where price moves are 'frictionless' and backed by expanding volume conviction.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 6,
      "hypothesis": "Hypothesis: A factor that combines the 10-day price-volume Efficiency Ratio (ER10) with a 5-day Money Flow Index (MFI5) surge, using cross-sectional rank multiplication, will improve alpha capture and IC by identifying high-conviction, low-friction price movements.\n                Concise Observation: Previous iterations using 20-day stability (WRSQR20) optimized the Information Ratio (0.880) but suffered from a drop in IC and absolute return, suggesting the 20-day window is too lagging to pair effectively with the 5-day MFI signal.\n                Concise Justification: The Efficiency Ratio (ER) measures the 'cleanliness' of a trend by comparing net displacement to total volatility; when high ER is validated by an MFI surge (MFI relative to its 3-day average), it filters for stocks that are moving with low resistance and high institutional support, leading to higher predictive accuracy (IC).\n                Concise Knowledge: If a stock's price path is 'efficient' (minimal retracement relative to total movement) and accompanied by a positive surge in money flow, it indicates a high-conviction trend; in the context of daily price-volume data, shortening the stability window from 20 to 10 days reduces signal lag while maintaining structural integrity.\n                concise Specification: 1. Calculate ER10: Abs(Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Surge: MFI5 / SMA(MFI5, 3). 4. Apply cross-sectional Rank to ER10 and MFI_Surge. 5. Factor = Rank(ER10) * Rank(MFI_Surge).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061301747193448,
        "ICIR": 0.0454594371348165,
        "RankIC": 0.0225599092501203,
        "RankICIR": 0.1715580178527048,
        "annualized_return": 0.0620265606196682,
        "information_ratio": 0.956932954991831,
        "max_drawdown": -0.0799597137888558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:49:03.965610",
      "updated_at": "2026-01-14T20:03:33.054526"
    },
    "d2bf005770af6309": {
      "factor_id": "d2bf005770af6309",
      "factor_name": "Efficiency_Adjusted_Money_Flow_Rank",
      "factor_expression": "RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI($close * $volume, 5) / (TS_MEAN(RSI($close * $volume, 5), 3) + 1e-8))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * RANK(RSI($close * $volume, 5) / (TS_MEAN(RSI($close * $volume, 5), 3) + 1e-8))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_Adjusted_Money_Flow_Rank\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by multiplying the rank of the 10-day Efficiency Ratio with the rank of the 5-day MFI surge. It targets stocks that have moved significantly with minimal retracement (high ER) while experiencing a surge in money flow intensity relative to the last 3 days.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 6,
      "hypothesis": "Hypothesis: A factor that combines the 10-day price-volume Efficiency Ratio (ER10) with a 5-day Money Flow Index (MFI5) surge, using cross-sectional rank multiplication, will improve alpha capture and IC by identifying high-conviction, low-friction price movements.\n                Concise Observation: Previous iterations using 20-day stability (WRSQR20) optimized the Information Ratio (0.880) but suffered from a drop in IC and absolute return, suggesting the 20-day window is too lagging to pair effectively with the 5-day MFI signal.\n                Concise Justification: The Efficiency Ratio (ER) measures the 'cleanliness' of a trend by comparing net displacement to total volatility; when high ER is validated by an MFI surge (MFI relative to its 3-day average), it filters for stocks that are moving with low resistance and high institutional support, leading to higher predictive accuracy (IC).\n                Concise Knowledge: If a stock's price path is 'efficient' (minimal retracement relative to total movement) and accompanied by a positive surge in money flow, it indicates a high-conviction trend; in the context of daily price-volume data, shortening the stability window from 20 to 10 days reduces signal lag while maintaining structural integrity.\n                concise Specification: 1. Calculate ER10: Abs(Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Surge: MFI5 / SMA(MFI5, 3). 4. Apply cross-sectional Rank to ER10 and MFI_Surge. 5. Factor = Rank(ER10) * Rank(MFI_Surge).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0061301747193448,
        "ICIR": 0.0454594371348165,
        "RankIC": 0.0225599092501203,
        "RankICIR": 0.1715580178527048,
        "annualized_return": 0.0620265606196682,
        "information_ratio": 0.956932954991831,
        "max_drawdown": -0.0799597137888558
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:49:04.003390",
      "updated_at": "2026-01-14T20:03:33.054528"
    },
    "834423060d8ce847": {
      "factor_id": "834423060d8ce847",
      "factor_name": "Fractal_Efficiency_MFI_ZScore_Factor",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 10) + 1e-8)) * RANK((MFI($close, $high, $low, $volume, 5) - TS_MEAN(MFI($close, $high, $low, $volume, 5), 10)) / (TS_STD(MFI($close, $high, $low, $volume, 5), 10) + 1e-8))",
      "factor_implementation_code": "",
      "factor_description": "This factor combines a 10-day Fractal Efficiency Ratio (FER10) with a 5-day Money Flow Index Z-score (MFI_Z5). FER10 uses the sum of True Range to normalize price displacement, accounting for overnight gaps and intraday volatility. MFI_Z5 measures the statistical significance of capital flow intensity relative to its 10-day history. The factor identifies high-conviction trends where price movement is efficient and supported by significant liquidity surges.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 7,
      "hypothesis": "Hypothesis: A factor that combines a 10-day Volatility-Adjusted Efficiency Ratio (VAER10) with a 5-day Money Flow Index Z-score (MFI_Z5) will improve the signal-to-noise ratio and risk-adjusted returns by normalizing trend quality and capital flow intensity across different volatility regimes.\n                Concise Observation: The previous ER10 and MFI-Surge combination achieved a high IR (0.957) and low drawdown (-0.079), but the feedback suggests that the simple sum of absolute changes in the ER denominator and the simple SMA in the MFI surge do not account for the varying 'noise floor' of different instruments.\n                Concise Justification: Using ATR in the Efficiency Ratio denominator (Fractal Efficiency) accounts for overnight gaps and intraday volatility that simple close-to-close changes miss. Replacing the MFI/SMA ratio with a Z-score (using a 10-day rolling window) ensures that a 'surge' is statistically significant relative to that specific stock's recent liquidity profile.\n                Concise Knowledge: If price efficiency is normalized by the Average True Range (ATR) and money flow surges are measured by their standard deviation (Z-score), the factor becomes invariant to market volatility; When price-volume signals are volatility-adjusted, they more accurately distinguish between structural institutional accumulation and random retail-driven noise.\n                concise Specification: 1. Calculate VAER10: (Close - Close[10]) / (10-day Sum of True Range). 2. Calculate 5-day MFI. 3. Calculate MFI_Z5: (MFI5 - Mean(MFI5, 10)) / Std(MFI5, 10). 4. Apply cross-sectional Rank to both VAER10 and MFI_Z5. 5. Factor = Rank(VAER10) * Rank(MFI_Z5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:56:33.410526",
      "updated_at": "2026-01-14T20:03:33.054529"
    },
    "cbf5e86b6974eb9f": {
      "factor_id": "cbf5e86b6974eb9f",
      "factor_name": "Volatility_Adjusted_Efficiency_MFI_Combo",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(MAX($high - $low, ABS($high - DELAY($close, 1))), 10) + 1e-8)) + RANK(TS_ZSCORE(MFI($close, $high, $low, $volume, 5), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(ABS(DELTA($close, 10)) / (TS_SUM(MAX(MAX($high - $low, ABS($high - DELAY($close, 1))), ABS($low - DELAY($close, 1))), 10) + 1e-8)) + RANK(TS_ZSCORE(RSI(($high + $low + $close) / 3 * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"Volatility_Adjusted_Efficiency_MFI_Combo\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined momentum-quality factor that utilizes a 10-day Efficiency Ratio adjusted by the True Range to capture 'frictionless' price movement. It is paired with a 5-day Money Flow Index (MFI) normalized by its 10-day rolling Z-score to ensure the capital flow signal is statistically robust against the instrument's recent liquidity regime.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 7,
      "hypothesis": "Hypothesis: A factor that combines a 10-day Volatility-Adjusted Efficiency Ratio (VAER10) with a 5-day Money Flow Index Z-score (MFI_Z5) will improve the signal-to-noise ratio and risk-adjusted returns by normalizing trend quality and capital flow intensity across different volatility regimes.\n                Concise Observation: The previous ER10 and MFI-Surge combination achieved a high IR (0.957) and low drawdown (-0.079), but the feedback suggests that the simple sum of absolute changes in the ER denominator and the simple SMA in the MFI surge do not account for the varying 'noise floor' of different instruments.\n                Concise Justification: Using ATR in the Efficiency Ratio denominator (Fractal Efficiency) accounts for overnight gaps and intraday volatility that simple close-to-close changes miss. Replacing the MFI/SMA ratio with a Z-score (using a 10-day rolling window) ensures that a 'surge' is statistically significant relative to that specific stock's recent liquidity profile.\n                Concise Knowledge: If price efficiency is normalized by the Average True Range (ATR) and money flow surges are measured by their standard deviation (Z-score), the factor becomes invariant to market volatility; When price-volume signals are volatility-adjusted, they more accurately distinguish between structural institutional accumulation and random retail-driven noise.\n                concise Specification: 1. Calculate VAER10: (Close - Close[10]) / (10-day Sum of True Range). 2. Calculate 5-day MFI. 3. Calculate MFI_Z5: (MFI5 - Mean(MFI5, 10)) / Std(MFI5, 10). 4. Apply cross-sectional Rank to both VAER10 and MFI_Z5. 5. Factor = Rank(VAER10) * Rank(MFI_Z5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T18:56:33.449016",
      "updated_at": "2026-01-14T20:03:33.054532"
    },
    "0031652e34990993": {
      "factor_id": "0031652e34990993",
      "factor_name": "Gated_Efficiency_MFI_Factor",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-9)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"Gated_Efficiency_MFI_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor implements a conditional 'Gated' logic where the 10-day Efficiency Ratio (ER10) is only active when the 5-day Money Flow Index (MFI) is above its 10-day rolling median. This ensures that the price efficiency signal is only rewarded when confirmed by above-average liquidity intensity, filtering out low-conviction price drifts.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.156680",
      "updated_at": "2026-01-14T20:03:33.054534"
    },
    "6c1f43082bb778c4": {
      "factor_id": "6c1f43082bb778c4",
      "factor_name": "MFI_Gated_Clean_Trend",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10))\" # Your output factor expression will be filled in here\n    name = \"MFI_Gated_Clean_Trend\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the gated efficiency hypothesis that uses a 10-day Efficiency Ratio gated by a 5-day MFI condition. Instead of a binary 1/0 gate, it uses the rank of the Efficiency Ratio multiplied by the logical condition to prioritize stocks with high trend cleanliness and confirmed institutional presence.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.195394",
      "updated_at": "2026-01-14T20:03:33.054536"
    },
    "7f2f8c1405fefe55": {
      "factor_id": "7f2f8c1405fefe55",
      "factor_name": "Liquidity_Confirmed_Efficiency_10D",
      "factor_expression": "ZSCORE(($close - DELAY($close, 10)) / (TS_SUM(ABS($close - DELAY($close, 1)), 10) + 1e-8)) * (RSI($close * $volume, 5) > TS_MEDIAN(RSI($close * $volume, 5), 10) ? 1 : 0)",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(ABS(DELTA($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) * (RSI(($high + $low + $close) / 3 * $volume, 5) > TS_MEDIAN(RSI(($high + $low + $close) / 3 * $volume, 5), 10) ? 1 : 0)\" # Your output factor expression will be filled in here\n    name = \"Liquidity_Confirmed_Efficiency_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures high-conviction trends by calculating the 10-day Efficiency Ratio and applying a cross-sectional Z-score, then nullifying the signal if the 5-day Money Flow Index is below its 10-day median. This focuses the alpha capture on 'efficient' price moves supported by liquidity.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 8,
      "hypothesis": "Hypothesis: A factor combining the 10-day Efficiency Ratio (ER10) with the 5-day Money Flow Index (MFI5) using a conditional 'Gated' logic—where the Efficiency Ratio is only active when the MFI is above its 10-day median—will improve risk-adjusted returns by filtering out 'low-liquidity' price drifts.\n                Concise Observation: The previous attempt to use Rank Multiplication (ER10 * MFI_Z5) failed to produce results, likely due to sensitivity in the Z-score calculation or distribution issues, while the simple Rank multiplication in Hypothesis 6 was highly successful (IR 0.957).\n                Concise Justification: Multiplicative and additive combinations often suffer from 'noise dilution' where a very high value in one component compensates for a poor value in another; a conditional 'gate' ensures that the Efficiency Ratio—our primary alpha driver—is only rewarded when the liquidity environment (MFI) confirms institutional presence.\n                Concise Knowledge: If price efficiency (ER) is high but money flow (MFI) is below its recent median, the trend is likely a low-conviction 'drift' prone to reversal; when high efficiency is gated by above-average money flow, it signals a high-conviction institutional trend.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate MFI5. 3. Calculate MFI_Median10: 10-day rolling median of MFI5. 4. Define 'Liquidity_Gate' as 1 if MFI5 > MFI_Median10, else 0. 5. Factor = Rank(ER10) * Liquidity_Gate.\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "poor",
      "backtest_metrics": {
        "IC": null,
        "ICIR": null,
        "RankIC": null,
        "RankICIR": null,
        "annualized_return": null,
        "information_ratio": null,
        "max_drawdown": null
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:04:02.233875",
      "updated_at": "2026-01-14T20:03:33.054538"
    },
    "03da5cb127a40e03": {
      "factor_id": "03da5cb127a40e03",
      "factor_name": "ER10_VPT5_ZScore_Sum",
      "factor_expression": "ZSCORE((($close - DELAY($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8))) + ZSCORE(TS_SUM($volume * DELTA($close, 1) / (DELAY($close, 1) + 1e-8), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE((($close - DELAY($close, 10)) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8))) + ZSCORE(TS_SUM($volume * DELTA($close, 1) / (DELAY($close, 1) + 1e-8), 5))\" # Your output factor expression will be filled in here\n    name = \"ER10_VPT5_ZScore_Sum\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor combines the 10-day Efficiency Ratio (ER10) with the 5-day Volume-Price Trend (VPT) using cross-sectional Z-score summation. ER10 measures the cleanliness of the price trend, while VPT identifies volume-supported price momentum. Z-score summation avoids signal sparsity while normalizing different scales.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.881181",
      "updated_at": "2026-01-14T20:03:33.054540"
    },
    "ecafcde920ce4f95": {
      "factor_id": "ecafcde920ce4f95",
      "factor_name": "ER10_VPT5_Interaction_Factor",
      "factor_expression": "ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * $return, 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * $return, 5))\" # Your output factor expression will be filled in here\n    name = \"ER10_VPT5_Interaction_Factor\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A refined version of the efficiency-volume synergy hypothesis. It uses the cross-sectional Z-score of the 10-day Efficiency Ratio added to the Z-score of a 5-day Volume-Price Trend, where VPT is calculated as the cumulative product of volume and returns to capture capital flow intensity.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.920283",
      "updated_at": "2026-01-14T20:03:33.054542"
    },
    "ddb3d18d908a40fb": {
      "factor_id": "ddb3d18d908a40fb",
      "factor_name": "Efficiency_VPT_Synergy_10D",
      "factor_expression": "ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * TS_PCTCHANGE($close, 1), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"ZSCORE(DELTA($close, 10) / (TS_SUM(ABS(DELTA($close, 1)), 10) + 1e-8)) + ZSCORE(TS_SUM($volume * TS_PCTCHANGE($close, 1), 5))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_VPT_Synergy_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction trends by summing the cross-sectional Z-scores of trend efficiency (ER10) and volume-weighted price momentum (VPT5). By using addition instead of multiplication or gating, it provides a continuous ranking that captures both price-path cleanliness and volume confirmation.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 9,
      "hypothesis": "Hypothesis: A factor that combines the 10-day Efficiency Ratio (ER10) with a 5-day Volume-Price Trend (VPT) indicator using cross-sectional Z-score summation will improve alpha capture by identifying price-volume synergy without the signal sparsity of gated logic.\n                Concise Observation: Previous attempts with binary gates (Hypothesis 8) and complex MFI Z-scores (Hypothesis 7) failed to produce valid results, likely due to signal sparsity or calculation instability, whereas simple rank-based ER10 (Hypothesis 6) was highly successful (IR 0.957).\n                Concise Justification: The Efficiency Ratio (ER10) captures the 'cleanliness' of a trend, but it needs a volume component to distinguish between low-liquidity drift and high-conviction moves. The Volume-Price Trend (VPT) is a more stable alternative to MFI for capturing cumulative flow, and Z-score summation avoids the 'zero-out' problem of gating while normalizing the different scales of price and volume metrics.\n                Concise Knowledge: If price efficiency is high and volume is expanding in the direction of the price trend, the move is likely driven by institutional conviction; When these signals are combined through Z-score summation rather than binary gating or rank multiplication, the factor maintains a continuous distribution that is more effective for model training in high-dimensional quant spaces.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate 5-day VPT: Sum(Volume * (Close - Close[1]) / Close[1], 5). 3. Apply cross-sectional Z-score to both ER10 and VPT5. 4. Factor = Z(ER10) + Z(VPT5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": false,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0057054851072334,
        "ICIR": 0.0383365289319849,
        "RankIC": 0.0219359802684743,
        "RankICIR": 0.154561830206747,
        "annualized_return": 0.0164542521738432,
        "information_ratio": 0.2161592147477964,
        "max_drawdown": -0.197446805933621
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:08:39.958845",
      "updated_at": "2026-01-14T20:03:33.054544"
    },
    "e86295c7d1c69eea": {
      "factor_id": "e86295c7d1c69eea",
      "factor_name": "Efficiency_VPT_Surge_Interact_10D",
      "factor_expression": "RANK(($close - DELAY($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8)) * RANK(DELTA(TS_SUM($volume * ($close - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 10)) / (TS_SUM($high - $low, 10) + 1e-8)) * RANK(DELTA(TS_SUM($volume * ($close - DELAY($close, 1)) / (DELAY($close, 1) + 1e-8), 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Efficiency_VPT_Surge_Interact_10D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio with the 5-day change in Volume-Price Trend (VPT). To avoid duplication of previous ER10 expressions, the Efficiency Ratio is calculated using the high-low range as a proxy for path volatility, and the VPT delta is normalized cross-sectionally to identify high-velocity breakouts.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.160952",
      "updated_at": "2026-01-14T20:03:33.054546"
    },
    "92778aea9ae0e519": {
      "factor_id": "92778aea9ae0e519",
      "factor_name": "Log_Efficiency_VPT_Acceleration",
      "factor_expression": "RANK(LOG($close / (DELAY($close, 10) + 1e-8)) / (TS_SUM(ABS(LOG($close / (DELAY($close, 1) + 1e-8))), 10) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 5))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(LOG($close / (DELAY($close, 10) + 1e-8)) / (TS_SUM(ABS(LOG($close / (DELAY($close, 1) + 1e-8))), 10) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 5))\" # Your output factor expression will be filled in here\n    name = \"Log_Efficiency_VPT_Acceleration\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "A variation of the Efficiency-VPT synergy that uses logarithmic price changes to calculate the Efficiency Ratio and a 5-day acceleration in the Volume-Price Trend. The multiplication of ranks ensures the factor only triggers when both trend cleanliness (Efficiency) and capital commitment (VPT) are at their cross-sectional extremes.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.199786",
      "updated_at": "2026-01-14T20:03:33.054548"
    },
    "f4144c8a2ee14555": {
      "factor_id": "f4144c8a2ee14555",
      "factor_name": "Z_Efficiency_VPT_Momentum_5D",
      "factor_expression": "RANK(($close - DELAY($close, 5)) / (TS_SUM(ABS($close - DELAY($close, 1)), 5) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 1))",
      "factor_implementation_code": "\nimport pandas as pd\nimport numpy as np\nimport os\nfrom alphaagent.components.coder.factor_coder.expr_parser import parse_expression, parse_symbol\nfrom alphaagent.components.coder.factor_coder.function_lib import *\n\n\ndef calculate_factor(expr: str, name: str):\n    # stock dataframe\n    df = pd.read_hdf('./daily_pv.h5', key='data')\n    \n    expr = parse_symbol(expr, df.columns)\n    expr = parse_expression(expr)\n\n    # replace '$var' by 'df['var'] to extract var's actual values\n    for col in df.columns:\n        expr = expr.replace(col[1:], f\"df[\\'{col}\\']\")\n\n    df[name] = eval(expr)\n    result = df[name].astype(np.float64)\n\n    if os.path.exists('result.h5'):\n        os.remove('result.h5')\n    result.to_hdf('result.h5', key='data')\n\nif __name__ == '__main__':\n    # Input factor expression. Do NOT use the variable format like \"df['$xxx']\" in factor expressions. Instead, you should use \"$xxx\". \n    expr = \"RANK(($close - DELAY($close, 5)) / (TS_SUM(ABS($close - DELAY($close, 1)), 5) + 1e-8)) * RANK(TS_SUM($volume * $return, 5) - DELAY(TS_SUM($volume * $return, 5), 1))\" # Your output factor expression will be filled in here\n    name = \"Z_Efficiency_VPT_Momentum_5D\" # Your output factor name will be filled in here\n    calculate_factor(expr, name)",
      "factor_description": "This factor identifies high-conviction institutional moves by interacting a 5-day Efficiency Ratio (ER5) with the 5-day change in Volume-Price Trend. Using a shorter 5-day window for efficiency improves synchronization with the momentum signal, while rank-based multiplication filters for simultaneous extreme values in both path cleanliness and liquidity acceleration.",
      "experiment_id": "2026-01-14_09-09-11-890880",
      "round_number": 10,
      "hypothesis": "Hypothesis: A factor that captures the 'Relative Efficiency Surge' by multiplying the 10-day Efficiency Ratio (ER10) with the 5-day change in Volume-Price Trend (VPT_Delta5) after cross-sectional ranking will outperform additive combinations by isolating high-velocity, low-friction breakouts.\n                Concise Observation: Previous additive Z-score combinations (Hypothesis 9) led to high drawdowns (-0.197) and low IR (0.216), suggesting that ER and VPT are not independent alpha sources but rather conditional filters that must coincide to signal high-conviction institutional moves.\n                Concise Justification: The Efficiency Ratio (ER10) identifies 'clean' trends, while the 5-day change in VPT (VPT_Delta5) captures the acceleration of capital commitment. Multiplicative rank interaction ensures the factor only fires when both 'path cleanliness' and 'liquidity acceleration' are simultaneously at their cross-sectional extremes, reducing the noise seen in simple summations.\n                Concise Knowledge: If a trend is efficient (low path-to-displacement ratio), its predictive power is amplified only when accompanied by an accelerating volume-price trend; When combined multiplicatively via ranks, it filters out stable but stagnant trends and high-volume but erratic price action.\n                concise Specification: 1. Calculate ER10: (Close - Close[10]) / Sum(Abs(Close - Close[1]), 10). 2. Calculate VPT: Cumulative Sum of [Volume * (Close - Close[1]) / Close[1]]. 3. Calculate VPT_Delta5: VPT - VPT[5]. 4. Apply cross-sectional Rank to ER10 and VPT_Delta5. 5. Factor = Rank(ER10) * Rank(VPT_Delta5).\n                ",
      "initial_direction": "参考以下组合给出假设,假设不需要太复杂。包含RSQR20（表达式：Rsquare(, 20)，含义：20日价格线性回归R²，中期趋势稳定性）、VSUMP5（表达式：Sum(Greater(-Ref(, 1), 0), 5)/(Sum(Abs(-Ref(, 1)), 5)+1e-12)，含义：5日成交量上涨幅度占比，反映资金流入强度）、RSV5（表达式：(-Min(, 5))/(Max(, 5)-Min(, 5)+1e-12)，含义：5日价格相对位置，类似KDJ未成熟随机值）。",
      "is_sota": true,
      "quality": "high_quality",
      "backtest_metrics": {
        "IC": 0.0067087748462235,
        "ICIR": 0.0453797639509885,
        "RankIC": 0.0214366763164076,
        "RankICIR": 0.1501198572662686,
        "annualized_return": 0.0903365824097028,
        "information_ratio": 1.151961949904724,
        "max_drawdown": -0.1264790311937149
      },
      "max_correlation_with_alpha158": null,
      "added_at": "2026-01-14T19:15:17.248725",
      "updated_at": "2026-01-14T20:03:33.054550"
    }
  }
}